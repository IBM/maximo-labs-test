{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the IBM Maximo Health, Predict and Utilities Lab for MAS version v8.8 Note This lab is still being developed, incomplete and may have errors. We provide it to get your feedback and allow you to reference the materials as the labs are built. This lab provides step-by-step instructions and code examples to help you learn about the product capabilities in IBM Maximo, Health and Predict - Utilities. You will: Setup custom scores to measure asset condition and action assets that need attention. Before getting started ensure you have completed the prerequisites: Prerequisites Learn more Maximo Developer Site Maximo Application Suite Documentation License See the Copyright page for how this Maximo Hands on Lab Exercise is licensed. Updated: 2022-06-16","title":"Welcome to the Lab"},{"location":"#welcome-to-the-ibm-maximo-health-predict-and-utilities-lab-for-mas-version-v88","text":"Note This lab is still being developed, incomplete and may have errors. We provide it to get your feedback and allow you to reference the materials as the labs are built. This lab provides step-by-step instructions and code examples to help you learn about the product capabilities in IBM Maximo, Health and Predict - Utilities. You will: Setup custom scores to measure asset condition and action assets that need attention. Before getting started ensure you have completed the prerequisites: Prerequisites","title":"Welcome to the IBM Maximo Health, Predict and Utilities Lab for MAS version v8.8"},{"location":"#learn-more","text":"Maximo Developer Site Maximo Application Suite Documentation","title":"Learn more"},{"location":"#license","text":"See the Copyright page for how this Maximo Hands on Lab Exercise is licensed. Updated: 2022-06-16","title":"License"},{"location":"appconnect_install/","text":"Data Load App Connect In this exercise you will install App Connect on IBM Cloud so that you can use load asset class data into Maximo Manage. Only App Connect installation is covered in this lab. You can skip these exercise steps if you are loading data using Python. Or your instructor has already loaded asset data into your environment. Install App Connect Deploy App Connect Integration Flows to load data into Health Predict and Utilities Pre-requisites Ensure you have access to: MAS v8.7 Health and Predict Utilities installed and access to the application App Connect is installed with-in OpenShift platform NOT ON IBM Cloud Platform. Asset Class Data and flow bar files for the Labs provided by the instructor. Installation of OpenShift version 4.6 or 4.8 installed & Administration access to OpenShift Platform so that you can complete the App Connect installation and setup steps. Verify the IBM App Connect Operator is available in OpenShift Platform. If IBM App Connect is not available as Operator , then you need to make it available using standard operator. If an Operator is not available, use the documenation to make an operator available in OpenShift Platform. Install App Connect (optional) Below are the steps to install IBM App Connect operator as part of OpenShift Platform. Create the namespace / project in OpenShift platform. E.g. masapp-connect App Connect Operator version has to be carefully choose. E.g. App Connect operator 1.5.2 in OCP 4.6 and 3.0 or 4.0 in OCP 4.8 Provide the name for App Connect, choose the right version Choose the License. Select the right license name in related to operator version is provided in below. License-Details Choose the License use as \"AppConnectEnterpriseProduction\" Choose the right \"Channel Version\" It is important to choose the right Channel Version . Relevant channel version is mentioned in link above as part of Step-5 Choose the Storage type as persistent-claim Choose Common Services as False Provide the name for app connect, choose the right version, choose the right project name and click on Install Wait for about 3-5 mts. Operator will be installed. Installation can be verified by clicking Worloads --> Pods --> Project/Namespace . Pods should be in Running status. Link for App Connect installation --> AppConn-Details Once the operator is installed successfully, there will Integration link created in Networking --> Routes . There is a URL created like <appconnectName-ui> Deploy Integration Flows Flows are used to set up assets and synchronize data each day as it changes. Flows are deployed on the App Connect Integration Server using a Bar file. The Bar file includes a UI for loading data using App Connect integration flows. BAR file related subcomponents are installed and made available as part of Health & Predict Installation. Use the steps for setting up an Integration-Server App Connect Configuration (optional) Open App Connect application by clicking the URL in above. Upon click the URL App Connect Integration server opens. Create and configure new Integration server to load the data files provided by your instructor. Integration servers are created using \"BAR\" files that are made available as part of App Connect setup.","title":"Install and Configure App Connect"},{"location":"appconnect_install/#data-load-app-connect","text":"In this exercise you will install App Connect on IBM Cloud so that you can use load asset class data into Maximo Manage. Only App Connect installation is covered in this lab. You can skip these exercise steps if you are loading data using Python. Or your instructor has already loaded asset data into your environment. Install App Connect Deploy App Connect Integration Flows to load data into Health Predict and Utilities","title":"Data Load App Connect"},{"location":"appconnect_install/#pre-requisites","text":"Ensure you have access to: MAS v8.7 Health and Predict Utilities installed and access to the application App Connect is installed with-in OpenShift platform NOT ON IBM Cloud Platform. Asset Class Data and flow bar files for the Labs provided by the instructor. Installation of OpenShift version 4.6 or 4.8 installed & Administration access to OpenShift Platform so that you can complete the App Connect installation and setup steps. Verify the IBM App Connect Operator is available in OpenShift Platform. If IBM App Connect is not available as Operator , then you need to make it available using standard operator. If an Operator is not available, use the documenation to make an operator available in OpenShift Platform.","title":"Pre-requisites"},{"location":"appconnect_install/#install-app-connect-optional","text":"Below are the steps to install IBM App Connect operator as part of OpenShift Platform. Create the namespace / project in OpenShift platform. E.g. masapp-connect App Connect Operator version has to be carefully choose. E.g. App Connect operator 1.5.2 in OCP 4.6 and 3.0 or 4.0 in OCP 4.8 Provide the name for App Connect, choose the right version Choose the License. Select the right license name in related to operator version is provided in below. License-Details Choose the License use as \"AppConnectEnterpriseProduction\" Choose the right \"Channel Version\" It is important to choose the right Channel Version . Relevant channel version is mentioned in link above as part of Step-5 Choose the Storage type as persistent-claim Choose Common Services as False Provide the name for app connect, choose the right version, choose the right project name and click on Install Wait for about 3-5 mts. Operator will be installed. Installation can be verified by clicking Worloads --> Pods --> Project/Namespace . Pods should be in Running status. Link for App Connect installation --> AppConn-Details Once the operator is installed successfully, there will Integration link created in Networking --> Routes . There is a URL created like <appconnectName-ui>","title":"Install App Connect (optional)"},{"location":"appconnect_install/#deploy-integration-flows","text":"Flows are used to set up assets and synchronize data each day as it changes. Flows are deployed on the App Connect Integration Server using a Bar file. The Bar file includes a UI for loading data using App Connect integration flows. BAR file related subcomponents are installed and made available as part of Health & Predict Installation. Use the steps for setting up an Integration-Server","title":"Deploy Integration Flows"},{"location":"appconnect_install/#app-connect-configuration-optional","text":"Open App Connect application by clicking the URL in above. Upon click the URL App Connect Integration server opens. Create and configure new Integration server to load the data files provided by your instructor. Integration servers are created using \"BAR\" files that are made available as part of App Connect setup.","title":"App Connect Configuration (optional)"},{"location":"asset_data_loader/","text":"Load Utilities Data Into Manage Maximo Predict comes with notebook templates to assist in streamlining data uploads to Maximo Manage. This notebook will create the following resources using provided csv files: Organizations Sites Locations Assets Meters Meter groups These instructions use the notebook named '0_HPU-DataLoader.ipynb' file with the Substation Transformer for Health and Predict for Utilities Demo Assets. In this exercise you will use Watson Studio, Manage and Predict - Utilities to: Gather notebooks and CSV files for all data to be uploaded Upload the and Run the HPU Data Loader Notebooks using a template to upload new Asset and Location Data to Maximo Manage. Confirm the Data Has been uploaded for your assets Handle Errors that may come up in the process Note You must complete the previous exercise for Setup Watson Studio before you start this exercise. This notebook can only be run once per environment per site with the same data set. Prior to uploading data, ensure this data set is not available in Maximo or create a new site or choose a different asset set before running the notebook cells specific to the data to be uploaded. For example, if Substation Transformers are already uploaded for the desired site nad location, only run the cell to upload a new asset csv for that location. Pre-requisites Review Predict documentation for the list of available models . Ensure your MAS Predict environment is running and you have access. Try your server URL that might look something like: https://main.predict.ivt11rel87.ivt.suite.myhost.com/ibm/pmi/service/rest/system/info Ensure you have Access to Asset data files for the Health and Predict Utilities Demo Data Note It is best to perform this lab in your own Watson Studio Project created using Setup Watson Studio instructions. If you are using a shared project, ensure you append each file uploaded with your initials and update the file paths in the notebooks to include that change. Gather notebooks and CSV Files Note Reach out to Carlos Ferreira at carlos.ferreria1@ibm.com for if you cannot access the github below. Navigate to https://github.ibm.com/Watson-IoT/eam-hpu-lab and click Code then Download Zip to download the files required to complete this lab Unzip the file Open the folder labeled csv file and zip/compress the folder containing the data to be uploaded to monitor. In this lab, we will be using the file labeled hpu_csv_v87_st which contains only the substation transformer data. Return to the root folder, and open the file labeled scripts and zip/compress the files inside. Rename the resulting zip file to hpu_dataloader then zip/compress it. Gather the Base url by logging into your Maximo environment, opening the Manage Application and copying the url. Save that and the API key from the previous step to be inserted into this notebook. Follow the instructions in set up Watson Studio under the 'Get URL' section to gather the APM_API_KEY . Upload files and run the Data Loader Notebook Add both the ZIP files to the data assets in your Watson Studio Project. Upload the HPU Data Loader notebook to your Project. Use the steps from the previous exercise Add Notebook From File to a Watson Studio Project . Select the 0_HPU-DataLoader.ipynb notebook template. Click on the pencil icon next to your notebook to open it in edit mode. If the notebook fails to start, restart it. Click on the i icon , Environment tab, Running status dropdown select box and choose Restart Run the Notebook Note If you are using a shared project, this cell is where you would update the file paths to include your initials Run the first cell two cells. These cells are importing and unziping the files to be used and installing necessary packages. Confirm the output has all the necessary files. If it does not and only lists the folder name see Unable to Unzip the Files Replace the values of MX_BASE_URL and MX_APIKEY with the URL and API key gathered at the start of this lab Update the Site ID and the Org ID with the site and org for the data to be associated to. The cell should now look like this: Run the cell to load in the Environment Information and set up the Org and Site to be used For steps 6-14 you will be uploading data from the CSV files. Some cells may take a few minutes to run. You will know it is complete when the text next to the cell goes from In[*] to In[#] where the # symbol is the order in which cells are run If you are creating a new Org and Site for the assets, run the cell under Create Org and Site . If you are uploading data to an existing Site, skip this cell. Before loading into an existing site, ensure the assets indicated do not exist under that site. Run the next cell to upload classification data Run the next cell to upload in domain data Run the next cell to upload in meter and meter group data Run the next cell to upload in location data for containers Run the next cell to upload location data Run the next cell to upload meter readings for locations Skip the commented out cell Run the next cell to upload asset data Run the next cell to upload meter readings for assets Skip the commented out cell Run the next cell to upload LocSystem Data Run the next cell upload LocHierarchy data (Hierarchy and container data) Run the final cell to update the map configuration to reflect the container data Confirm Proper Data Upload The following steps will allow you confirm that the data was uploaded properly. Navigate to Maximo Manage for the environment provided to the notebook Go to the Assets application Filter by the created Site (or the site assets have been added to) Ensure all the assets uploaded are listed and they have the associated location listed Click on one of the Assets and navigate to the Meters tab Expand one of the meters and ensure there is data. Not all demo assets have meter readings. Navigate to Maximo Health Click on the Map view and turn Containers on Filter by your site/assets and ensure you can see containers Note Containers should be Grey until health scores are configured. Error Handling Unable to unzip the file If when running the cell to unzip the files containing the scripts and the data, rather than getting the full file list in the output this is received: Or when running any of the cells to create or load data, you receive an error. Follow the steps below to ensure your file is zipped/compressed properly: Open the file that needs to be re-zipped and select all the files within that folder Right Click > Compress Rename the resulting file to the correct file name indicated in Gather Notebooks and CSV files Re-upload the file to your Watson Studio project and run the first cell again Note If you are using a Windows Machine, the following steps may need to be altered. Congratulations you have learned how to upload Health and Predict - Utilities data via a notebook. You have also gained experience using Jupyter Notebooks in Watson Studio! In the next exercises you will learn how to use the 1_Create-HPU-ScoreGroups.ipynb Notebook template to create health scores for Health and Predict for Utilities assets and associate the asset notebook to that created group.","title":"Load Utilities Data Into Manage"},{"location":"asset_data_loader/#load-utilities-data-into-manage","text":"Maximo Predict comes with notebook templates to assist in streamlining data uploads to Maximo Manage. This notebook will create the following resources using provided csv files: Organizations Sites Locations Assets Meters Meter groups These instructions use the notebook named '0_HPU-DataLoader.ipynb' file with the Substation Transformer for Health and Predict for Utilities Demo Assets. In this exercise you will use Watson Studio, Manage and Predict - Utilities to: Gather notebooks and CSV files for all data to be uploaded Upload the and Run the HPU Data Loader Notebooks using a template to upload new Asset and Location Data to Maximo Manage. Confirm the Data Has been uploaded for your assets Handle Errors that may come up in the process Note You must complete the previous exercise for Setup Watson Studio before you start this exercise. This notebook can only be run once per environment per site with the same data set. Prior to uploading data, ensure this data set is not available in Maximo or create a new site or choose a different asset set before running the notebook cells specific to the data to be uploaded. For example, if Substation Transformers are already uploaded for the desired site nad location, only run the cell to upload a new asset csv for that location.","title":"Load Utilities Data Into Manage"},{"location":"asset_data_loader/#pre-requisites","text":"Review Predict documentation for the list of available models . Ensure your MAS Predict environment is running and you have access. Try your server URL that might look something like: https://main.predict.ivt11rel87.ivt.suite.myhost.com/ibm/pmi/service/rest/system/info Ensure you have Access to Asset data files for the Health and Predict Utilities Demo Data Note It is best to perform this lab in your own Watson Studio Project created using Setup Watson Studio instructions. If you are using a shared project, ensure you append each file uploaded with your initials and update the file paths in the notebooks to include that change.","title":"Pre-requisites"},{"location":"asset_data_loader/#gather-notebooks-and-csv-files","text":"Note Reach out to Carlos Ferreira at carlos.ferreria1@ibm.com for if you cannot access the github below. Navigate to https://github.ibm.com/Watson-IoT/eam-hpu-lab and click Code then Download Zip to download the files required to complete this lab Unzip the file Open the folder labeled csv file and zip/compress the folder containing the data to be uploaded to monitor. In this lab, we will be using the file labeled hpu_csv_v87_st which contains only the substation transformer data. Return to the root folder, and open the file labeled scripts and zip/compress the files inside. Rename the resulting zip file to hpu_dataloader then zip/compress it. Gather the Base url by logging into your Maximo environment, opening the Manage Application and copying the url. Save that and the API key from the previous step to be inserted into this notebook. Follow the instructions in set up Watson Studio under the 'Get URL' section to gather the APM_API_KEY .","title":"Gather notebooks and CSV Files"},{"location":"asset_data_loader/#upload-files-and-run-the-data-loader-notebook","text":"Add both the ZIP files to the data assets in your Watson Studio Project. Upload the HPU Data Loader notebook to your Project. Use the steps from the previous exercise Add Notebook From File to a Watson Studio Project . Select the 0_HPU-DataLoader.ipynb notebook template. Click on the pencil icon next to your notebook to open it in edit mode. If the notebook fails to start, restart it. Click on the i icon , Environment tab, Running status dropdown select box and choose Restart","title":"Upload files and run the Data Loader Notebook"},{"location":"asset_data_loader/#run-the-notebook","text":"Note If you are using a shared project, this cell is where you would update the file paths to include your initials Run the first cell two cells. These cells are importing and unziping the files to be used and installing necessary packages. Confirm the output has all the necessary files. If it does not and only lists the folder name see Unable to Unzip the Files Replace the values of MX_BASE_URL and MX_APIKEY with the URL and API key gathered at the start of this lab Update the Site ID and the Org ID with the site and org for the data to be associated to. The cell should now look like this: Run the cell to load in the Environment Information and set up the Org and Site to be used For steps 6-14 you will be uploading data from the CSV files. Some cells may take a few minutes to run. You will know it is complete when the text next to the cell goes from In[*] to In[#] where the # symbol is the order in which cells are run If you are creating a new Org and Site for the assets, run the cell under Create Org and Site . If you are uploading data to an existing Site, skip this cell. Before loading into an existing site, ensure the assets indicated do not exist under that site. Run the next cell to upload classification data Run the next cell to upload in domain data Run the next cell to upload in meter and meter group data Run the next cell to upload in location data for containers Run the next cell to upload location data Run the next cell to upload meter readings for locations Skip the commented out cell Run the next cell to upload asset data Run the next cell to upload meter readings for assets Skip the commented out cell Run the next cell to upload LocSystem Data Run the next cell upload LocHierarchy data (Hierarchy and container data) Run the final cell to update the map configuration to reflect the container data","title":"Run the Notebook"},{"location":"asset_data_loader/#confirm-proper-data-upload","text":"The following steps will allow you confirm that the data was uploaded properly. Navigate to Maximo Manage for the environment provided to the notebook Go to the Assets application Filter by the created Site (or the site assets have been added to) Ensure all the assets uploaded are listed and they have the associated location listed Click on one of the Assets and navigate to the Meters tab Expand one of the meters and ensure there is data. Not all demo assets have meter readings. Navigate to Maximo Health Click on the Map view and turn Containers on Filter by your site/assets and ensure you can see containers Note Containers should be Grey until health scores are configured.","title":"Confirm Proper Data Upload"},{"location":"asset_data_loader/#error-handling","text":"Unable to unzip the file If when running the cell to unzip the files containing the scripts and the data, rather than getting the full file list in the output this is received: Or when running any of the cells to create or load data, you receive an error. Follow the steps below to ensure your file is zipped/compressed properly: Open the file that needs to be re-zipped and select all the files within that folder Right Click > Compress Rename the resulting file to the correct file name indicated in Gather Notebooks and CSV files Re-upload the file to your Watson Studio project and run the first cell again Note If you are using a Windows Machine, the following steps may need to be altered. Congratulations you have learned how to upload Health and Predict - Utilities data via a notebook. You have also gained experience using Jupyter Notebooks in Watson Studio! In the next exercises you will learn how to use the 1_Create-HPU-ScoreGroups.ipynb Notebook template to create health scores for Health and Predict for Utilities assets and associate the asset notebook to that created group.","title":"Error Handling"},{"location":"asset_investment/","text":"Asset Investment Optimization Maximo Health includes Asset Investment Optimization templates that you can use to see which strategies work best to meet your business goals. In this exercise you will use Health to: Identify Assets in need of inspection, repair or replacement. Create an Asset Investment Project Add Assets to a Project Create an Investment Template by asset type Evaluate Investment Options to see which works best to maintain risk, reduce maintenance costs etc. Set maintain risk strategy to create a business as usual baseline Set reduce risk strategy to adjust the risk of the project based on risk tolerance Set stay in budget strategy to adjust the budget for the project Compare strategies Prerequisites This lab requires the following A working Maximo Application Suite (MAS) environment with Maximo Manage, or another Enterprise Asset Management (EAM) system, Maximo Health, Maximo Health and Predict \u2013 Utilities (HPU), and Maximo Optimizer installed. Sufficient asset data to run the analysis and get insights Please note that the MAS Worldwide (WW) demo environment is NOT a suitable environment for this lab. The WW demo environment is shared, and making ANY changes to that environment will impact other users\u2019 ability to demonstrate MAS. Introduction This lab is intended to demonstrate the Asset Investment Optimizer (AIO) capability in HPU. The AIO allows a Reliability Engineer (RE) to build a project of assets, assign a length of the project, and run multiple strategies to determine which assets should to be replaced over the life of the project, and when. The RE can compare strategies, export details, and ultimately execute the one that meets their needs. The strategies are\u2026 Maintain risk Reduce risk (the RE can select the risk value) Work within a budget (the RE can select the budget) For any use case in Asset Performance Management (APM), the Reliability Engineer (RE) will typically follow three basic steps. Identify assets at risk Investigate assets at risk Take an action The AIO capability is an action that can be taken by the RE to ultimately reduce risk. It can be demonstrated as a stand-alone feature, as presented here, or as a take an action step in a longer narrative. As a result, the asset references and visualizations will vary based on the data set and story, but the steps are the same. Navigate to Health and Predict - Utilities Action: Navigate to Health and Predict - Utilities (HPU). From the main MAS page, select the Industry solutions tab. Then click Health and Predict \u2013 Utilities menu. Identify Assets for a Project The first step in using the Asset Investment Optimization (AIO) feature is to select assets to start a new project or to be part of an existing project. In most list/grid views in HPU, there is a selection box on each asset line that can be checked. Multiple assets on a page can be checked. Once selected, those assets can be used to create a new project, or added to an existing project. Value: The RE can build a project, or add assets to a project from any dashboard, at any time, when they identify an asset at risk. Action: From the main grid view, click the filter icon, then select Type . From the pop-up, find Substation Transformers , select it, and press OK . It may be necessary to use the search capability or scroll. Finally, press Apply . Create a Project The filter will reduce the initial list of all assets under management, to a list of assets identified as substation transformers. In this case, there are 13 substation transformers. Value: The filter capability makes it easy to find and list assets from specific sites, types, failure classes and containers. Action: Select the above assets that appear on the resulting list and press Create investment project . In this case, the first 3 appear on the list (in bold). ST_1393137 ST_1400501 ST_1400502 ST_1400517 ST_1400518 On the Create A Project page, complete the required fields as follows, then press Create . Name: AIO Lab (in a shared environment, this must be unique for each user) Duration in years: 10 Target start quarter: 3Q Target start year: 2022 Note If there is NOT a Replacement plan template already created for Substation Transformers, there will be a prompt to create one. To complete the template, follow the steps later in this lab. Add Assets to an Existing Project Once the project is successfully created, a summary screen of the project will be presented. Take the following steps to add the remaining substation transformers to the project. Value: The RE can add additional assets to a project at any time. Follow the prompt on the left navigation panel to return to the Assets view, and to the list of substation transformers. If this does not direct to the list of substation transformers, follow the previous steps to produce that list. From the resulting list, click through to page 2 of the substation transformer list. Select the remaining substation transformers (in bold): ST_1393137 ST_1400501 ST_1400502 ST_1400517 ST_1400518 Click Add to investment project . In this case, it is the final 2 substation transformers on the following list. From the Add to the investment project popup, select the lab to which these assets will be added, in this case AIO Lab , and press Add . A popup will show that the assets are being added to the project, and the Edit project page will appear. Click Save at the bottom of the page. An additional popup will appear as a reminder that adding additional assets to an existing project will invalidate previous results. Click Save to confirm and proceed. Create a Replacement Plan Template A replacement plan is required for each asset is the project. The assets must either have unique replacement plans, or all of the asset types in the project (in this case, substation transformer) must have replacement plan templates. Value: If an asset exhibits characteristics different from the other assets in its type, or a plan has already been developed for the asset, the asset can still be included in a project using its unique replacement plan. Navigate to the Asset investment optimizer using the left navigation bar. From the Asset investment optimizer page, select Plan templates . On the Plan templates page, select an existing template OR click the + symbol to create a new one. In this case, select substation transformers since there is already a replacement plan template created. The only additional step required when creating a new template is to identify the asset type. On the Edit a replacement plan template , complete the required fields as follows. Expected downtime in hours: 4 Estimated capital cost: $15,000 Estimated operation cost: $20,000 Estimated failure cost: $23,000 Expected life in years: 50 Then click Save . If prompted to Confirm edit , press Continue . Evaluate Investment Options Edit an AIO Project A project can be adjusted at any time. However, making changes will invalidate any investment strategies that have already been executed against the project. After the changes are made, the strategies must be run again. Value: Once a project is created, changes like adjusting assets, the length of the project, and when it starts, can be made at any time. The RE does not need to create a new project. From the Asset investment optimizer page, select the Project tab. Select the project AIO Lab . From the AIO Lab project page, select the pencil icon to review the details of the project. Review the details of the project, and make any required adjustments. In this case, no changes are required. Press Cancel . If changes are made, an additional popup will appear as a reminder that changes to an existing project will invalidate previous results. Click Save to confirm and proceed. Maintain Risk AIO Project The first strategy, maintain risk, determines which assets need to be replaced, and when, in order to maintain the average risk of the project over the life of the project. The average risk is the average of the individual assets in the project. Value: The maintain risk strategy sets a business as usual baseline, to which other strategies can be compared. Action: On the main AIO Lab project page, the maintain risk strategy will already be available and selected in the left column. The average risk score will be calculated. In this case, it is 42. Select the Run analysis button to execute the strategy. The analysis may take some time to run, during which there will be indicators. The results will automatically appear in the report view. In this case, 4 of the 5 assets must be replaced for a total cost of $140,000, with an average risk score of 17.2, and the highest risk score of 31.7 for the duration. Select the table view to see which assets need to be replaced, and when. Reduce Risk AIO Project: The reduce risk strategy allows the RE to select the average risk score for the project. The strategy will determine which assets need to be replaced, and when, in order to maintain the desired risk of the project over the life of the project. Value: The reduce risk strategy allows the RE to adjust the risk of the project based on their risk tolerance. From the main AIO Lab project page, in this case from the table view, click on the + symbol to add a new strategy. From the pop up box, use the pull down menu to select Reduce risk . From the next pop up box, enter a risk value of 10 , the click Create . On the main AIO Lab project page, the reduce risk strategy will be available and selected in the left column, above the last strategy executed, in this case, the maintain risk strategy. Select the Run analysis button to execute the strategy. Once again, the analysis may take some time to run, during which there will be indicators. The results will automatically appear in the report view. In this case, all 5 assets must be replaced for a total cost of $175,000, with an average risk score of 8.0, and the highest risk score of 19.1 for the duration. Select the table view to see which assets need to be replaced, and when. Note Multiple reduce risk strategies can be created using different target risk scores. Stay in Budget AIO Project The stay in budget strategy allows the RE to set a budget for the project. The strategy will determine which assets need to be replaced, and when, in order to stick to a budget for the project. Value: The stay in budget strategy allows the RE to adjust the budget for the project based on the available budget. Action: From the main AIO Lab project page, in this case from the table view, click on the + symbol to add a new strategy. From the pop up box, use the pull down menu to select Stay in budget . From the next pop up box, enter the following values below and the click Create . Capex: 60,000 Opex: 80,000 Total budget: 140,000 On the main AIO Lab project page, the stay in budget strategy will be available and selected in the left column, above the last strategy executed, in this case, the reduce risk strategy. Select the Run analysis button to execute the strategy. Once again, the analysis may take some time to run, during which there will be indicators. The results will automatically appear in the report view. In this case, 4 of the 5 assets must be replaced for a total cost of $140,000, with an average risk score of 17.2, and the highest risk score of 31.7 for the duration. Select the list view to see which assets need to be replace, and when. Note Multiple stay in budget strategies can be created using different budgets. Comparing Investment Strategies Within each AIO project, the RE can compare up to three strategies. Since the RE can create multiple reduce risk and stay in budget strategies, the RE can compare any combination of strategies. In this case, the comparison will be the maintain risk, reduce risk, and stay in budget strategies. Value: The comparison capability gives the RE an easy view to identify which strategy meets their needs, and export the details. From the main AIO Lab project page, in this case from the table view, click on the Compare strategies button. From the popup, select all three strategies, press Create . The resulting comparison provides key information for the RE to decide which strategy to pursue. To export details from one of the strategies, click export at the bottom of one of the strategies. In this case, select Maintain risk. From the Export Data popup, select analysis report, and click Export . Open the results in an application, or save it. The analysis report will show a summary of the selected strategy. Selecting Details for recommended replacements will produce details of the strategy. Summary The data presented in this lab is intended to demonstrate the AIO capabilities, and the results may not accurately reflect real-world scenarios. Note that strategies are highly sensitive and dependent on multiple factors like End of Life and information in the Replacement plan template. It may be necessary to experiment to get satisfactory results. Clean up From the breadcrumbs (or from the left navigation bar), select the Asset Investment Optimizer. On the Project tabs, hover the cursor to the far right of the project name, and select Delete when it appears. When prompted, confirm the deletion of the project. Congratulations. You now have identified at risk assets and have added them to an asset investment optimization project to improve their condition.","title":"Asset Investment Optimization"},{"location":"asset_investment/#asset-investment-optimization","text":"Maximo Health includes Asset Investment Optimization templates that you can use to see which strategies work best to meet your business goals. In this exercise you will use Health to: Identify Assets in need of inspection, repair or replacement. Create an Asset Investment Project Add Assets to a Project Create an Investment Template by asset type Evaluate Investment Options to see which works best to maintain risk, reduce maintenance costs etc. Set maintain risk strategy to create a business as usual baseline Set reduce risk strategy to adjust the risk of the project based on risk tolerance Set stay in budget strategy to adjust the budget for the project Compare strategies Prerequisites This lab requires the following A working Maximo Application Suite (MAS) environment with Maximo Manage, or another Enterprise Asset Management (EAM) system, Maximo Health, Maximo Health and Predict \u2013 Utilities (HPU), and Maximo Optimizer installed. Sufficient asset data to run the analysis and get insights Please note that the MAS Worldwide (WW) demo environment is NOT a suitable environment for this lab. The WW demo environment is shared, and making ANY changes to that environment will impact other users\u2019 ability to demonstrate MAS.","title":"Asset Investment Optimization"},{"location":"asset_investment/#introduction","text":"This lab is intended to demonstrate the Asset Investment Optimizer (AIO) capability in HPU. The AIO allows a Reliability Engineer (RE) to build a project of assets, assign a length of the project, and run multiple strategies to determine which assets should to be replaced over the life of the project, and when. The RE can compare strategies, export details, and ultimately execute the one that meets their needs. The strategies are\u2026 Maintain risk Reduce risk (the RE can select the risk value) Work within a budget (the RE can select the budget) For any use case in Asset Performance Management (APM), the Reliability Engineer (RE) will typically follow three basic steps. Identify assets at risk Investigate assets at risk Take an action The AIO capability is an action that can be taken by the RE to ultimately reduce risk. It can be demonstrated as a stand-alone feature, as presented here, or as a take an action step in a longer narrative. As a result, the asset references and visualizations will vary based on the data set and story, but the steps are the same.","title":"Introduction"},{"location":"asset_investment/#navigate-to-health-and-predict-utilities","text":"Action: Navigate to Health and Predict - Utilities (HPU). From the main MAS page, select the Industry solutions tab. Then click Health and Predict \u2013 Utilities menu.","title":"Navigate to Health and Predict - Utilities"},{"location":"asset_investment/#identify-assets-for-a-project","text":"The first step in using the Asset Investment Optimization (AIO) feature is to select assets to start a new project or to be part of an existing project. In most list/grid views in HPU, there is a selection box on each asset line that can be checked. Multiple assets on a page can be checked. Once selected, those assets can be used to create a new project, or added to an existing project. Value: The RE can build a project, or add assets to a project from any dashboard, at any time, when they identify an asset at risk. Action: From the main grid view, click the filter icon, then select Type . From the pop-up, find Substation Transformers , select it, and press OK . It may be necessary to use the search capability or scroll. Finally, press Apply .","title":"Identify Assets for a Project"},{"location":"asset_investment/#create-a-project","text":"The filter will reduce the initial list of all assets under management, to a list of assets identified as substation transformers. In this case, there are 13 substation transformers. Value: The filter capability makes it easy to find and list assets from specific sites, types, failure classes and containers. Action: Select the above assets that appear on the resulting list and press Create investment project . In this case, the first 3 appear on the list (in bold). ST_1393137 ST_1400501 ST_1400502 ST_1400517 ST_1400518 On the Create A Project page, complete the required fields as follows, then press Create . Name: AIO Lab (in a shared environment, this must be unique for each user) Duration in years: 10 Target start quarter: 3Q Target start year: 2022 Note If there is NOT a Replacement plan template already created for Substation Transformers, there will be a prompt to create one. To complete the template, follow the steps later in this lab.","title":"Create a Project"},{"location":"asset_investment/#add-assets-to-an-existing-project","text":"Once the project is successfully created, a summary screen of the project will be presented. Take the following steps to add the remaining substation transformers to the project. Value: The RE can add additional assets to a project at any time. Follow the prompt on the left navigation panel to return to the Assets view, and to the list of substation transformers. If this does not direct to the list of substation transformers, follow the previous steps to produce that list. From the resulting list, click through to page 2 of the substation transformer list. Select the remaining substation transformers (in bold): ST_1393137 ST_1400501 ST_1400502 ST_1400517 ST_1400518 Click Add to investment project . In this case, it is the final 2 substation transformers on the following list. From the Add to the investment project popup, select the lab to which these assets will be added, in this case AIO Lab , and press Add . A popup will show that the assets are being added to the project, and the Edit project page will appear. Click Save at the bottom of the page. An additional popup will appear as a reminder that adding additional assets to an existing project will invalidate previous results. Click Save to confirm and proceed.","title":"Add Assets to an Existing Project"},{"location":"asset_investment/#create-a-replacement-plan-template","text":"A replacement plan is required for each asset is the project. The assets must either have unique replacement plans, or all of the asset types in the project (in this case, substation transformer) must have replacement plan templates. Value: If an asset exhibits characteristics different from the other assets in its type, or a plan has already been developed for the asset, the asset can still be included in a project using its unique replacement plan. Navigate to the Asset investment optimizer using the left navigation bar. From the Asset investment optimizer page, select Plan templates . On the Plan templates page, select an existing template OR click the + symbol to create a new one. In this case, select substation transformers since there is already a replacement plan template created. The only additional step required when creating a new template is to identify the asset type. On the Edit a replacement plan template , complete the required fields as follows. Expected downtime in hours: 4 Estimated capital cost: $15,000 Estimated operation cost: $20,000 Estimated failure cost: $23,000 Expected life in years: 50 Then click Save . If prompted to Confirm edit , press Continue .","title":"Create a Replacement Plan Template"},{"location":"asset_investment/#evaluate-investment-options","text":"","title":"Evaluate Investment Options"},{"location":"asset_investment/#edit-an-aio-project","text":"A project can be adjusted at any time. However, making changes will invalidate any investment strategies that have already been executed against the project. After the changes are made, the strategies must be run again. Value: Once a project is created, changes like adjusting assets, the length of the project, and when it starts, can be made at any time. The RE does not need to create a new project. From the Asset investment optimizer page, select the Project tab. Select the project AIO Lab . From the AIO Lab project page, select the pencil icon to review the details of the project. Review the details of the project, and make any required adjustments. In this case, no changes are required. Press Cancel . If changes are made, an additional popup will appear as a reminder that changes to an existing project will invalidate previous results. Click Save to confirm and proceed.","title":"Edit an AIO Project"},{"location":"asset_investment/#maintain-risk-aio-project","text":"The first strategy, maintain risk, determines which assets need to be replaced, and when, in order to maintain the average risk of the project over the life of the project. The average risk is the average of the individual assets in the project. Value: The maintain risk strategy sets a business as usual baseline, to which other strategies can be compared. Action: On the main AIO Lab project page, the maintain risk strategy will already be available and selected in the left column. The average risk score will be calculated. In this case, it is 42. Select the Run analysis button to execute the strategy. The analysis may take some time to run, during which there will be indicators. The results will automatically appear in the report view. In this case, 4 of the 5 assets must be replaced for a total cost of $140,000, with an average risk score of 17.2, and the highest risk score of 31.7 for the duration. Select the table view to see which assets need to be replaced, and when.","title":"Maintain Risk AIO Project"},{"location":"asset_investment/#reduce-risk-aio-project","text":"The reduce risk strategy allows the RE to select the average risk score for the project. The strategy will determine which assets need to be replaced, and when, in order to maintain the desired risk of the project over the life of the project. Value: The reduce risk strategy allows the RE to adjust the risk of the project based on their risk tolerance. From the main AIO Lab project page, in this case from the table view, click on the + symbol to add a new strategy. From the pop up box, use the pull down menu to select Reduce risk . From the next pop up box, enter a risk value of 10 , the click Create . On the main AIO Lab project page, the reduce risk strategy will be available and selected in the left column, above the last strategy executed, in this case, the maintain risk strategy. Select the Run analysis button to execute the strategy. Once again, the analysis may take some time to run, during which there will be indicators. The results will automatically appear in the report view. In this case, all 5 assets must be replaced for a total cost of $175,000, with an average risk score of 8.0, and the highest risk score of 19.1 for the duration. Select the table view to see which assets need to be replaced, and when. Note Multiple reduce risk strategies can be created using different target risk scores.","title":"Reduce Risk AIO Project:"},{"location":"asset_investment/#stay-in-budget-aio-project","text":"The stay in budget strategy allows the RE to set a budget for the project. The strategy will determine which assets need to be replaced, and when, in order to stick to a budget for the project. Value: The stay in budget strategy allows the RE to adjust the budget for the project based on the available budget. Action: From the main AIO Lab project page, in this case from the table view, click on the + symbol to add a new strategy. From the pop up box, use the pull down menu to select Stay in budget . From the next pop up box, enter the following values below and the click Create . Capex: 60,000 Opex: 80,000 Total budget: 140,000 On the main AIO Lab project page, the stay in budget strategy will be available and selected in the left column, above the last strategy executed, in this case, the reduce risk strategy. Select the Run analysis button to execute the strategy. Once again, the analysis may take some time to run, during which there will be indicators. The results will automatically appear in the report view. In this case, 4 of the 5 assets must be replaced for a total cost of $140,000, with an average risk score of 17.2, and the highest risk score of 31.7 for the duration. Select the list view to see which assets need to be replace, and when. Note Multiple stay in budget strategies can be created using different budgets.","title":"Stay in Budget AIO Project"},{"location":"asset_investment/#comparing-investment-strategies","text":"Within each AIO project, the RE can compare up to three strategies. Since the RE can create multiple reduce risk and stay in budget strategies, the RE can compare any combination of strategies. In this case, the comparison will be the maintain risk, reduce risk, and stay in budget strategies. Value: The comparison capability gives the RE an easy view to identify which strategy meets their needs, and export the details. From the main AIO Lab project page, in this case from the table view, click on the Compare strategies button. From the popup, select all three strategies, press Create . The resulting comparison provides key information for the RE to decide which strategy to pursue. To export details from one of the strategies, click export at the bottom of one of the strategies. In this case, select Maintain risk. From the Export Data popup, select analysis report, and click Export . Open the results in an application, or save it. The analysis report will show a summary of the selected strategy. Selecting Details for recommended replacements will produce details of the strategy.","title":"Comparing Investment Strategies"},{"location":"asset_investment/#summary","text":"The data presented in this lab is intended to demonstrate the AIO capabilities, and the results may not accurately reflect real-world scenarios. Note that strategies are highly sensitive and dependent on multiple factors like End of Life and information in the Replacement plan template. It may be necessary to experiment to get satisfactory results. Clean up From the breadcrumbs (or from the left navigation bar), select the Asset Investment Optimizer. On the Project tabs, hover the cursor to the far right of the project name, and select Delete when it appears. When prompted, confirm the deletion of the project. Congratulations. You now have identified at risk assets and have added them to an asset investment optimization project to improve their condition.","title":"Summary"},{"location":"data_dictionary/","text":"Pump Data Dictionary In this exercise you will: Understand the Asset Data that will be used in these labs for each exercise. Note This lab is still being developed, incomplete and may have errors. We provide it to get your feedback and allow you to reference the materials as the labs are built. Understand Asset Data This lab uses publicly available data for a centrifugal pump on Kaggle.com The data is for a single pump that exhibited 7 failures. The table below describes the columns with sensor time series data that are included in the CSV files. See the Kaggle web site for more explanation of the data. Metric Name Description SENSOR_00 Motor Casing Vibration SENSOR_01 Motor Frequency A SENSOR_02 Motor Frequency B SENSOR_03 Motor Frequency C SENSOR_04 Motor Speed SENSOR_05 Motor Current SENSOR_06 Motor Active Power SENSOR_07 Motor Apparent Power SENSOR_08 Motor Reactive Power SENSOR_09 Motor Shaft Power SENSOR_10 Motor Phase Current A SENSOR_11 Motor Phase Current B SENSOR_12 Motor Phase Current C SENSOR_13 Motor Coupling Vibration SENSOR_14 Motor Phase Voltage AB SENSOR_16 Motor Phase Voltage BC SENSOR_17 Motor Phase Voltage CA SENSOR_18 Pump Casing Vibration SENSOR_19 Pump Stage 1 Impeller Speed SENSOR_20 Pump Stage 1 Impeller Speed SENSOR_21 Pump Stage 1 Impeller Speed SENSOR_22 Pump Stage 1 Impeller Speed SENSOR_23 Pump Stage 1 Impeller Speed SENSOR_24 Pump Stage 1 Impeller Speed SENSOR_25 Pump Stage 2 Impeller Speed SENSOR_26 Pump Stage 2 Impeller Speed SENSOR_27 Pump Stage 2 Impeller Speed SENSOR_28 Pump Stage 2 Impeller Speed SENSOR_29 Pump Stage 2 Impeller Speed SENSOR_30 Pump Stage 2 Impeller Speed SENSOR_31 Pump Stage 2 Impeller Speed SENSOR_32 Pump Stage 2 Impeller Speed SENSOR_33 Pump Stage 2 Impeller Speed SENSOR_34 Pump Inlet Flow SENSOR_35 Pump Discharge Flow SENSOR_36 Pump UNKNOWN SENSOR_37 Pump Lube Oil Overhead Reservoir Level SENSOR_38 Pump Lube Oil Return Temp SENSOR_39 Pump Lube Oil Supply Temp SENSOR_40 Pump Thrust Bearing Active Temp SENSOR_41 Motor Non Drive End Radial Bearing Temp 1 SENSOR_42 Motor Non Drive End Radial Bearing Temp 2 SENSOR_43 Pump Thrust Bearing Inactive Temp SENSOR_44 Pump Drive End Radial Bearing Temp 1 SENSOR_45 Pump non Drive End Radial Bearing Temp 1 SENSOR_46 Pump Non Drive End Radial Bearing Temp 2 SENSOR_47 Pump Drive End Radial Bearing Temp 2 SENSOR_48 Pump Inlet Pressure SENSOR_49 Pump Temp Unknown SENSOR_50 Pump Discharge Pressure 1 SENSOR_51 Pump Discharge Pressure 2 machine_status NORMAL, BROKEN or RECOVERING Congratulations. You now have sample pump data you can work with to analyze for anomalies and failures. In a later lab exercise you will prepare the data for being used by Health and Predict for algorithm and model performance assessment using Watson Studio.","title":"Pump Data Dictionary"},{"location":"data_dictionary/#pump-data-dictionary","text":"In this exercise you will: Understand the Asset Data that will be used in these labs for each exercise. Note This lab is still being developed, incomplete and may have errors. We provide it to get your feedback and allow you to reference the materials as the labs are built.","title":"Pump Data Dictionary"},{"location":"data_dictionary/#understand-asset-data","text":"This lab uses publicly available data for a centrifugal pump on Kaggle.com The data is for a single pump that exhibited 7 failures. The table below describes the columns with sensor time series data that are included in the CSV files. See the Kaggle web site for more explanation of the data. Metric Name Description SENSOR_00 Motor Casing Vibration SENSOR_01 Motor Frequency A SENSOR_02 Motor Frequency B SENSOR_03 Motor Frequency C SENSOR_04 Motor Speed SENSOR_05 Motor Current SENSOR_06 Motor Active Power SENSOR_07 Motor Apparent Power SENSOR_08 Motor Reactive Power SENSOR_09 Motor Shaft Power SENSOR_10 Motor Phase Current A SENSOR_11 Motor Phase Current B SENSOR_12 Motor Phase Current C SENSOR_13 Motor Coupling Vibration SENSOR_14 Motor Phase Voltage AB SENSOR_16 Motor Phase Voltage BC SENSOR_17 Motor Phase Voltage CA SENSOR_18 Pump Casing Vibration SENSOR_19 Pump Stage 1 Impeller Speed SENSOR_20 Pump Stage 1 Impeller Speed SENSOR_21 Pump Stage 1 Impeller Speed SENSOR_22 Pump Stage 1 Impeller Speed SENSOR_23 Pump Stage 1 Impeller Speed SENSOR_24 Pump Stage 1 Impeller Speed SENSOR_25 Pump Stage 2 Impeller Speed SENSOR_26 Pump Stage 2 Impeller Speed SENSOR_27 Pump Stage 2 Impeller Speed SENSOR_28 Pump Stage 2 Impeller Speed SENSOR_29 Pump Stage 2 Impeller Speed SENSOR_30 Pump Stage 2 Impeller Speed SENSOR_31 Pump Stage 2 Impeller Speed SENSOR_32 Pump Stage 2 Impeller Speed SENSOR_33 Pump Stage 2 Impeller Speed SENSOR_34 Pump Inlet Flow SENSOR_35 Pump Discharge Flow SENSOR_36 Pump UNKNOWN SENSOR_37 Pump Lube Oil Overhead Reservoir Level SENSOR_38 Pump Lube Oil Return Temp SENSOR_39 Pump Lube Oil Supply Temp SENSOR_40 Pump Thrust Bearing Active Temp SENSOR_41 Motor Non Drive End Radial Bearing Temp 1 SENSOR_42 Motor Non Drive End Radial Bearing Temp 2 SENSOR_43 Pump Thrust Bearing Inactive Temp SENSOR_44 Pump Drive End Radial Bearing Temp 1 SENSOR_45 Pump non Drive End Radial Bearing Temp 1 SENSOR_46 Pump Non Drive End Radial Bearing Temp 2 SENSOR_47 Pump Drive End Radial Bearing Temp 2 SENSOR_48 Pump Inlet Pressure SENSOR_49 Pump Temp Unknown SENSOR_50 Pump Discharge Pressure 1 SENSOR_51 Pump Discharge Pressure 2 machine_status NORMAL, BROKEN or RECOVERING Congratulations. You now have sample pump data you can work with to analyze for anomalies and failures. In a later lab exercise you will prepare the data for being used by Health and Predict for algorithm and model performance assessment using Watson Studio.","title":"Understand Asset Data"},{"location":"data_preparation/","text":"Data Preparation and Loading Using Notebooks In this exercise you will use Predict libraries and notebook in Watson Studio to: Download Pump Data and Import into Watson Studio Notebook from Kaggle website Add the data prepration notebook template included with this lab to prepare the pump data. Create an asset information file to describe the pump used in later exercises for EOL Curve algorithm. Create an asset metrics file used to train and test the Failure Prediction Date algorithm. Create an asset failure file used to train and test the Failure Prediction Date algorithm. Note Be sure to prepend your initials on all the data asset files you create in this exercise so that you can be sure you are creating the files correctly. Download Pump Data and Import to Watson Studio Notebook Download data from Kaggle . Name the file kaggle-pump-sensor.csv . If the file is already present in your project you can skip this step. Click on Assets tab. Click on Add to Project button. Select Data . Browse to and select the CSV file you downloaded from the Kaggle Web site. Alternatively just drag the CSV file into data asset project on the right. Add the Data Preparation Notebook to Watson Studio Data preparation involves cleaning data, reshaping the data columns and rows into the format and values needed for each notebook template. In some cases it involves removing rows or columns that have invalid or blank values (NaN). Or imputing values to replace blank values (NaN). The data preparation notebook has already been created for you for use. Use the steps from the previous exercises Add Notebook From File to a Watson Studio Project to add the data_preparation.ipynb to your Watson Studio Project or the Project suggested by your facilitator. Rename your notebook by pre-pending your initials to the notebook. Use the steps below to understand or recreate the notebook yourself. Create a new notebook from file to prepare the date to be used by Predict for predicting failures. Browse to open the ./notebooks/data_preparation.ipynb be sure to pre-pend your initials and pick the v4CPU Python 3.8 environment. Study each notebook cell in the data_preparation notebook. The first cell loads needed libraries to process the data using Pandas and Numpy which are open source libraries used to analyze and process timeseries data. The explanation of these libraries is outside the scope of this lab and is a pre-requisite. Sample Code import pandas as pd import numpy as np import time import sys The next cell sets the display values to be able to see the data tables and logs in the Jupyter notebook for df head() Sample Code pd.set_option('display.max_columns', None) pd.set_option('max_colwidth', 1000) pd.set_option('max_rows', 100) pd.set_option('display.max_rows', 100) pd.set_option('display.max_columns', 100) Insert the code to load the kaggle-pump-sensor.csv that you uploaded earlier in the exercise. Click on the code generator icon at the top of Watson Studio. Click on the kaggle-pump-sensor.csv file you downloaded earlier and named kaggle-pump-sensor.csv . The code is inserted into a new cell below where you are currently active. Set Environment Variables Set the environment variables you will use throughout data preparation. See Setup Watson Studio for how to find these values. Sample Code ASSET_ID = ID of each asset ie pump in your CSV files. APM_ID = Value for the mxe.PMIId system property. | Used to train and score all notebooks | APM_API_BASEURL = Root of the URL value for the PREDICTAPI endpoint. | Used to train and score all notebooks | EXTERNAL_APM_API_BASEURL = Route location for the Predict project retrieved from the Red Hat\u00ae OpenShift\u00ae Container Platform. | Used to download the notebooks | APM_API_KEY = API Key to make secure programmatic calls to APM import os os.environ['ASSET_ID'] = 'your_asset_id' os.environ['APM_ID'] = 'your_APM_ID' os.environ['APM_API_BASEURL'] = 'your_https://main.fake.suite.maximo.com/maximo/' os.environ['EXTERNAL_APM_API_BASEURL'] = 'your_https://main.fake.maximo.com/maximo/' os.environ['APM_API_KEY'] = 'your_APM_API_KEY' Verify Environment Variables You can check the environment variables and reference them by using the auto insert code in Watson Studio. Click on the code generator icon at the top of Watson Studio. Click on the sensor data csv file you loaded earlier and nameed 'kaggle-pump-sensor.csv' Prepare Asset Information Data The Asset Information file is used for End Of Life Curve. This step can be skipped if you don't want to create an End of Life Curve in Predict. You must load metadata describing your asset and meter data describing the timeseries metrics and failure dates. There are 3 files needed. Each file is described below. To load asset data into Health you must have asset date. an anomaly model or failure prediction model using Predict you must include For model training using Predict you must include this file. If you are using Health and have an existing installation of Manage Asset information data is time series data that should have the following column formats: Column Name Description asset_id String that is the unique asset identifier like ST_1393137 installation_date String for timestamp of reading Predict supports formats like date 1998-03-28 or date time 2008-01-08 00:00:00 decommission_date String for timestamp of reading Predict supports formats like 2008-01-08 00:00:00 Example CSV File: asset_id,installation_date,decommission_date ST_1393137,1998-03-28, ST_1393138,1999-03-28, ST_1400501,2002-01-01, ST_1400502,1978-01-01, ST_1400503,1988-01-01,2017-01-01 ST_1400504,1972-02-01,2013-09-01 ST_1400505,1978-04-01,2018-09-01 ST_1400506,1985-12-01,2000-09-01 ST_1400507,1990-01-01,2020-09-01 ST_1400508,1982-12-01,2021-01-01 ST_1400517,2004-05-29, ST_1400518,2001-01-26, ST_1400519,2004-03-11, Create an Asset Information File Create an asset information file for the pump data. Since the Kaggle pump data is for a single pump you can create a file with a single asset. Since the pump data doesn't have asset decommission dates you can leave them blank. In this step you will create the CSV file and save it to your project assets in Watson Studio. You will use a Watson Studio Python library named ibm_watson_studio_lib that is available in your environment by default. See this API reference for more information. Sample Code: ASSET_INFO_FILE = \"pumps_asset_info.csv\" asset_info_list = [ ['pump_00',pd.Timestamp('2008-01-08'),\"\"]] df_asset_info = pd.DataFrame(asset_info_list, columns=['asset_id','installation_date','decommission_date']) print(df_asset_info) from ibm_watson_studio_lib import access_project_or_space wslib = access_project_or_space() wslib.save_data(ASSET_INFO_FILE, df_asset_info.to_csv(index=False).encode()) Example CSV File that will be created: asset_id,installation_date,decommission_date pump_00,2008-01-08, Prepare Asset Metrics Data Asset metrics data is time series data that must have the following column formats: Column Name Description timestamp String for timestamp of reading Predict supports like YYYY-MM-DD HH:MM:SS 2008-01-08 00:00:00 asset_id String that is the unique asset identifier like ST_1393137 replace_with_your_metric_name String, float, integer values for the metric name that has time series value of the metric. Add columns for each deviceid The device identifier for the pump devices pump00 and pump01 devicetype Type of device or asset type. For example SubmersiblePump Example CSV File: timestamp, asset_id,VELOCITYX,VELOCITYY,VELOCITYZ,MOTORTEMP,WINDINGTEMP,CURRENT,PRESSURE,LOAD,deviceid,devicetype 2008-01-08 00:00:00,ST_1393137,2.789723591922755e-05,1.6746073164430882e-05,8.339162527937205e-05,100.83577170779785,44.35493000421977,248.35431420298488,236.06861760559738,119.19549771099527,ST_1393137,Pump 2008-01-08 00:00:00,ST_1400503,1.8955077909665885e-05,5.310167683286737e-05,4.929701336603421e-05,117.40003242411258,59.44633346537405,198.43270265068318,135.58041388401696,363.32438733010264,ST_1400503,Pump 2008-01-08 00:00:00,ST_1393138,5.383833971733809e-05,8.621918766532621e-05,0.00022628816228392745,56.84127240243945,85.39674348536191,320.10652050792254,116.96629884075016,348.63962293620796,ST_1393138,Pump 2008-01-08 00:00:00,ST_1400504,0.0001924944000548656,1.1741761162809006e-06,8.175834516599423e-05,119.5450558945755,94.7939330989897,236.70840492432868,32.6440692097963,312.4522186383818,ST_1400504,Pump 2008-01-08 00:00:00,ST_1400501,0.003545132038944409,6.876746074246931e-07,0.0036784498219412103,45.59886793076733,23.05892702945967,286.74721509016484,180.20107874577167,231.70223738465447,ST_1400501,Pump 2008-01-08 00:05:00,ST_1400504,0.00019302373395002626,0.00016932421485671423,0.00013430225226540582,190.6814045868194,37.57188465045573,137.3792392640947,299.6397304979968,159.14737257788806,ST_1400504,Pump 2008-01-08 00:05:00,ST_1400503,2.0484241964768835e-05,0.00010325648402054188,5.190215923800423e-05,54.63392121323369,36.27128188087939,300.653034213001,255.42177133667667,354.67651009829115,ST_1400503,Pump 2008-01-08 00:05:00,ST_1393137,6.366443036021074e-05,7.064831711578456e-05,0.00011524493308429085,54.97140429029558,38.663214620823275,227.54222031273997,156.7913987644162,130.128691037622,ST_1393137,Pump 2008-01-08 00:05:00,ST_1393138,0.00013067224960744417,0.0008823036374320248,0.00032697196744563284,93.54844644228176,1.0334067253278365,201.09726853381162,177.26721567826152,464.38594263559753,ST_1393138,Pump 2008-01-08 00:05:00,ST_1400501,0.006280909664161449,0.0010025129547774347,0.004949649433126646,120.43190732195221,56.22655349254132,103.56854139558924,149.58631977664385,327.4758640952711,ST_1400501,Pump 2008-01-08 00:10:00,ST_1400504,0.00020046116700583871,0.00023040699143567206,0.00019016599105797782,26.21601912040133,17.065778325053998,283.1600018147578,83.84456591349925,214.12986021619156,ST_1400504,Pump 2008-01-08 00:10:00,ST_1393137,7.602581095239591e-05,7.9852673251668e-05,0.00012796988361707395,34.50644451498961,71.16775071874916,187.36661322063892,213.0005900404975,78.99669369869281,ST_1393137,Pump 2008-01-08 00:10:00,ST_1400503,8.657794445832145e-05,0.00013001986273436517,7.091561697253335e-05,74.35723049281981,48.2234783756648,126.26599720968146,177.59628306468898,258.13878219243736,ST_1400503,Pump 2008-01-08 00:10:00,ST_1400501,0.010575435663603527,0.0014778309163699932,0.005209847134218125,98.86547795829622,36.977105925193136,178.05030077180396,79.52583077900974,243.4138352490094,ST_1400501,Pump Create an Asset Metrics File Since the Kaggle pump data is for a single pump you can create a file with a single asset. Since the pump data doesn't have decommission dates you can leave them blank. Also since not all the columns are needed to make a failure prediction we can reduce the columns down to the minimum number. Reduce the 'data_df_1' that you read in earlier and add the required columns for ASSET_ID , deviceid , devicetype . Select only the columns that are needed for pump predicting failure. Sample Code: pump_df = data_df_1[['timestamp','sensor_10', 'sensor_04','sensor_02', 'sensor_12','sensor_05', 'sensor_00','sensor_11', 'sensor_13','sensor_06', 'sensor_01','sensor_09', 'sensor_26']] Assign constant values for the columns that are needed for pump predicting failure for asset_id , deviceid and devicetype Sample Code: print(os.getenv('ASSET_ID')) # Add a column for deviceType DeviceID and Asset_ID pump_df['asset_id'] = os.getenv('ASSET_ID') pump_df['deviceid'] = os.getenv('ASSET_ID') pump_df['devicetype'] = os.getenv('DEVICE_TYPE') pump_df.head() Prepare Asset Failure Data Asset failure data is time series data that describes when the asset failure periods happen. Asset failure data must have the column formats in the table below. The failure dates includes the failure CSV data which identifies the start and end of failure dates for each asset id with the following columns: Column Name Description fail_date String for timestamp of day 2008-01-08 and day-time 2008-01-08 00:10:00 that the asset failed. asset_id String that is the unique asset identifier like ST_1393137 description String,describes the failure cause or condition. failure_code String that identifies the fault. problem_code String that desribes the problem code for troubleshooting. site_id String of where the asset is located failure_record Integer that identifies the Manage record identifier failure instance of failure types. Example CSV File: fail_date,asset_id,description,failure_code,problem_code,site_id,failure_record 2008-01-08,ST_1393137,Pump stopped due to failure,PUMPS,STOPPED,DIST1,1 2008-02-10,ST_1393137,Pump stopped due to failure,PUMPS,STOPPED,DIST1,1 2008-03-11,ST_1393137,Pump stopped due to failure,PUMPS,STOPPED,DIST1,1 2008-04-09,ST_1393137,Pump stopped due to failure,PUMPS,STOPPED,DIST1,1 2008-05-06,ST_1393137,Pump stopped due to failure,PUMPS,STOPPED,DIST1,1 2008-05-18,ST_1393137,Pump stopped due to failure,PUMPS,STOPPED,DIST1,1 2008-06-04,ST_1393137,Pump stopped due to failure,PUMPS,STOPPED,DIST1,1 2008-06-30,ST_1393137,Pump stopped due to failure,PUMPS,STOPPED,DIST1,1 2008-01-24,ST_1393138,Pump stopped due to failure,PUMPS,STOPPED,DIST1,1 Create an Asset Failure File Create an asset failure file for the pump data. Since the Kaggle pump data is for a single pump you can create a file with a single asset. Since the pump data doesn't have asset decommission dates you can leave them blank. In this step you will create the CSV file and save it to your project assets in Watson Studio. You will use a Watson Studio Python library named ibm_watson_studio_lib that is available in your environment by default. See this API reference for more information. Review the code cells to understand how to drop columns and add columns to using Pandas to create the right format for the Asset Failure CSV file. Congratulations. You now have the pump data files in the files and format required for evaluating algorithm and prediction performance in the next exercises.","title":"Data Preparation"},{"location":"data_preparation/#data-preparation-and-loading-using-notebooks","text":"In this exercise you will use Predict libraries and notebook in Watson Studio to: Download Pump Data and Import into Watson Studio Notebook from Kaggle website Add the data prepration notebook template included with this lab to prepare the pump data. Create an asset information file to describe the pump used in later exercises for EOL Curve algorithm. Create an asset metrics file used to train and test the Failure Prediction Date algorithm. Create an asset failure file used to train and test the Failure Prediction Date algorithm. Note Be sure to prepend your initials on all the data asset files you create in this exercise so that you can be sure you are creating the files correctly.","title":"Data Preparation and Loading Using Notebooks"},{"location":"data_preparation/#download-pump-data-and-import-to-watson-studio-notebook","text":"Download data from Kaggle . Name the file kaggle-pump-sensor.csv . If the file is already present in your project you can skip this step. Click on Assets tab. Click on Add to Project button. Select Data . Browse to and select the CSV file you downloaded from the Kaggle Web site. Alternatively just drag the CSV file into data asset project on the right.","title":"Download Pump Data and Import to Watson Studio Notebook"},{"location":"data_preparation/#add-the-data-preparation-notebook-to-watson-studio","text":"Data preparation involves cleaning data, reshaping the data columns and rows into the format and values needed for each notebook template. In some cases it involves removing rows or columns that have invalid or blank values (NaN). Or imputing values to replace blank values (NaN). The data preparation notebook has already been created for you for use. Use the steps from the previous exercises Add Notebook From File to a Watson Studio Project to add the data_preparation.ipynb to your Watson Studio Project or the Project suggested by your facilitator. Rename your notebook by pre-pending your initials to the notebook. Use the steps below to understand or recreate the notebook yourself. Create a new notebook from file to prepare the date to be used by Predict for predicting failures. Browse to open the ./notebooks/data_preparation.ipynb be sure to pre-pend your initials and pick the v4CPU Python 3.8 environment. Study each notebook cell in the data_preparation notebook. The first cell loads needed libraries to process the data using Pandas and Numpy which are open source libraries used to analyze and process timeseries data. The explanation of these libraries is outside the scope of this lab and is a pre-requisite. Sample Code import pandas as pd import numpy as np import time import sys The next cell sets the display values to be able to see the data tables and logs in the Jupyter notebook for df head() Sample Code pd.set_option('display.max_columns', None) pd.set_option('max_colwidth', 1000) pd.set_option('max_rows', 100) pd.set_option('display.max_rows', 100) pd.set_option('display.max_columns', 100) Insert the code to load the kaggle-pump-sensor.csv that you uploaded earlier in the exercise. Click on the code generator icon at the top of Watson Studio. Click on the kaggle-pump-sensor.csv file you downloaded earlier and named kaggle-pump-sensor.csv . The code is inserted into a new cell below where you are currently active.","title":"Add the Data Preparation Notebook to Watson Studio"},{"location":"data_preparation/#set-environment-variables","text":"Set the environment variables you will use throughout data preparation. See Setup Watson Studio for how to find these values. Sample Code ASSET_ID = ID of each asset ie pump in your CSV files. APM_ID = Value for the mxe.PMIId system property. | Used to train and score all notebooks | APM_API_BASEURL = Root of the URL value for the PREDICTAPI endpoint. | Used to train and score all notebooks | EXTERNAL_APM_API_BASEURL = Route location for the Predict project retrieved from the Red Hat\u00ae OpenShift\u00ae Container Platform. | Used to download the notebooks | APM_API_KEY = API Key to make secure programmatic calls to APM import os os.environ['ASSET_ID'] = 'your_asset_id' os.environ['APM_ID'] = 'your_APM_ID' os.environ['APM_API_BASEURL'] = 'your_https://main.fake.suite.maximo.com/maximo/' os.environ['EXTERNAL_APM_API_BASEURL'] = 'your_https://main.fake.maximo.com/maximo/' os.environ['APM_API_KEY'] = 'your_APM_API_KEY'","title":"Set Environment Variables"},{"location":"data_preparation/#verify-environment-variables","text":"You can check the environment variables and reference them by using the auto insert code in Watson Studio. Click on the code generator icon at the top of Watson Studio. Click on the sensor data csv file you loaded earlier and nameed 'kaggle-pump-sensor.csv'","title":"Verify Environment Variables"},{"location":"data_preparation/#prepare-asset-information-data","text":"The Asset Information file is used for End Of Life Curve. This step can be skipped if you don't want to create an End of Life Curve in Predict. You must load metadata describing your asset and meter data describing the timeseries metrics and failure dates. There are 3 files needed. Each file is described below. To load asset data into Health you must have asset date. an anomaly model or failure prediction model using Predict you must include For model training using Predict you must include this file. If you are using Health and have an existing installation of Manage Asset information data is time series data that should have the following column formats: Column Name Description asset_id String that is the unique asset identifier like ST_1393137 installation_date String for timestamp of reading Predict supports formats like date 1998-03-28 or date time 2008-01-08 00:00:00 decommission_date String for timestamp of reading Predict supports formats like 2008-01-08 00:00:00 Example CSV File: asset_id,installation_date,decommission_date ST_1393137,1998-03-28, ST_1393138,1999-03-28, ST_1400501,2002-01-01, ST_1400502,1978-01-01, ST_1400503,1988-01-01,2017-01-01 ST_1400504,1972-02-01,2013-09-01 ST_1400505,1978-04-01,2018-09-01 ST_1400506,1985-12-01,2000-09-01 ST_1400507,1990-01-01,2020-09-01 ST_1400508,1982-12-01,2021-01-01 ST_1400517,2004-05-29, ST_1400518,2001-01-26, ST_1400519,2004-03-11,","title":"Prepare Asset Information Data"},{"location":"data_preparation/#create-an-asset-information-file","text":"Create an asset information file for the pump data. Since the Kaggle pump data is for a single pump you can create a file with a single asset. Since the pump data doesn't have asset decommission dates you can leave them blank. In this step you will create the CSV file and save it to your project assets in Watson Studio. You will use a Watson Studio Python library named ibm_watson_studio_lib that is available in your environment by default. See this API reference for more information. Sample Code: ASSET_INFO_FILE = \"pumps_asset_info.csv\" asset_info_list = [ ['pump_00',pd.Timestamp('2008-01-08'),\"\"]] df_asset_info = pd.DataFrame(asset_info_list, columns=['asset_id','installation_date','decommission_date']) print(df_asset_info) from ibm_watson_studio_lib import access_project_or_space wslib = access_project_or_space() wslib.save_data(ASSET_INFO_FILE, df_asset_info.to_csv(index=False).encode()) Example CSV File that will be created: asset_id,installation_date,decommission_date pump_00,2008-01-08,","title":"Create an Asset Information File"},{"location":"data_preparation/#prepare-asset-metrics-data","text":"Asset metrics data is time series data that must have the following column formats: Column Name Description timestamp String for timestamp of reading Predict supports like YYYY-MM-DD HH:MM:SS 2008-01-08 00:00:00 asset_id String that is the unique asset identifier like ST_1393137 replace_with_your_metric_name String, float, integer values for the metric name that has time series value of the metric. Add columns for each deviceid The device identifier for the pump devices pump00 and pump01 devicetype Type of device or asset type. For example SubmersiblePump Example CSV File: timestamp, asset_id,VELOCITYX,VELOCITYY,VELOCITYZ,MOTORTEMP,WINDINGTEMP,CURRENT,PRESSURE,LOAD,deviceid,devicetype 2008-01-08 00:00:00,ST_1393137,2.789723591922755e-05,1.6746073164430882e-05,8.339162527937205e-05,100.83577170779785,44.35493000421977,248.35431420298488,236.06861760559738,119.19549771099527,ST_1393137,Pump 2008-01-08 00:00:00,ST_1400503,1.8955077909665885e-05,5.310167683286737e-05,4.929701336603421e-05,117.40003242411258,59.44633346537405,198.43270265068318,135.58041388401696,363.32438733010264,ST_1400503,Pump 2008-01-08 00:00:00,ST_1393138,5.383833971733809e-05,8.621918766532621e-05,0.00022628816228392745,56.84127240243945,85.39674348536191,320.10652050792254,116.96629884075016,348.63962293620796,ST_1393138,Pump 2008-01-08 00:00:00,ST_1400504,0.0001924944000548656,1.1741761162809006e-06,8.175834516599423e-05,119.5450558945755,94.7939330989897,236.70840492432868,32.6440692097963,312.4522186383818,ST_1400504,Pump 2008-01-08 00:00:00,ST_1400501,0.003545132038944409,6.876746074246931e-07,0.0036784498219412103,45.59886793076733,23.05892702945967,286.74721509016484,180.20107874577167,231.70223738465447,ST_1400501,Pump 2008-01-08 00:05:00,ST_1400504,0.00019302373395002626,0.00016932421485671423,0.00013430225226540582,190.6814045868194,37.57188465045573,137.3792392640947,299.6397304979968,159.14737257788806,ST_1400504,Pump 2008-01-08 00:05:00,ST_1400503,2.0484241964768835e-05,0.00010325648402054188,5.190215923800423e-05,54.63392121323369,36.27128188087939,300.653034213001,255.42177133667667,354.67651009829115,ST_1400503,Pump 2008-01-08 00:05:00,ST_1393137,6.366443036021074e-05,7.064831711578456e-05,0.00011524493308429085,54.97140429029558,38.663214620823275,227.54222031273997,156.7913987644162,130.128691037622,ST_1393137,Pump 2008-01-08 00:05:00,ST_1393138,0.00013067224960744417,0.0008823036374320248,0.00032697196744563284,93.54844644228176,1.0334067253278365,201.09726853381162,177.26721567826152,464.38594263559753,ST_1393138,Pump 2008-01-08 00:05:00,ST_1400501,0.006280909664161449,0.0010025129547774347,0.004949649433126646,120.43190732195221,56.22655349254132,103.56854139558924,149.58631977664385,327.4758640952711,ST_1400501,Pump 2008-01-08 00:10:00,ST_1400504,0.00020046116700583871,0.00023040699143567206,0.00019016599105797782,26.21601912040133,17.065778325053998,283.1600018147578,83.84456591349925,214.12986021619156,ST_1400504,Pump 2008-01-08 00:10:00,ST_1393137,7.602581095239591e-05,7.9852673251668e-05,0.00012796988361707395,34.50644451498961,71.16775071874916,187.36661322063892,213.0005900404975,78.99669369869281,ST_1393137,Pump 2008-01-08 00:10:00,ST_1400503,8.657794445832145e-05,0.00013001986273436517,7.091561697253335e-05,74.35723049281981,48.2234783756648,126.26599720968146,177.59628306468898,258.13878219243736,ST_1400503,Pump 2008-01-08 00:10:00,ST_1400501,0.010575435663603527,0.0014778309163699932,0.005209847134218125,98.86547795829622,36.977105925193136,178.05030077180396,79.52583077900974,243.4138352490094,ST_1400501,Pump","title":"Prepare Asset Metrics Data"},{"location":"data_preparation/#create-an-asset-metrics-file","text":"Since the Kaggle pump data is for a single pump you can create a file with a single asset. Since the pump data doesn't have decommission dates you can leave them blank. Also since not all the columns are needed to make a failure prediction we can reduce the columns down to the minimum number. Reduce the 'data_df_1' that you read in earlier and add the required columns for ASSET_ID , deviceid , devicetype . Select only the columns that are needed for pump predicting failure. Sample Code: pump_df = data_df_1[['timestamp','sensor_10', 'sensor_04','sensor_02', 'sensor_12','sensor_05', 'sensor_00','sensor_11', 'sensor_13','sensor_06', 'sensor_01','sensor_09', 'sensor_26']] Assign constant values for the columns that are needed for pump predicting failure for asset_id , deviceid and devicetype Sample Code: print(os.getenv('ASSET_ID')) # Add a column for deviceType DeviceID and Asset_ID pump_df['asset_id'] = os.getenv('ASSET_ID') pump_df['deviceid'] = os.getenv('ASSET_ID') pump_df['devicetype'] = os.getenv('DEVICE_TYPE') pump_df.head()","title":"Create an Asset Metrics File"},{"location":"data_preparation/#prepare-asset-failure-data","text":"Asset failure data is time series data that describes when the asset failure periods happen. Asset failure data must have the column formats in the table below. The failure dates includes the failure CSV data which identifies the start and end of failure dates for each asset id with the following columns: Column Name Description fail_date String for timestamp of day 2008-01-08 and day-time 2008-01-08 00:10:00 that the asset failed. asset_id String that is the unique asset identifier like ST_1393137 description String,describes the failure cause or condition. failure_code String that identifies the fault. problem_code String that desribes the problem code for troubleshooting. site_id String of where the asset is located failure_record Integer that identifies the Manage record identifier failure instance of failure types. Example CSV File: fail_date,asset_id,description,failure_code,problem_code,site_id,failure_record 2008-01-08,ST_1393137,Pump stopped due to failure,PUMPS,STOPPED,DIST1,1 2008-02-10,ST_1393137,Pump stopped due to failure,PUMPS,STOPPED,DIST1,1 2008-03-11,ST_1393137,Pump stopped due to failure,PUMPS,STOPPED,DIST1,1 2008-04-09,ST_1393137,Pump stopped due to failure,PUMPS,STOPPED,DIST1,1 2008-05-06,ST_1393137,Pump stopped due to failure,PUMPS,STOPPED,DIST1,1 2008-05-18,ST_1393137,Pump stopped due to failure,PUMPS,STOPPED,DIST1,1 2008-06-04,ST_1393137,Pump stopped due to failure,PUMPS,STOPPED,DIST1,1 2008-06-30,ST_1393137,Pump stopped due to failure,PUMPS,STOPPED,DIST1,1 2008-01-24,ST_1393138,Pump stopped due to failure,PUMPS,STOPPED,DIST1,1","title":"Prepare Asset Failure Data"},{"location":"data_preparation/#create-an-asset-failure-file","text":"Create an asset failure file for the pump data. Since the Kaggle pump data is for a single pump you can create a file with a single asset. Since the pump data doesn't have asset decommission dates you can leave them blank. In this step you will create the CSV file and save it to your project assets in Watson Studio. You will use a Watson Studio Python library named ibm_watson_studio_lib that is available in your environment by default. See this API reference for more information. Review the code cells to understand how to drop columns and add columns to using Pandas to create the right format for the Asset Failure CSV file. Congratulations. You now have the pump data files in the files and format required for evaluating algorithm and prediction performance in the next exercises.","title":"Create an Asset Failure File"},{"location":"fast_start_loader/","text":"Load Historical Pump Data Into Monitor Maximo Predict includes notebook templates that you can use to quickly upload your device data and associate them to newly created assets within Maximo. Out of the box, users are provided with a set of notebooks including multiple different Fast Start Data Loaders. These notebooks vary in what type of data they will be uploading into the Maximo System. In this lab, we will be uploading sensor data for new devices, failure data, and new assets. In this exercise you will use Watson Studio, Monitor and Predict to: Upload historical Data using the FastStart Loader notebook template. Run Notebooks to load your device type and device metrics into Monitor and creates Predict groups. Confirm Monitor Data Upload and Prediction Groups Error Handling for data column name format Note You must complete the previous exercise for Data Preparation and Loading Using Notebooks exercise before you start this exercise. Pre-requisites Review Predict documentation for the list of available models . Ensure your MAS Predict environment is running and you have access. Try your server URL that might look something like: https://main.predict.ivt11rel87.ivt.suite.myhost.com/ibm/pmi/service/rest/system/info Upload and Start the Fast Start Data Loader Notebook Upload or open the Fast Start Data Loader template notebook to your Project. These instructions will be based off using the 'FastStart2021-New.ipynb' file. Use the steps from the previous exercise Add Notebook From File to a Watson Studio Project Rename the notebook template by prepending your initials to the template. If you already have uploaded the notebook, open it with Watson Studio. Select the FastStart2021-New.ipynb notebook template that you have renamed with your initials. Open the notebook. Click on the pencil icon next to your notebook If the notebook fails to start, restart it. Click on the i icon , Environment tab, Running status drop down select box and choose Restart Run the Notebook Part 1 - Introduction Run the first cell two cells. These cells are setting up the files required to complete the notebook. Read the introduction for details on the notebook and how it fits into the Maximo Predict process. Ensure that your csv files are uploaded in the requested format. Note that the asset metrics csv file needs to have Asset Id, Install Date and Decommission Date, NOT the site ID. Part 2 - Install the Maximo Predict SDK Ensure you have a 'Predict_Envs.json' file uploaded. If one is not provided, follow the instructions in set up Watson Studio under the 'Get URL' section to gather the APM_ID , APM_API_BASE_URL , and APM_API_KEY to create a JSON file containing the credentials and upload to Watson Studio with your initials prepended to the file name. Run the cell to open the JSON file. If you have created a JSON file with your initials prepended, update f = open('/project_data/data_asset/Predict_Envs.json,) to include your initials on the file name. See example image. Run the following two cells to set up variables required for the environment. Note that both should produce an output without errors similar to main.predict.ivt11rel87.ivt.suite.maximo.com Run the cell to install the pmlib using the pip install command Ensure the output runs without errors. (Warnings are Okay) then run the cell to import pmlib into the project Run the cell to import the additional required libraries Update the following values in the cell with your initials: Change newAssetPrefix = 'New_' to newAssetPrefix = '{initials}_' Change default_device_type = 'Pump_AFM' to default_device_type = '{initials}_Pump_AFM' Change device_ids_oem = ['PMPDEVICE002', 'PMPDEVICE004', 'PMPDEVICE006', 'PMPDEVICE008', 'PMPDEVICE010'] to device_ids_oem = ['{initials}_PMPDEVICE00'] Run the cell and make a note of the resulting output. This will be needed in future notebooks to call your assets. Run the following cell to store the variables just created Run the cell to set the preferred column names for Maximo's system Part 3 - Load the Data Into Dataframes Update asset_installation_decommission_dates_df = pd.read_csv('/project_data/data_asset/asset_installation_decommission_date_afm.csv') to match the filename for your asset information (containing asset id, installation date and decommission date). If your Installation Date column header or your Decommission date column header do not match the values called in this cell ( installation_date and decommission_date ), update to match your column headers. Run the cell to load the asset attributes and ensure the output matches your data. Note that the column headers in the output should match the variables defined in the previous cell. Repeat these steps for each csv file being imported for the remainder of part 3. Note: Not all of these cells are redefining the column headers. If you get errors down the line, you may need to update the column header in the data frame created here. See Update DateFrame Headers . Part 4 - Add Timeshift to Make Data More Recent Run the first cell to view the current date range of the data. Run the second cell to calculate and view the shift in time that will be applied Run the third cell to perform the time shift Run the fourth cell to view the new range of dates for the sensor dataframe Repeat these steps for the remainder of part 4 to perform the timeshift on the failure data Part 5 - Clean up DataFrames Run these two cells to clean up dataframes and reformat to Maximo's standards Part 6 - Delete Existing Data Note This section is REQUIRED if you are refreshing asset data or uploading new data for an existing asset. If you get errors in this section, you may need to update the column header in the data frame created here. See Update DateFrame Headers . Run the first four cells to delete data from Maximo to be replaced. Wait five minutes after the final cell to allow for the data to be fully deleted Run the next two cells to delete the asset group Part 7 - Insert Data The following steps will update the MAS database to include the data from the CSV files. 1. Run the cell to view the DataFrame to be imported and run the following cell to use the pmlib library to create the assets in the list. 2. Run the cell to view the assets attributes that will be imported into MAS. Run the following cell to update those values. 3. Run the cell to view the failure history that will be imported into MAS. Run the following cell to import the failure data. 4. Run the cell to write the function definitions required to create your asset group. Run the following cell to create teh asset group. 5. Run the cell to print the asset group name and the asset group id. Take a note of the results as they may be needed in future notebooks. Run the following cell to store the notebook results Set up the IOT Devices. Update DataFrame columns from [timestamp_col_name, asset_id_col_name, 'VELOCITYX', 'VELOCITYY', 'VELOCITYZ', 'MOTORTEMP', 'WINDINGTEMP', 'CURRENT', 'PRESSURE', 'LOAD', device_id_col_name, device_type_col_name] to match the sensor readings for your asset. For example, the line may now read: sensor_data_afm_df.columns = [asset_id_col_name,timestamp_col_name, 'Current_10', 'Speed_4', 'Frequency_2','Current_12','Current_5', 'Vibration_00', 'Current_11','Vibration_13','Power_6','Vibration_1','Power_9','Speed_26',device_id_col_name, device_type_col_name] Run the cell Click into the next cell In the menu, go to Insert > Cell Above In that cell, insert the following code and run: features_for_training=list(set(list(sensor_data_afm_df.columns))- set(['asset_id','evt_timestamp','deviceid','devicetype'])) features_for_training Update the value of columns to columns=features_for_training Run the cell and ensure there are no errors Run the following cell to import the asset device mappings Continue to part 8 or scroll down to run the final cell to save the results. Part 8 - Add additional Data (Optional) This portion of the notebook is optional. If there is additional data to be uploaded you can use this section and customize the data being sent to MAS and creating scoring data for your assets. These cells would have to be updated for your data. Note Ensure you run the final cell with: store_json = json.dumps(store) project.save_data(\"fast_execution.json\", store_json, overwrite=True) Confirm Data Upload and Prediction Groups Confirm that the historical data was uploaded to Monitor. Confirm that the Prediction group was created and linked to the model notebook template you created. Navigate to Predict within your environment Use the left-hand menu to go into Predict Grouping Ensure your asset group is available in the list and confirm your asset is available within the group. Navigate to IOT within your environment. Under devices , search to ensure your device is there Navigate to Device Types and find your device type. Check that your physical and logical interfaces are active. Navigate to Monitor and ensure your devices have data Error Handling Update DateFrame Header If you receive an object attribute error for pandas, with a column header initialized in Part 2 step 10 listed similar to: Then follow these steps to replace your dataframe header to resolve this error. 1. Click into the cell that resulted in an error. In the menu, go to Insert > Cell Above Rename the columns by adding the following code in the cell: {DataFrame_to_Change}.rename(columns={'{current_column_header}': site_id_col_name}, inplace=True) {DataFrame_to_Change}.head() Run the cell. The output should show the new header in the table. For example: in order to change the failure_data_afm_df column header from 'site' to the preferred header: Congratulations you have loaded historical data and created Predict Groups linking your devices metrics inputs to list of assets and notebook template that will be used to score predictions using Predict with Monitor device data!","title":"Load Pump Data Into Monitor"},{"location":"fast_start_loader/#load-historical-pump-data-into-monitor","text":"Maximo Predict includes notebook templates that you can use to quickly upload your device data and associate them to newly created assets within Maximo. Out of the box, users are provided with a set of notebooks including multiple different Fast Start Data Loaders. These notebooks vary in what type of data they will be uploading into the Maximo System. In this lab, we will be uploading sensor data for new devices, failure data, and new assets. In this exercise you will use Watson Studio, Monitor and Predict to: Upload historical Data using the FastStart Loader notebook template. Run Notebooks to load your device type and device metrics into Monitor and creates Predict groups. Confirm Monitor Data Upload and Prediction Groups Error Handling for data column name format Note You must complete the previous exercise for Data Preparation and Loading Using Notebooks exercise before you start this exercise.","title":"Load Historical Pump Data Into Monitor"},{"location":"fast_start_loader/#pre-requisites","text":"Review Predict documentation for the list of available models . Ensure your MAS Predict environment is running and you have access. Try your server URL that might look something like: https://main.predict.ivt11rel87.ivt.suite.myhost.com/ibm/pmi/service/rest/system/info","title":"Pre-requisites"},{"location":"fast_start_loader/#upload-and-start-the-fast-start-data-loader-notebook","text":"Upload or open the Fast Start Data Loader template notebook to your Project. These instructions will be based off using the 'FastStart2021-New.ipynb' file. Use the steps from the previous exercise Add Notebook From File to a Watson Studio Project Rename the notebook template by prepending your initials to the template. If you already have uploaded the notebook, open it with Watson Studio. Select the FastStart2021-New.ipynb notebook template that you have renamed with your initials. Open the notebook. Click on the pencil icon next to your notebook If the notebook fails to start, restart it. Click on the i icon , Environment tab, Running status drop down select box and choose Restart","title":"Upload and Start the Fast Start Data Loader Notebook"},{"location":"fast_start_loader/#run-the-notebook","text":"","title":"Run the Notebook"},{"location":"fast_start_loader/#part-1-introduction","text":"Run the first cell two cells. These cells are setting up the files required to complete the notebook. Read the introduction for details on the notebook and how it fits into the Maximo Predict process. Ensure that your csv files are uploaded in the requested format. Note that the asset metrics csv file needs to have Asset Id, Install Date and Decommission Date, NOT the site ID.","title":"Part 1 - Introduction"},{"location":"fast_start_loader/#part-2-install-the-maximo-predict-sdk","text":"Ensure you have a 'Predict_Envs.json' file uploaded. If one is not provided, follow the instructions in set up Watson Studio under the 'Get URL' section to gather the APM_ID , APM_API_BASE_URL , and APM_API_KEY to create a JSON file containing the credentials and upload to Watson Studio with your initials prepended to the file name. Run the cell to open the JSON file. If you have created a JSON file with your initials prepended, update f = open('/project_data/data_asset/Predict_Envs.json,) to include your initials on the file name. See example image. Run the following two cells to set up variables required for the environment. Note that both should produce an output without errors similar to main.predict.ivt11rel87.ivt.suite.maximo.com Run the cell to install the pmlib using the pip install command Ensure the output runs without errors. (Warnings are Okay) then run the cell to import pmlib into the project Run the cell to import the additional required libraries Update the following values in the cell with your initials: Change newAssetPrefix = 'New_' to newAssetPrefix = '{initials}_' Change default_device_type = 'Pump_AFM' to default_device_type = '{initials}_Pump_AFM' Change device_ids_oem = ['PMPDEVICE002', 'PMPDEVICE004', 'PMPDEVICE006', 'PMPDEVICE008', 'PMPDEVICE010'] to device_ids_oem = ['{initials}_PMPDEVICE00'] Run the cell and make a note of the resulting output. This will be needed in future notebooks to call your assets. Run the following cell to store the variables just created Run the cell to set the preferred column names for Maximo's system","title":"Part 2 - Install the Maximo Predict SDK"},{"location":"fast_start_loader/#part-3-load-the-data-into-dataframes","text":"Update asset_installation_decommission_dates_df = pd.read_csv('/project_data/data_asset/asset_installation_decommission_date_afm.csv') to match the filename for your asset information (containing asset id, installation date and decommission date). If your Installation Date column header or your Decommission date column header do not match the values called in this cell ( installation_date and decommission_date ), update to match your column headers. Run the cell to load the asset attributes and ensure the output matches your data. Note that the column headers in the output should match the variables defined in the previous cell. Repeat these steps for each csv file being imported for the remainder of part 3. Note: Not all of these cells are redefining the column headers. If you get errors down the line, you may need to update the column header in the data frame created here. See Update DateFrame Headers .","title":"Part 3 - Load the Data Into Dataframes"},{"location":"fast_start_loader/#part-4-add-timeshift-to-make-data-more-recent","text":"Run the first cell to view the current date range of the data. Run the second cell to calculate and view the shift in time that will be applied Run the third cell to perform the time shift Run the fourth cell to view the new range of dates for the sensor dataframe Repeat these steps for the remainder of part 4 to perform the timeshift on the failure data","title":"Part 4 - Add Timeshift to Make Data More Recent"},{"location":"fast_start_loader/#part-5-clean-up-dataframes","text":"Run these two cells to clean up dataframes and reformat to Maximo's standards","title":"Part 5 - Clean up DataFrames"},{"location":"fast_start_loader/#part-6-delete-existing-data","text":"Note This section is REQUIRED if you are refreshing asset data or uploading new data for an existing asset. If you get errors in this section, you may need to update the column header in the data frame created here. See Update DateFrame Headers . Run the first four cells to delete data from Maximo to be replaced. Wait five minutes after the final cell to allow for the data to be fully deleted Run the next two cells to delete the asset group","title":"Part 6 - Delete Existing Data"},{"location":"fast_start_loader/#part-7-insert-data","text":"The following steps will update the MAS database to include the data from the CSV files. 1. Run the cell to view the DataFrame to be imported and run the following cell to use the pmlib library to create the assets in the list. 2. Run the cell to view the assets attributes that will be imported into MAS. Run the following cell to update those values. 3. Run the cell to view the failure history that will be imported into MAS. Run the following cell to import the failure data. 4. Run the cell to write the function definitions required to create your asset group. Run the following cell to create teh asset group. 5. Run the cell to print the asset group name and the asset group id. Take a note of the results as they may be needed in future notebooks. Run the following cell to store the notebook results Set up the IOT Devices. Update DataFrame columns from [timestamp_col_name, asset_id_col_name, 'VELOCITYX', 'VELOCITYY', 'VELOCITYZ', 'MOTORTEMP', 'WINDINGTEMP', 'CURRENT', 'PRESSURE', 'LOAD', device_id_col_name, device_type_col_name] to match the sensor readings for your asset. For example, the line may now read: sensor_data_afm_df.columns = [asset_id_col_name,timestamp_col_name, 'Current_10', 'Speed_4', 'Frequency_2','Current_12','Current_5', 'Vibration_00', 'Current_11','Vibration_13','Power_6','Vibration_1','Power_9','Speed_26',device_id_col_name, device_type_col_name] Run the cell Click into the next cell In the menu, go to Insert > Cell Above In that cell, insert the following code and run: features_for_training=list(set(list(sensor_data_afm_df.columns))- set(['asset_id','evt_timestamp','deviceid','devicetype'])) features_for_training Update the value of columns to columns=features_for_training Run the cell and ensure there are no errors Run the following cell to import the asset device mappings Continue to part 8 or scroll down to run the final cell to save the results.","title":"Part 7 - Insert Data"},{"location":"fast_start_loader/#part-8-add-additional-data-optional","text":"This portion of the notebook is optional. If there is additional data to be uploaded you can use this section and customize the data being sent to MAS and creating scoring data for your assets. These cells would have to be updated for your data. Note Ensure you run the final cell with: store_json = json.dumps(store) project.save_data(\"fast_execution.json\", store_json, overwrite=True)","title":"Part 8 - Add additional Data (Optional)"},{"location":"fast_start_loader/#confirm-data-upload-and-prediction-groups","text":"Confirm that the historical data was uploaded to Monitor. Confirm that the Prediction group was created and linked to the model notebook template you created. Navigate to Predict within your environment Use the left-hand menu to go into Predict Grouping Ensure your asset group is available in the list and confirm your asset is available within the group. Navigate to IOT within your environment. Under devices , search to ensure your device is there Navigate to Device Types and find your device type. Check that your physical and logical interfaces are active. Navigate to Monitor and ensure your devices have data","title":"Confirm Data Upload and Prediction Groups"},{"location":"fast_start_loader/#error-handling","text":"","title":"Error Handling"},{"location":"fast_start_loader/#update-dateframe-header","text":"If you receive an object attribute error for pandas, with a column header initialized in Part 2 step 10 listed similar to: Then follow these steps to replace your dataframe header to resolve this error. 1. Click into the cell that resulted in an error. In the menu, go to Insert > Cell Above Rename the columns by adding the following code in the cell: {DataFrame_to_Change}.rename(columns={'{current_column_header}': site_id_col_name}, inplace=True) {DataFrame_to_Change}.head() Run the cell. The output should show the new header in the table. For example: in order to change the failure_data_afm_df column header from 'site' to the preferred header: Congratulations you have loaded historical data and created Predict Groups linking your devices metrics inputs to list of assets and notebook template that will be used to score predictions using Predict with Monitor device data!","title":"Update DateFrame Header"},{"location":"get_started/","text":"Get Started In this Lab you wil learn how to use Maximo Health and Predict-Utilities to understand the asset health and failure risks for pumps and other utility assets. The version of Health and Predict - Utilities used in this Lab is for Maximo Application Suite v8.8. Description Maximo Manage includes the ability to manage assets. Reliability Engineers can use asset data stored in Manage and other data sources to better plan their asset maintenance and repairs to ensure asset reliability and reduce operational risks. By leveraging asset health scoring and AI algorithms to detect anomalies and predict asset failures in time to mitigate or avoid their negative impacts. Health and Predict - Utilities includes proven machine learning model templates to make predictions or classify asset condition using asset data. These lab exercises provide you the best practices and guided instructions for how to use Health and Predict - Utilities to set up and asses your asset condition scoring, failure prediction dates and anomaly detection using a real world public pump data set. The intended audience for this lab are reliability engineers and data scientists who will set up the Maximo Environment and analyze their data to create prediction models for asset end of life using Predict model templates. Reliability Engineers who need to plan to address poor asset health and risk with an asset investment plan to repair or replace their assets. You will use a publicly available pump data set from Kaggle to build a Anomaly Detection model. The pump data definition explains what sensor readings are available based on the known information about the data set provided on the Kaggle site You will use instructor provided simulated CSV asset data for a set of substation transformers to create health scores and asset failure predictions using the automation notebooks provided. Ways to Setup and Load Asset Data There are three possible ways to get data into Health and Predict - Utilities. Data loading Python Notebooks requires that you have set up Watson Studio with Predict Libraries and Notebooks . Data loading meter data using EAM CronTask - Not covered in this lab Data loading meter data and asset types using App Connect - Not covered in this lab. Only the installation is covered. Pre-requisites For this exercise ensure you have access to : MAS v8.8 Health and Predict. Cloud Pak for Data Watson Studio compatible with MAS v8.8 App Connect (optional). You can use the App Connect add on included with Maximo Application Suite as an Add On. Or install it yourself using the App Connect exercises. Access to the asset csv data and Jupyter Notebooks used to in this Lab exercise. They can be provided by the instructor. Exercises These are the exercises available in this lab. Setup Watson Studio with Health and Predict - Utilities libraries and Notebook templates Understand Health and Predict - Utilities Models explains how to prepare your asset data to be analyzed by Health and Predict - Utilities. Data Preparation explains how to prepare and format your asset data into files needed for an example prediction model using Health and Predict - Utilities with Watson Studio. Load Historical Utilities Data explains how to assess the performance of a failure date prediction model using Health and Predict - Utilities with Watson Studio. Pump Data Dictionary explains the public pump data used in this lab from Kaggle. Load Historical Pump Data explains how to Load Historical Pump Data Into Monitor using Health and Predict - Utilities with Watson Studio and create: Failure Prediction Date Model Failure Probability Model Anomaly Detection Model Prediction Group to link a group of assets to a deployed Predict models. Asset Health Scoring Reliability Engineer uses the MAS Health and Predict applications to review the asset conditions and ensure that there aren't any failures predicted before planned maintenance. Asset Investment Optimization to action assets in poor condition using the Health Web UI. View and config Asset Matrix for the distribution of High risk assets Install and Configure App Connect flows to load asset metadata and timeseries data into Health and Predict - Utilities. (Optional) Architecture Here is the architectural deployment pattern these labs are targeted for: Maximo v7.6.1 deployment with Maximo Application Suite Health Predict and Utilities Maximo Application Suite Health Predict and Utilities deployed as a Manage Add On","title":"Get Started"},{"location":"get_started/#get-started","text":"In this Lab you wil learn how to use Maximo Health and Predict-Utilities to understand the asset health and failure risks for pumps and other utility assets. The version of Health and Predict - Utilities used in this Lab is for Maximo Application Suite v8.8.","title":"Get Started"},{"location":"get_started/#description","text":"Maximo Manage includes the ability to manage assets. Reliability Engineers can use asset data stored in Manage and other data sources to better plan their asset maintenance and repairs to ensure asset reliability and reduce operational risks. By leveraging asset health scoring and AI algorithms to detect anomalies and predict asset failures in time to mitigate or avoid their negative impacts. Health and Predict - Utilities includes proven machine learning model templates to make predictions or classify asset condition using asset data. These lab exercises provide you the best practices and guided instructions for how to use Health and Predict - Utilities to set up and asses your asset condition scoring, failure prediction dates and anomaly detection using a real world public pump data set. The intended audience for this lab are reliability engineers and data scientists who will set up the Maximo Environment and analyze their data to create prediction models for asset end of life using Predict model templates. Reliability Engineers who need to plan to address poor asset health and risk with an asset investment plan to repair or replace their assets. You will use a publicly available pump data set from Kaggle to build a Anomaly Detection model. The pump data definition explains what sensor readings are available based on the known information about the data set provided on the Kaggle site You will use instructor provided simulated CSV asset data for a set of substation transformers to create health scores and asset failure predictions using the automation notebooks provided. Ways to Setup and Load Asset Data There are three possible ways to get data into Health and Predict - Utilities. Data loading Python Notebooks requires that you have set up Watson Studio with Predict Libraries and Notebooks . Data loading meter data using EAM CronTask - Not covered in this lab Data loading meter data and asset types using App Connect - Not covered in this lab. Only the installation is covered. Pre-requisites For this exercise ensure you have access to : MAS v8.8 Health and Predict. Cloud Pak for Data Watson Studio compatible with MAS v8.8 App Connect (optional). You can use the App Connect add on included with Maximo Application Suite as an Add On. Or install it yourself using the App Connect exercises. Access to the asset csv data and Jupyter Notebooks used to in this Lab exercise. They can be provided by the instructor.","title":"Description"},{"location":"get_started/#exercises","text":"These are the exercises available in this lab. Setup Watson Studio with Health and Predict - Utilities libraries and Notebook templates Understand Health and Predict - Utilities Models explains how to prepare your asset data to be analyzed by Health and Predict - Utilities. Data Preparation explains how to prepare and format your asset data into files needed for an example prediction model using Health and Predict - Utilities with Watson Studio. Load Historical Utilities Data explains how to assess the performance of a failure date prediction model using Health and Predict - Utilities with Watson Studio. Pump Data Dictionary explains the public pump data used in this lab from Kaggle. Load Historical Pump Data explains how to Load Historical Pump Data Into Monitor using Health and Predict - Utilities with Watson Studio and create: Failure Prediction Date Model Failure Probability Model Anomaly Detection Model Prediction Group to link a group of assets to a deployed Predict models. Asset Health Scoring Reliability Engineer uses the MAS Health and Predict applications to review the asset conditions and ensure that there aren't any failures predicted before planned maintenance. Asset Investment Optimization to action assets in poor condition using the Health Web UI. View and config Asset Matrix for the distribution of High risk assets Install and Configure App Connect flows to load asset metadata and timeseries data into Health and Predict - Utilities. (Optional)","title":"Exercises"},{"location":"get_started/#architecture","text":"Here is the architectural deployment pattern these labs are targeted for: Maximo v7.6.1 deployment with Maximo Application Suite Health Predict and Utilities Maximo Application Suite Health Predict and Utilities deployed as a Manage Add On","title":"Architecture"},{"location":"health_score/","text":"Asset Health Scoring Maximo Health includes health scores for understanding asset conditions. Allowing you to identify which assets are most critical and in need of maintenance or replacement. In this exercise the Reliability Engineer uses Health to: Create an asset group view View asset map View work queues Create health group scores View asset details page View predict model for asset failure probability View asset timeline Take action by creating service request Remove temporary views and groups Pre-requisites Review Health documentation for the list of available models . Ensure your MAS v8.7 Health environment is running and you have access. Please note that the MAS Worldwide (WW) demo environment is NOT a suitable environment for this lab. The WW demo environment is shared, and making ANY changes to that environment will impact other users\u2019 ability to demonstrate MAS. Introduction This lab exercise guide is for Maximo Health and Predict. Maximo Predict uses historical and real-time asset performance data, maintenance records, inspection reports, and environmental data to correlate performance factors that predict asset degradation or failure. Predict uses artificial intelligence to optimize predict model accuracy. Maximo Health introduced the concept of work queues to provide a consolidated view of the Assets and their health. It provides Asset Performance KPI view and fleet wide view and health drill down. It also allows you to take actions based on conditions. This may be based on either Inspection or Sensor Data. Maximo Predict allows for increasing the life of asset. It reduces maintenance costs and improves asset utilization by reducing unnecessary and redundant maintenance based on condition monitoring infused with IoT, AI, and ML. Also, it helps in conducting the proactive maintenances for assets that need attention. Through this Maximo Health and Predict lab exercise, you will learn how to Get better insight into the health of assets and predict failures well in advance Reduce unnecessary Preventive Maintenance or doing condition-based monitoring. It would take about 60 minutes to go through the lab exercise and learn about the Maximo Health and Predict applications. Note: Follow the Actions steps in bold to navigate through the lab procedures. Glossary Age is the actual age. It is the current date minus the installation date. Anomaly Detection helps identify unusual patterns in the behavior of the asset, which might indicate potential failures or pre-failure behaviors. Asset timeline provides insight into the state of your asset by time in a graphical view. Asset health is the overall state of an asset might be based solely on observation or on a driver, such as condition, performance, or cost. Asset type is a category for an asset used to manage assets with similar characteristics. Criticality defines the importance of the asset to business processes. It configures how this score is calculated on the Scoring page. End of Life Curve uses retirement and age data for similar assets to estimate the end of life. Estimated Time to Failure is the number of remaining days the asset could operate before failure. If multiple failure modes are possible, the failure mode with the soonest failure estimate and the user can select a different failure mode to see its estimated failure date. Factors that contribute to failures The factors that contribute to failure are the parameters used in the training model to predict the failure of an asset. You can view this information in the failure contribution analysis tree. Fair is an asset health condition indicates that the asset is in minimum operability and can complete its basic functions. Failure Probability is the percentage that the asset failure could occur in the selected prediction window. Failure Probability Trend is the historical trend of failure probability of the asset during a period. Good is asset health condition indicates that the asset is operating at a high level without problems. Health is the overall condition of the asset. Health History is the overall condition of the asset over a period. Meters are readings for the asset to determine the operational status. MRR is the maintenance-to-replacement ratio (MRR) for the asset. MRR is calculated by dividing the current total cost of all maintenance for the asset, including parts and labor, by the replacement cost. If the percentage is 100% or greater, the current total cost of the asset is greater than the cost to replace the asset. Next Failure is the time remaining until the asset is expected to fail based on the predictive model. Next PM is the number of days until the next scheduled generation of preventive maintenance (PM) work order. The card is empty if the generation date is the current date or in the past, and no other work order generations are scheduled. Normalized score is a rating representing the adjustment of a health score to a common baseline. Poor is an asset health condition indicates that the asset has serious problems keeping it from functioning as intended. RUL is the remaining percentage of the asset's useful life. The remaining useful life (RUL) is calculated by subtracting the age from the manufacturer's expected life. If the age exceeds the expected life, the RUL is 0%. Work Queues provide users with a list of tasks, work or items to review and display the outstanding number of records to be reviewed on an ongoing basis. Lab Overview Through this lab exercise, you will learn how a Reliability Engineer uses the MAS Health and Predict applications to review the asset conditions and ensure that there aren't any failures predicted before planned maintenance. Together, MAS Health and Predict applications provide a view of an enterprise's assets' current state and project future conditions of those assets. Story A Water Resource Authority needs to manage wastewater treatment assets across multiple cities and regions from a single application. Pumps are one of the critical assets in the wastewater plant. In this lab exercise, we will learn how a reliability engineer uses the MAS Health and Predict applications to review the pump conditions and ensure that there aren't any failures predicted before planned maintenance. Health and Predict arm the Reliability Engineer with AI-powered insights to take actions to extend the life of the assets, reduce maintenance costs, and eliminate unplanned downtime. You can identify assets that need attention, investigate those assets, and finally take an action to avoid unplanned downtime. Persona Reliability Engineer manages the reliability risk by ensuring the asset is available and functions without failure. Based on the industry and market, reliability engineers manage multiple assets and processes. Launch the Maximo Aplication Suite Application for Health and Predict - Utilities. Click the App Switcher icon on the top right side of the home page. Select Health application from the menu bar and you will view the assets list. Create an Asset Group View Follow the actions below to create and view your pump group. This view will allow the Reliability Engineer to view their asset conditions in a tabular and map view. You can create and save view so that you don\u2019t have to start over every time. This view includes a status column, filters on my pumps, and sorts them by OEM and non-OEM. Follow the steps to create asset group view. Click on the Search icon and type pmpd to view all the pumps from the assets list. Create your pump group by selecting the menu option Save as and typing your Maximo lab login as your pump view name. Save your view. You can view the pump group you have created using the drop-down menu. View both IT and OT data of your pumps in a single view. Click on the Column Selection menu icon. Click Manage columns . Type manufacturer in the search field and press enter key on your keyboard. Select the check box for manufacturer and click Ok Click on the Column Selection icon. Check if you can see the added new field Manufacturer in your view. Asset Map View See how the assets are spatially distributed may assist the Reliability Engineer with identifying and investigating assets at risk. Follow the steps to view asset map. Click the Map icon to view the asset and its health condition in a map view. Click and select the pump PMPDEVICE007 , which has a poor health score on the map. Use the zoom in/out feature to adjust your map view. Use the zoom in/out features to adjust your map view. Click on Actions and choose the option Add Flag . Select the Flag option Replace and click Add Flag . You will see the Replace tag added to the pump. Note If the pump is already tagged with Replace , you will see a system message (see below). Close the system message and go to the next exercise if you see this message. Work Queues Follow the actions below to view the work queue of the asset group you have. Work queues are preconfigured views designed to help you find what you're looking for and manage your day-to-day activities. Work Queues are particularly valuable to a Reliability Engineer who needs to address a specific problem, like at water treatment plant, to avoid unplanned downtime. The missing data Work Queues are extremely useful to a Reliability Engineer as they can help identify gaps in data necessary to create health scores or predictive failure models. Follow the steps to view the work queues. Click on the navigation menu in the upper left corner and select the Work Queues tab. View the Work Queues list. Reliability Engineers can view the queues based on preconfigured categories. Click the hamburger menu again to close the tab, and select the Failing before PM work queue to view the assets that could fail before scheduled preventive maintenance is completed. Expand the column width of \"Asset\" to view the full asset names. View the list of pumps and their predicted failure dates. Check for the pump that has the lowest Health Score. Create health scores Before we continue to investigate our assets at risk, we\u2019ll learn how to create health, criticality, and risk scores. All three types of scores are created in a similar manner. We\u2019ll create a health score for our lab. Follow the steps to create health scores. Select Scoring from the left navigation bar to open the scoring feature in Maximo Health The initial view will show the Groups of assets that have already been created. You\u2019ll also see a tab for Ranges and Contributors . Select the Ranges tab so that we can explore how ranges are created. On this page, you can see that custom ranges have already been created for health, criticality, and risk scores. In addition to creating custom ranges, you can also name them, and assign different colors and symbols to each range. The ability to customize ranges, and scores, is important since each enterprise has different preferences, as well as different risk tolerances. Let\u2019s review the ranges for Health that have already been established. Click on Health at the top of the Health score box. Three ranges have been created for the health scores. Each range has limits, a name, color, and symbol assigned to it. Select the Scoring breadcrumb at the top of the page to return to the main scoring page. Select the Contributors tab so that we can explore what contributors are available to use when creating scores. Select the FACRULYEARSSAMPLE highlighted blue text in a box to review one of the sample formulas included with Maximo Health. This contributor holds a formula that describes the asset\u2019s remaining useful life in years. Once you\u2019ve reviewed the page, select the Scoring breadcrumb at the top of the page to return to the Contributors page. Then select the Groups tab. From the Groups page, we\u2019ll create a custom health score. Your health score will use the ranges, and the contributor that we just reviewed. Select the Create Group + button to create your own group. Create your own group with the following information. Name: The username you used to login to this lab (example: s123think22) Description: Think2022 Lab Sample Group Object: Asset Select Select to select a group. In the Select a Query box, type in Pumps in the search box, and select the check mark at the end of line. This will search for a prebuilt query for pumps. Select Pumps from the resulting search and click Apply . On the next page, click Create to create your unique group of 10 pumps. On the group page that you just created, click Add Score to create a health score for your pumps. In the popup, click on the Health score box to highlight it, then click Done . We\u2019ll create a health score that is a weighted average of several contributors, including sensor readings, and a field from Manage. Click on the + symbol to add our first contributor, a pre-built formula for Remaining Useful Life. From the Add a Contributor pop-up, FIRST select the box for FACRULYEARSSAMPLE , and then click Add . If you do not see the blue bar or Add option, select the circled check mark in the upper right corner of the FACRULYEARSSAMPLE box. Click on the \u0192x symbol to add a second contributor, a formula we\u2019ll write to get the number count from a field in Manage. On the pop up, complete the form with the following inputs: Name: Open Work Orders Description: A count of open work orders in Manage Formula: count$openwo Scroll down the screen and enter the following values: Best possible value: 0 Worst possible value: 5 Then click Add formula to score . Click on the hierarchy symbol to add a contributor group, which will consist of multiple sensor readings. On the pop up, complete the form as follow, the click Create . Name: Meter Health Description: Contributor group of meters Click on the contributor group Meter Health that you just created to add contributors. Click on the + to add multiple contributors to your group. Scroll down the screen and click on the following boxes to select them, then click Add . MOTORTEMP VELOCITYZ VELOCITYX VELOCITYY Click on the pencil icon to edit the percentage each contributor contributes to the group. On the Edit contributor settings pop up, adjust the Weight to 25 for each of the 4 contributors, and click Save . Return to your Health score page by clicking Health in the breadcrumbs. Click on the pencil icon to edit the percentage each contributor contributes to the overall Health score. On the Edit contributor settings pop up, adjust the Weight to 60% for FACRULYEARSSAMPLE , 20% for Open Work Orders , and 20% for Meter Health , then click Save . Return to your main score page by clicking Scoring in the breadcrumbs. You have successfully created a health score for your group of pumps. You will see your scoring group, along with scoring groups on the page. Asset Details Understand asset Health using the Asset details page. Follow the steps to view the asset details page. Click the Work Queues icon on the left side of the menu screen. Select Failing before PM from the queue names. Adjust the \"Asset: column width to view the full asset names and click on PMPDEVICE003 View pump PMPDEVICE003 and click and view details under Asset Health section. Scroll down to the health history section. Select 1 month period and view the health history data for the last 30 days. The graph here has the Score on the y-axis with the date on the x-axis and maps the Health score and its contributors. This way, we can see a view of how this information contributes to the overall Health of the asset. Asset Failure Probability IBM Predict includes templates to help our Data Scientist get started building models to project days to failure, calculate the probability of failure, detect anomalies, and generate an asset life curve based on group asset deployment and retirement dates.\u202f These templates include a large number of algorithms and can automatically select the one that best fits our data for the optimal outcome. Follow the steps to view predict model. Click and expand Predictions section and wait for the predictive model results to load. Wait for the Predict failure data table and graph to load for the pump PMPDEVICE003 . Scroll down to the Failure probability trend card. Maximize the Failure probability trend and view the data. Close the maximized view by clicking on the close icon. Scroll down to Factors that contribute to failures card and view the results or full analysis tree. Asset Timeline Follow the steps to view asset timeline. Open the Asset timeline tab. Hover over Predicted failure . While each piece of information, or widget, gives you insight into the state of our asset, all of the information together, gives us a richer view. This helps us make a data-driven decision on how to address this asset. Taking action Follow the steps to take action on resolving the asset health issues and risks you have uncovered. Scroll the screen up until you see the PMPDEVICE003 and click Actions and select Create Service Request . Type the following and select priority as High . Create the ticket by clicking on Create . Summary: Test Summary Description: Test Description Closing This exercise explains how to remove the temporary pump views. You will remove the pump views you have created. Follow the steps below to exit. Go to Asset icon located in the top left side of the menu bar. Click the Asset menu located in the top left side of the menu bar. Select the pump view you have created (as part of the exercise section 4.2) Click on the menu option and select Delete . Check if you have selected the pump view you have created and click Delete . How to remove the temporary groups Follow the steps to remove temporary groups. Click the Scoring menu located in the top left side of the menu bar. Go to the group you have created and delete it. Check if you have selected the group you have created and click Delete . Congratulations! You have experienced how a Reliability Engineer continued the investigation, using Maximo Health and Predict to better understand the current and future states of the pumps, identify potential problems, and take actions using AI-driven insights to avoid unplanned downtime.","title":"Asset Health Scoring"},{"location":"health_score/#asset-health-scoring","text":"Maximo Health includes health scores for understanding asset conditions. Allowing you to identify which assets are most critical and in need of maintenance or replacement. In this exercise the Reliability Engineer uses Health to: Create an asset group view View asset map View work queues Create health group scores View asset details page View predict model for asset failure probability View asset timeline Take action by creating service request Remove temporary views and groups","title":"Asset Health Scoring"},{"location":"health_score/#pre-requisites","text":"Review Health documentation for the list of available models . Ensure your MAS v8.7 Health environment is running and you have access. Please note that the MAS Worldwide (WW) demo environment is NOT a suitable environment for this lab. The WW demo environment is shared, and making ANY changes to that environment will impact other users\u2019 ability to demonstrate MAS.","title":"Pre-requisites"},{"location":"health_score/#introduction","text":"This lab exercise guide is for Maximo Health and Predict. Maximo Predict uses historical and real-time asset performance data, maintenance records, inspection reports, and environmental data to correlate performance factors that predict asset degradation or failure. Predict uses artificial intelligence to optimize predict model accuracy. Maximo Health introduced the concept of work queues to provide a consolidated view of the Assets and their health. It provides Asset Performance KPI view and fleet wide view and health drill down. It also allows you to take actions based on conditions. This may be based on either Inspection or Sensor Data. Maximo Predict allows for increasing the life of asset. It reduces maintenance costs and improves asset utilization by reducing unnecessary and redundant maintenance based on condition monitoring infused with IoT, AI, and ML. Also, it helps in conducting the proactive maintenances for assets that need attention. Through this Maximo Health and Predict lab exercise, you will learn how to Get better insight into the health of assets and predict failures well in advance Reduce unnecessary Preventive Maintenance or doing condition-based monitoring. It would take about 60 minutes to go through the lab exercise and learn about the Maximo Health and Predict applications. Note: Follow the Actions steps in bold to navigate through the lab procedures.","title":"Introduction"},{"location":"health_score/#glossary","text":"Age is the actual age. It is the current date minus the installation date. Anomaly Detection helps identify unusual patterns in the behavior of the asset, which might indicate potential failures or pre-failure behaviors. Asset timeline provides insight into the state of your asset by time in a graphical view. Asset health is the overall state of an asset might be based solely on observation or on a driver, such as condition, performance, or cost. Asset type is a category for an asset used to manage assets with similar characteristics. Criticality defines the importance of the asset to business processes. It configures how this score is calculated on the Scoring page. End of Life Curve uses retirement and age data for similar assets to estimate the end of life. Estimated Time to Failure is the number of remaining days the asset could operate before failure. If multiple failure modes are possible, the failure mode with the soonest failure estimate and the user can select a different failure mode to see its estimated failure date. Factors that contribute to failures The factors that contribute to failure are the parameters used in the training model to predict the failure of an asset. You can view this information in the failure contribution analysis tree. Fair is an asset health condition indicates that the asset is in minimum operability and can complete its basic functions. Failure Probability is the percentage that the asset failure could occur in the selected prediction window. Failure Probability Trend is the historical trend of failure probability of the asset during a period. Good is asset health condition indicates that the asset is operating at a high level without problems. Health is the overall condition of the asset. Health History is the overall condition of the asset over a period. Meters are readings for the asset to determine the operational status. MRR is the maintenance-to-replacement ratio (MRR) for the asset. MRR is calculated by dividing the current total cost of all maintenance for the asset, including parts and labor, by the replacement cost. If the percentage is 100% or greater, the current total cost of the asset is greater than the cost to replace the asset. Next Failure is the time remaining until the asset is expected to fail based on the predictive model. Next PM is the number of days until the next scheduled generation of preventive maintenance (PM) work order. The card is empty if the generation date is the current date or in the past, and no other work order generations are scheduled. Normalized score is a rating representing the adjustment of a health score to a common baseline. Poor is an asset health condition indicates that the asset has serious problems keeping it from functioning as intended. RUL is the remaining percentage of the asset's useful life. The remaining useful life (RUL) is calculated by subtracting the age from the manufacturer's expected life. If the age exceeds the expected life, the RUL is 0%. Work Queues provide users with a list of tasks, work or items to review and display the outstanding number of records to be reviewed on an ongoing basis.","title":"Glossary"},{"location":"health_score/#lab-overview","text":"Through this lab exercise, you will learn how a Reliability Engineer uses the MAS Health and Predict applications to review the asset conditions and ensure that there aren't any failures predicted before planned maintenance. Together, MAS Health and Predict applications provide a view of an enterprise's assets' current state and project future conditions of those assets. Story A Water Resource Authority needs to manage wastewater treatment assets across multiple cities and regions from a single application. Pumps are one of the critical assets in the wastewater plant. In this lab exercise, we will learn how a reliability engineer uses the MAS Health and Predict applications to review the pump conditions and ensure that there aren't any failures predicted before planned maintenance. Health and Predict arm the Reliability Engineer with AI-powered insights to take actions to extend the life of the assets, reduce maintenance costs, and eliminate unplanned downtime. You can identify assets that need attention, investigate those assets, and finally take an action to avoid unplanned downtime. Persona Reliability Engineer manages the reliability risk by ensuring the asset is available and functions without failure. Based on the industry and market, reliability engineers manage multiple assets and processes. Launch the Maximo Aplication Suite Application for Health and Predict - Utilities. Click the App Switcher icon on the top right side of the home page. Select Health application from the menu bar and you will view the assets list.","title":"Lab Overview"},{"location":"health_score/#create-an-asset-group-view","text":"Follow the actions below to create and view your pump group. This view will allow the Reliability Engineer to view their asset conditions in a tabular and map view. You can create and save view so that you don\u2019t have to start over every time. This view includes a status column, filters on my pumps, and sorts them by OEM and non-OEM. Follow the steps to create asset group view. Click on the Search icon and type pmpd to view all the pumps from the assets list. Create your pump group by selecting the menu option Save as and typing your Maximo lab login as your pump view name. Save your view. You can view the pump group you have created using the drop-down menu. View both IT and OT data of your pumps in a single view. Click on the Column Selection menu icon. Click Manage columns . Type manufacturer in the search field and press enter key on your keyboard. Select the check box for manufacturer and click Ok Click on the Column Selection icon. Check if you can see the added new field Manufacturer in your view.","title":"Create an Asset Group View"},{"location":"health_score/#asset-map-view","text":"See how the assets are spatially distributed may assist the Reliability Engineer with identifying and investigating assets at risk. Follow the steps to view asset map. Click the Map icon to view the asset and its health condition in a map view. Click and select the pump PMPDEVICE007 , which has a poor health score on the map. Use the zoom in/out feature to adjust your map view. Use the zoom in/out features to adjust your map view. Click on Actions and choose the option Add Flag . Select the Flag option Replace and click Add Flag . You will see the Replace tag added to the pump. Note If the pump is already tagged with Replace , you will see a system message (see below). Close the system message and go to the next exercise if you see this message.","title":"Asset Map View"},{"location":"health_score/#work-queues","text":"Follow the actions below to view the work queue of the asset group you have. Work queues are preconfigured views designed to help you find what you're looking for and manage your day-to-day activities. Work Queues are particularly valuable to a Reliability Engineer who needs to address a specific problem, like at water treatment plant, to avoid unplanned downtime. The missing data Work Queues are extremely useful to a Reliability Engineer as they can help identify gaps in data necessary to create health scores or predictive failure models. Follow the steps to view the work queues. Click on the navigation menu in the upper left corner and select the Work Queues tab. View the Work Queues list. Reliability Engineers can view the queues based on preconfigured categories. Click the hamburger menu again to close the tab, and select the Failing before PM work queue to view the assets that could fail before scheduled preventive maintenance is completed. Expand the column width of \"Asset\" to view the full asset names. View the list of pumps and their predicted failure dates. Check for the pump that has the lowest Health Score.","title":"Work Queues"},{"location":"health_score/#create-health-scores","text":"Before we continue to investigate our assets at risk, we\u2019ll learn how to create health, criticality, and risk scores. All three types of scores are created in a similar manner. We\u2019ll create a health score for our lab. Follow the steps to create health scores. Select Scoring from the left navigation bar to open the scoring feature in Maximo Health The initial view will show the Groups of assets that have already been created. You\u2019ll also see a tab for Ranges and Contributors . Select the Ranges tab so that we can explore how ranges are created. On this page, you can see that custom ranges have already been created for health, criticality, and risk scores. In addition to creating custom ranges, you can also name them, and assign different colors and symbols to each range. The ability to customize ranges, and scores, is important since each enterprise has different preferences, as well as different risk tolerances. Let\u2019s review the ranges for Health that have already been established. Click on Health at the top of the Health score box. Three ranges have been created for the health scores. Each range has limits, a name, color, and symbol assigned to it. Select the Scoring breadcrumb at the top of the page to return to the main scoring page. Select the Contributors tab so that we can explore what contributors are available to use when creating scores. Select the FACRULYEARSSAMPLE highlighted blue text in a box to review one of the sample formulas included with Maximo Health. This contributor holds a formula that describes the asset\u2019s remaining useful life in years. Once you\u2019ve reviewed the page, select the Scoring breadcrumb at the top of the page to return to the Contributors page. Then select the Groups tab. From the Groups page, we\u2019ll create a custom health score. Your health score will use the ranges, and the contributor that we just reviewed. Select the Create Group + button to create your own group. Create your own group with the following information. Name: The username you used to login to this lab (example: s123think22) Description: Think2022 Lab Sample Group Object: Asset Select Select to select a group. In the Select a Query box, type in Pumps in the search box, and select the check mark at the end of line. This will search for a prebuilt query for pumps. Select Pumps from the resulting search and click Apply . On the next page, click Create to create your unique group of 10 pumps. On the group page that you just created, click Add Score to create a health score for your pumps. In the popup, click on the Health score box to highlight it, then click Done . We\u2019ll create a health score that is a weighted average of several contributors, including sensor readings, and a field from Manage. Click on the + symbol to add our first contributor, a pre-built formula for Remaining Useful Life. From the Add a Contributor pop-up, FIRST select the box for FACRULYEARSSAMPLE , and then click Add . If you do not see the blue bar or Add option, select the circled check mark in the upper right corner of the FACRULYEARSSAMPLE box. Click on the \u0192x symbol to add a second contributor, a formula we\u2019ll write to get the number count from a field in Manage. On the pop up, complete the form with the following inputs: Name: Open Work Orders Description: A count of open work orders in Manage Formula: count$openwo Scroll down the screen and enter the following values: Best possible value: 0 Worst possible value: 5 Then click Add formula to score . Click on the hierarchy symbol to add a contributor group, which will consist of multiple sensor readings. On the pop up, complete the form as follow, the click Create . Name: Meter Health Description: Contributor group of meters Click on the contributor group Meter Health that you just created to add contributors. Click on the + to add multiple contributors to your group. Scroll down the screen and click on the following boxes to select them, then click Add . MOTORTEMP VELOCITYZ VELOCITYX VELOCITYY Click on the pencil icon to edit the percentage each contributor contributes to the group. On the Edit contributor settings pop up, adjust the Weight to 25 for each of the 4 contributors, and click Save . Return to your Health score page by clicking Health in the breadcrumbs. Click on the pencil icon to edit the percentage each contributor contributes to the overall Health score. On the Edit contributor settings pop up, adjust the Weight to 60% for FACRULYEARSSAMPLE , 20% for Open Work Orders , and 20% for Meter Health , then click Save . Return to your main score page by clicking Scoring in the breadcrumbs. You have successfully created a health score for your group of pumps. You will see your scoring group, along with scoring groups on the page.","title":"Create health scores"},{"location":"health_score/#asset-details","text":"Understand asset Health using the Asset details page. Follow the steps to view the asset details page. Click the Work Queues icon on the left side of the menu screen. Select Failing before PM from the queue names. Adjust the \"Asset: column width to view the full asset names and click on PMPDEVICE003 View pump PMPDEVICE003 and click and view details under Asset Health section. Scroll down to the health history section. Select 1 month period and view the health history data for the last 30 days. The graph here has the Score on the y-axis with the date on the x-axis and maps the Health score and its contributors. This way, we can see a view of how this information contributes to the overall Health of the asset.","title":"Asset Details"},{"location":"health_score/#asset-failure-probability","text":"IBM Predict includes templates to help our Data Scientist get started building models to project days to failure, calculate the probability of failure, detect anomalies, and generate an asset life curve based on group asset deployment and retirement dates.\u202f These templates include a large number of algorithms and can automatically select the one that best fits our data for the optimal outcome. Follow the steps to view predict model. Click and expand Predictions section and wait for the predictive model results to load. Wait for the Predict failure data table and graph to load for the pump PMPDEVICE003 . Scroll down to the Failure probability trend card. Maximize the Failure probability trend and view the data. Close the maximized view by clicking on the close icon. Scroll down to Factors that contribute to failures card and view the results or full analysis tree.","title":"Asset Failure Probability"},{"location":"health_score/#asset-timeline","text":"Follow the steps to view asset timeline. Open the Asset timeline tab. Hover over Predicted failure . While each piece of information, or widget, gives you insight into the state of our asset, all of the information together, gives us a richer view. This helps us make a data-driven decision on how to address this asset.","title":"Asset Timeline"},{"location":"health_score/#taking-action","text":"Follow the steps to take action on resolving the asset health issues and risks you have uncovered. Scroll the screen up until you see the PMPDEVICE003 and click Actions and select Create Service Request . Type the following and select priority as High . Create the ticket by clicking on Create . Summary: Test Summary Description: Test Description","title":"Taking action"},{"location":"health_score/#closing","text":"This exercise explains how to remove the temporary pump views. You will remove the pump views you have created. Follow the steps below to exit. Go to Asset icon located in the top left side of the menu bar. Click the Asset menu located in the top left side of the menu bar. Select the pump view you have created (as part of the exercise section 4.2) Click on the menu option and select Delete . Check if you have selected the pump view you have created and click Delete .","title":"Closing"},{"location":"health_score/#how-to-remove-the-temporary-groups","text":"Follow the steps to remove temporary groups. Click the Scoring menu located in the top left side of the menu bar. Go to the group you have created and delete it. Check if you have selected the group you have created and click Delete . Congratulations! You have experienced how a Reliability Engineer continued the investigation, using Maximo Health and Predict to better understand the current and future states of the pumps, identify potential problems, and take actions using AI-driven insights to avoid unplanned downtime.","title":"How to remove the temporary groups"},{"location":"hpu_models/","text":"Understand Utilities Models In this exercise, you will learn: To use the Substation Transformer Models included with Health and Predict - Utilities (HPU). Create a Score Group for Substation Transformer Assets. Update and Schedule Notebooks for Utilities. Troubleshoot Notebooks for Utilities. Pre-requisites Ensure you have access to : MAS v8.8 Health and Predict Utilities HPU dataloader URL Waston studio access Sample ST(Substation Transformer) data for HPU, and make sure required data are loaded through dataloader via App Connect. Check out the sample data folder structure as below. Out Of The Box Models Health and Predict - Utilities includes the supported Asset Classes listed in table below: Asset class Model DISTRIBUTION TRANSFORMER IBM Transformers Tap Changers 5.0.0 SUBSTATION TRANSFORMER IBM Transformers Tap Changers 5.0.0,IBM Transformers Tap Changers DGA 5.0.0 INSTRUMENT TRANSFORMER IBM Instrument Transformers Oil Filled CTs 5.0.0 SWITCHGEAR IBM Gas Insulated Switchgear 5.0.0 UNDERGROUND TRANSMISSION MANHOLE IBM Underground Transmission Manholes 5.0.0 METAL SUPPORT STRUCTURE IBM Metal Support Structures 5.0.0 OVERHEAD TRANSMISSION WIRE IBM Conductors 5.0.0 POLE - Wood Power Pole IBM Wood Pole Structures 5.0.0 CIRCUITBREAKER - Oil Circuit Breaker IBM Circuit Breakers Oil 5.0.0 CIRCUITBREAKER - Air Blast Circuit Breaker IBM Circuit Breakers Air Blast 5.0.0 CIRCUITBREAKER - Air Magnetic Circuit Breaker IBM Circuit Breakers Air Magnetic 5.0.0 CIRCUITBREAKER - Vacuum Circuit Breaker IBM Circuit Breakers Vacuum 5.0.0 CIRCUITBREAKER - SF6 Circuit Breaker IBM Circuit Breakers SF6 5.0.0 UNDERGROUNDTRANSMISSIONCABLE - High Pressure Fluid Filled Pipe Type (HPFF) Cables IBM HPFF Cables 5.0.0 UNDERGROUNDTRANSMISSIONCABLE - Mass Impregnated (MI) Cables IBM MI Cables 5.0.0 UNDERGROUNDTRANSMISSIONCABLE - Self Contained Fluid Filled (SCFF) Cables IBM SCFF Cables 5.0.0 UNDERGROUNDTRANSMISSIONCABLE - Self Contained Gas Filled (SCGF) Submarine Cables IBM SCGF Cables 5.0.0 UNDERGROUNDTRANSMISSIONCABLE - Extruded Cross Linked Polyethylene (XLPE) Cables IBM XLPE Cables 5.0.0 Note Some asset classes have subtype, like Circuit Breaker or Underground Transmission Cable HPU Model Calculation Methodology Create a Score Group Create a Score Group for Substation Transformer Assets 1. Login and go to Health and Predict Utilities application. 2. Click Scoring and DGA settings in the menu,in Scoring and DGA settings page, click Create a scoring and DGA group button. 3. In the create score group page,fill in name,description, select Asset object,choose Connectigng group to notebook . 4. Then click Select to choose IBM Transformers Tap Changers DGA 5.0.0 notebook in the notebook list dialog,click Use notebook . 5. Scroll down query part, click Select to open query dialog, user can select an existing query, or click + button to create a new query for ST assets. E.g Select site and classification for the new query. 6. After select the notebook and query, click Create to create the score group. 7. After score group is created, system will redirect to the score group detail page, in this page, user can see all the scores and the asset list. 8. Click the score in the table, and active it on the right, scores need to be activated one by one based on the dependency. 9. After activating all the scores, click the Recalculate scores to start the analysis. Update and Schedule Notebooks In this exercise you will check the notebook configuration file, notebook and the job, also update the notebook and save to latest version. You will also schedule Jobs to run the notebooks and do asset scoring by changing the cron task schedule. In Health and Predict - Utilities, the scoring calculation happen in Watson Studio jobs. Each asset type has a configure file, notebook, and job deployed on Watson Studio project. When user clicks Recalculate scores on UI, it triggers the job to run, do the calculation, and save results to the Database. Substation Transformer Model Configuration For ST (Substation Transformer), configuration file is named IBM-Transformers-Tap-Changers-DGA-5.0.0.cfg . In the configuration file, under Common section defaultsetup.components has all the scores group, contributors listed, and functions and parameters for each item. In defaultsetup.dependencies section describes the dependencies. E.g Health depends on Transformer health index and Tap changer health index , Transformer health index group calculated based on several contributors. Function details can be found in [ext_function_name] in the file named. E.g For Health ext_function_name is configured as [Health Weighted] , the implementation is common_calculate_weighted which is pre-defined in healthlib. Example Configuration [Common] name = IBM Transformers Tap Changers DGA 5.0.0 desc = Transformers tap changers dga model notebook = IBM-Transformers-Tap-Changers-DGA-5.0.0 job = Run-IBM-Transformers-Tap-Changers-DGA-4-0-0 usewith = asset,locations defaultsetup.components = type, name, ext_function_name, description, parameters \"CONTRIBUTOR\",\"Bushing condition\", \"Bushing Condition\", \"Bushing condition contributor\",\"Condition meter=B-CONDIT\" \"CONTRIBUTOR\",\"Oil leaks\",\"Oil Leaks\",\"Oil leaks contributor\",\"Condition meter=OIL-LEAKS\" \"CONTRIBUTOR\",\"Main Tank/Cabinets and control condition\",\"Main Tank/Cabinets and Control Condition\",\"Main Tank/Cabinets and control condition contributor\",\"Condition meter=MAIN-TCC\" \"CONTRIBUTOR\",\"Conservator/Oil preservation system condition\",\"Conservator/Oil Preservation System Condition\",\"Conservator/Oil preservation system condition contributor\",\"Condition meter=CO-PRES\" \"CONTRIBUTOR\",\"Radiators/Cooling system condition\",\"Radiators/Cooling System Condition\",\"Radiators/Cooling system condition contributor\",\"Condition meter=RC-SYS\" \"CONTRIBUTOR\",\"Foundation/Support Steel/Grounding condition\",\"Foundation/Support Steel/Grounding Condition\",\"Foundation/Support Steel/Grounding condition contributor\",\"Condition meter=FS-SG\" \"CONTRIBUTOR\",\"Overall power transformer condition\",\"Overall Power Transformer Condition\",\"Overall Power Transformer Condition contributor\",\"Condition meter=OVER-PT\" \"CONTRIBUTOR\",\"Winding doble test\",\"Winding Doble Test\",\"Winding Doble Test contributor\",\"Condition meter=WINDDT\" \"CONTRIBUTOR\",\"Oil quality test\",\"Oil Quality Test\",\"Oil Quality Test contributor\",\"Condition meter=OIL-QT\" \"CONTRIBUTOR\",\"Thermograph (IR)\",\"Thermograph (IR)\",\"Thermograph (IR) contributor\",\"Condition meter=ST-THERM\" \"CONTRIBUTOR\",\"Bushing DGA analysis\",\"Bushing DGA Analysis\",\"Bushing DGA Analysis contributor\",\"Condition meter=B-DGAOA\" \"CONTRIBUTOR\",\"Furan oil analysis\",\"Furan Oil Analysis\",\"Furan Oil Analysis contributor\",\"Condition meter=FUR-OA\" \"CONTRIBUTOR\",\"DGA oil analysis\",\"DGA Oil Analysis\",\"DGA Oil Analysis contributor\",\"H2 meter=DGAR-H2,CH4 meter=DGAR-CH4,C2H6 meter=DGAR-C2H6,C2H4 meter=DGAR-C2H4,C2H2 meter=DGAR-C2H2,CO meter=DGAR-CO,CO2 meter=DGAR-CO2\" \"GROUP\", \"Transformer health index\",\"Group\",\"Transformer Health Index Formulation\", \"CONTRIBUTOR\",\"Tap changer tank condition\",\"Tap Changer Tank Condition\",\"Tap Changer Tank Condition contributor\",\"Condition meter=TANK-CON\" \"CONTRIBUTOR\",\"Tap changer tank leaks\",\"Tap Changer Tank Leaks\",\"Tap Changer Tank Leaks contributor\",\"Condition meter=TANK-L\" \"CONTRIBUTOR\",\"Tap changer gaskets, seals and pressure relief condition\",\"Tap Changer Gaskets, Seals and Pressure Relief Condition\",\"Tap Changer Gaskets, Seals and Pressure Relief Condition contributor\",\"Condition meter=GS-PR\" \"CONTRIBUTOR\",\"Tap changer LTC control and mechanism cabinet\",\"Tap Changer LTC Control and Mechanism Cabinet\",\"Tap Changer LTC Control and Mechanism Cabinet contributor\",\"Condition meter=LTC-CMC\" \"CONTRIBUTOR\",\"Tap changer control and mechanism cabinet component condition\",\"Tap Changer Control and Mechanism Cabinet Component Condition\",\"Tap Changer Control and Mechanism Cabinet Component Condition contributor\",\"Condition meter=CTRMEC-CO\" \"CONTRIBUTOR\",\"Overall tap changer condition\",\"Overall Tap Changer Condition\",\"Overall Tap Changer Condition contributor\",\"Condition meter=OVER-TCC\" \"CONTRIBUTOR\",\"Tap changer oil analysis (DGA Metal Content)\",\"Tap Changer Oil Analysis (DGA Metal Content)\",\"Tap Changer Oil Analysis (DGA Metal Content) contributor\",\"Condition meter=TC-OQT\" \"CONTRIBUTOR\",\"Tap changer oil quality test\",\"Tap Changer Oil Quality Test\",\"Tap Changer Oil Quality Test contributor\",\"Condition meter=TC-QT\" \"GROUP\", \"Tap changer health index\",\"Group\",\"Tap Changer Health Index Formulation\", \"CONTRIBUTOR\", \"Age\", \"Age\", \"Age function contributor\",\"\" \"CONTRIBUTOR\", \"Number of customer\", \"Number of Customer\", \"Number of Customer contributor\",\"NOC attribute=NUMBEROFCUSTOMERS,Feeder attribute=FEEDER\" \"SCORE\", \"Health\", \"Health Weighted\", \"Weighted health calculation\", \"SCORE\", \"Effective age\", \"Effective Age\", \"Effective Age of the asset\",\"Mean life=30\" \"SCORE\", \"End of life\", \"End Of Life\", \"End of Life of the asset\", \"SCORE\", \"Criticality\", \"Criticality\", \"Criticality of the asset\", \"SCORE\", \"Risk\", \"Risk\", \"Risk of the asset\", \"SCORE\", \"Duval triangle score\", \"Duval Triangle Score\",\"Duval triangle for dissolved gas analysis\", \"SCORE\", \"History of combustible gas concentration\", \"DGA Trend Score\",\"History of combustible gas concentration\", defaultsetup.dependencies = parent, child, role, weight \"Transformer health index\",\"Bushing condition\",,\"3\" \"Transformer health index\",\"Oil leaks\",,\"3\" \"Transformer health index\",\"Main Tank/Cabinets and control condition\",,\"3\" \"Transformer health index\",\"Conservator/Oil preservation system condition\",,\"3\" \"Transformer health index\",\"Radiators/Cooling system condition\",,\"3\" \"Transformer health index\",\"Foundation/Support Steel/Grounding condition\",,\"3\" \"Transformer health index\",\"Overall power transformer condition\",,\"8\" \"Transformer health index\",\"Winding doble test\",,\"14\" \"Transformer health index\",\"Oil quality test\",,\"10\" \"Transformer health index\",\"Thermograph (IR)\",,\"8\" \"Transformer health index\",\"Bushing DGA analysis\",,\"14\" \"Transformer health index\",\"Furan oil analysis\",,\"14\" \"Transformer health index\",\"DGA oil analysis\",,\"14\" \"Health\",\"Transformer health index\",,\"80\" \"Tap changer health index\",\"Tap changer tank condition\",,\"6\" \"Tap changer health index\",\"Tap changer tank leaks\",,\"6\" \"Tap changer health index\",\"Tap changer gaskets, seals and pressure relief condition\",,\"6\" \"Tap changer health index\",\"Tap changer LTC control and mechanism cabinet\",,\"6\" \"Tap changer health index\",\"Tap changer control and mechanism cabinet component condition\",,\"6\" \"Tap changer health index\",\"Overall tap changer condition\",,\"21\" \"Tap changer health index\",\"Tap changer oil analysis (DGA Metal Content)\",, \"28\" \"Tap changer health index\",\"Tap changer oil quality test\",,\"21\" \"Health\",\"Tap changer health index\",,\"20\" \"Criticality\", \"Number of customer\",,\"100\" \"Effective age\", \"Health\", \"HEALTH\", \"\" \"Effective age\", \"Age\", \"AGE\", \"\" \"End of life\", \"Effective age\", \"EFFECTIVEAGE\",\"\" \"Risk\", \"Criticality\", \"CRITICALITY\", \"\" \"Risk\", \"End of life\", \"EOL\", \"\" ....... [Group] type = GROUP desc = Group of contributors impl = common_calculate_weighted calctype = WEIGHT [Health Weighted] type = SCORE scoretype = HEALTH desc = Weighted scores from each contributor impl = common_calculate_weighted calctype = WEIGHT [End Of Life] type = SCORE scoretype = EOL desc = End of life of the asset impl = common_calculate_end_of_life calctype = NONE roles = EFFECTIVEAGE parameter.curve.name = Curve parameter.curve.type = string parameter.curve.desc = Curve of assets parameter.curve.default = 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100 [Effective Age] type = SCORE scoretype = EFFECTIVEAGE desc = Effective age score impl = common_calculate_effective_age calctype = NONE roles = HEALTH,AGE # parameter.<id>.<item> parameter.mean_life.name = Mean life parameter.mean_life.type = number parameter.mean_life.format = decimal parameter.mean_life.desc = mean life of the asset parameter.mean_life.default = 30 [Criticality] type = SCORE scoretype = CRITICALITY desc = Criticality score impl = common_calculate_weighted calctype = WEIGHT [Risk] type = SCORE scoretype = RISK desc = Risk score impl = common_calculate_risk roles = EOL,CRITICALITY calctype = NONE Below is the dependency of out of the box Substation Transformer scores. Substation Transformer Model Notebook For ST(Substation Transformer), notebook is IBM-Transformers-Tap-Changers-DGA-5.0.0.ipynb as configured in cfg file. Any permenant modification on notebook, will need save to a latest version to take affect, because each job binds with a version of the notebook, by default it's the Latest version. ST Watson Studio Job Job is Run-IBM-Transformers-Tap-Changers-DGA-4-0-0.Details and can be checked using the steps below. 1. Login to Watson Studio, enter the project, and click the Job tab, click the job defined in configruation file, and then click Edit Configuration , click Next and Next , we can see by default it binds to latest version and runtime is Default Python 3.8 , close the edit page by clicking X on the right corner. 2. Log can be checked by clicking on one of the history runs, either check directly on the page or download to local. Customize Notebook Model for NOC Users can change how the scores are calculated as needed in the Notebooks. For example, for customize the Criticality which is calculated 100% weight of NOC (Number Of Customers) by default. Login Watson Studio, enter the project, click the Assets tab, enter the notebook IBM-Transformers-Tap-Changers-DGA-5.0.0.ipynb ,find the cell which defined function calculate_number_of_customer , comment out the old code, and write new customize NOC functiion based on customer's own methodology. Then save a latest version. //Code example. @maximo_function def calculate_number_of_customer(context,targetType=None): //Input customized logic here...... logger = healthlib.get_logger() noc_attr = context.get_parameter(name='NOC attribute') logger.debug('Noc attribute=%s', noc_attr) noc = context.get_spec(noc_attr) logger.debug('noc=%s', noc) result = min(100,max(0, 100 * noc/10000)) return result Update scheduler for cron task instance created during score group set up User can change the schedule by changing the crontask instance's schedule. 1. Login and go to Health and Predict Utilities application, click Scoring and DGA settings in the menu, and search for the score group just created, click to enter the group details page to get the group id which later will be used to find the corresponding crontask instance. 2. Click Administration administration to go to Administration page. Then click Cron Task Setup to enter the crontask application. 3. Search for AHSCORINGGROUP cron task. And click to enter the crontask detail page. User can trigger the analysis by clcik Reload Request under More actions , choose the crontask instance that matches score group id. User can also click calendar icon to update the schedule for the cron task instance which has the same id as group id. Troubleshoot Enable Debug Mode For a small group of assets, user can enable debug mode for debugging the model. Login Watson Studio, enter the project, click the Assets tab, enter the notebook IBM-Transformers-Tap-Changers-DGA-5.0.0.ipynb , click the pencil icon to edit,find the cell healthlib.set_log_level(level='INFO') , change to healthlib.set_log_level(level='DEBUG') .Then save to a latest version. Login Health and Predict Utilities application, go to Scoring and DGA settings , enter the related group, click the Recalculate scores to trigger a new analysis. After the calculation finishes, go back to Watson Studio, click the Job tab, then click the correspoding job for the score group. A new page will open where user can edit the job and or check the job history. Click latest finished job history to check the debug logs. Run Notebook Directly for Debugging Purpose If user want to directly run the notebook to calculate the score for debug purpose instead of the job, user can add some enviroment variables in notebook temporarily. 1. Login Watson Studio, enter the project, click the Assets tab, enter the notebook IBM-Transformers-Tap-Changers-DGA-5.0.0.ipynb , click the pencil icon to edit. Click plus button to add a new cell on top, and put below code sample with actual value. Here are some code examples for debugging . Code example for debugging on a certain score group. import os os.environ['maximo_context'] = '{\"maximoUrl\":\"https://<health or manage host>/maximo/\",\"maximoApiKey\":\"**************\",\"expgroupname\":\"1003\"}' Code example for debugging on an individule asset. import os os.environ['maximo_context'] = '{\"maximoUrl\":\"https://<health or manage host>/maximo/\",\"maximoApiKey\":\"**************\",\"expgroupname\":\"1003\",\"siteid\":\"***\",\"assetnum\":\"***\"}' maximoApiKey can be found in Application administration page. Login Health and Predict \u2013 Utilities and click the Application administration page, click to the Start Center and in the Go To section, click Administration.On the API Keys tab, search and find maxadmin's apikey. expgroupname can be found in score group detail page. For <health or manage host> in maximoUrl can be extracted from health url. 2. Click Run to run cell by cell or restart the kernel run the whole notebook. Note When debugging in notebook directly, do not save as latest version, since it's hardcoded. The corresponding job should instead get those inputs from Health during the runtime. Congratulation you learned about the Substation Transformer Models included with Health and Predict - Utilities (HPU) and create a Score Groups. You also can now modify, schedule and debug the model notebooks.","title":"Understand Health and Predict - Utilities Models"},{"location":"hpu_models/#understand-utilities-models","text":"In this exercise, you will learn: To use the Substation Transformer Models included with Health and Predict - Utilities (HPU). Create a Score Group for Substation Transformer Assets. Update and Schedule Notebooks for Utilities. Troubleshoot Notebooks for Utilities. Pre-requisites Ensure you have access to : MAS v8.8 Health and Predict Utilities HPU dataloader URL Waston studio access Sample ST(Substation Transformer) data for HPU, and make sure required data are loaded through dataloader via App Connect. Check out the sample data folder structure as below.","title":"Understand Utilities Models"},{"location":"hpu_models/#out-of-the-box-models","text":"Health and Predict - Utilities includes the supported Asset Classes listed in table below: Asset class Model DISTRIBUTION TRANSFORMER IBM Transformers Tap Changers 5.0.0 SUBSTATION TRANSFORMER IBM Transformers Tap Changers 5.0.0,IBM Transformers Tap Changers DGA 5.0.0 INSTRUMENT TRANSFORMER IBM Instrument Transformers Oil Filled CTs 5.0.0 SWITCHGEAR IBM Gas Insulated Switchgear 5.0.0 UNDERGROUND TRANSMISSION MANHOLE IBM Underground Transmission Manholes 5.0.0 METAL SUPPORT STRUCTURE IBM Metal Support Structures 5.0.0 OVERHEAD TRANSMISSION WIRE IBM Conductors 5.0.0 POLE - Wood Power Pole IBM Wood Pole Structures 5.0.0 CIRCUITBREAKER - Oil Circuit Breaker IBM Circuit Breakers Oil 5.0.0 CIRCUITBREAKER - Air Blast Circuit Breaker IBM Circuit Breakers Air Blast 5.0.0 CIRCUITBREAKER - Air Magnetic Circuit Breaker IBM Circuit Breakers Air Magnetic 5.0.0 CIRCUITBREAKER - Vacuum Circuit Breaker IBM Circuit Breakers Vacuum 5.0.0 CIRCUITBREAKER - SF6 Circuit Breaker IBM Circuit Breakers SF6 5.0.0 UNDERGROUNDTRANSMISSIONCABLE - High Pressure Fluid Filled Pipe Type (HPFF) Cables IBM HPFF Cables 5.0.0 UNDERGROUNDTRANSMISSIONCABLE - Mass Impregnated (MI) Cables IBM MI Cables 5.0.0 UNDERGROUNDTRANSMISSIONCABLE - Self Contained Fluid Filled (SCFF) Cables IBM SCFF Cables 5.0.0 UNDERGROUNDTRANSMISSIONCABLE - Self Contained Gas Filled (SCGF) Submarine Cables IBM SCGF Cables 5.0.0 UNDERGROUNDTRANSMISSIONCABLE - Extruded Cross Linked Polyethylene (XLPE) Cables IBM XLPE Cables 5.0.0 Note Some asset classes have subtype, like Circuit Breaker or Underground Transmission Cable HPU Model Calculation Methodology","title":"Out Of The Box Models"},{"location":"hpu_models/#create-a-score-group","text":"Create a Score Group for Substation Transformer Assets 1. Login and go to Health and Predict Utilities application. 2. Click Scoring and DGA settings in the menu,in Scoring and DGA settings page, click Create a scoring and DGA group button. 3. In the create score group page,fill in name,description, select Asset object,choose Connectigng group to notebook . 4. Then click Select to choose IBM Transformers Tap Changers DGA 5.0.0 notebook in the notebook list dialog,click Use notebook . 5. Scroll down query part, click Select to open query dialog, user can select an existing query, or click + button to create a new query for ST assets. E.g Select site and classification for the new query. 6. After select the notebook and query, click Create to create the score group. 7. After score group is created, system will redirect to the score group detail page, in this page, user can see all the scores and the asset list. 8. Click the score in the table, and active it on the right, scores need to be activated one by one based on the dependency. 9. After activating all the scores, click the Recalculate scores to start the analysis.","title":"Create a Score Group"},{"location":"hpu_models/#update-and-schedule-notebooks","text":"In this exercise you will check the notebook configuration file, notebook and the job, also update the notebook and save to latest version. You will also schedule Jobs to run the notebooks and do asset scoring by changing the cron task schedule. In Health and Predict - Utilities, the scoring calculation happen in Watson Studio jobs. Each asset type has a configure file, notebook, and job deployed on Watson Studio project. When user clicks Recalculate scores on UI, it triggers the job to run, do the calculation, and save results to the Database.","title":"Update and Schedule Notebooks"},{"location":"hpu_models/#substation-transformer-model-configuration","text":"For ST (Substation Transformer), configuration file is named IBM-Transformers-Tap-Changers-DGA-5.0.0.cfg . In the configuration file, under Common section defaultsetup.components has all the scores group, contributors listed, and functions and parameters for each item. In defaultsetup.dependencies section describes the dependencies. E.g Health depends on Transformer health index and Tap changer health index , Transformer health index group calculated based on several contributors. Function details can be found in [ext_function_name] in the file named. E.g For Health ext_function_name is configured as [Health Weighted] , the implementation is common_calculate_weighted which is pre-defined in healthlib. Example Configuration [Common] name = IBM Transformers Tap Changers DGA 5.0.0 desc = Transformers tap changers dga model notebook = IBM-Transformers-Tap-Changers-DGA-5.0.0 job = Run-IBM-Transformers-Tap-Changers-DGA-4-0-0 usewith = asset,locations defaultsetup.components = type, name, ext_function_name, description, parameters \"CONTRIBUTOR\",\"Bushing condition\", \"Bushing Condition\", \"Bushing condition contributor\",\"Condition meter=B-CONDIT\" \"CONTRIBUTOR\",\"Oil leaks\",\"Oil Leaks\",\"Oil leaks contributor\",\"Condition meter=OIL-LEAKS\" \"CONTRIBUTOR\",\"Main Tank/Cabinets and control condition\",\"Main Tank/Cabinets and Control Condition\",\"Main Tank/Cabinets and control condition contributor\",\"Condition meter=MAIN-TCC\" \"CONTRIBUTOR\",\"Conservator/Oil preservation system condition\",\"Conservator/Oil Preservation System Condition\",\"Conservator/Oil preservation system condition contributor\",\"Condition meter=CO-PRES\" \"CONTRIBUTOR\",\"Radiators/Cooling system condition\",\"Radiators/Cooling System Condition\",\"Radiators/Cooling system condition contributor\",\"Condition meter=RC-SYS\" \"CONTRIBUTOR\",\"Foundation/Support Steel/Grounding condition\",\"Foundation/Support Steel/Grounding Condition\",\"Foundation/Support Steel/Grounding condition contributor\",\"Condition meter=FS-SG\" \"CONTRIBUTOR\",\"Overall power transformer condition\",\"Overall Power Transformer Condition\",\"Overall Power Transformer Condition contributor\",\"Condition meter=OVER-PT\" \"CONTRIBUTOR\",\"Winding doble test\",\"Winding Doble Test\",\"Winding Doble Test contributor\",\"Condition meter=WINDDT\" \"CONTRIBUTOR\",\"Oil quality test\",\"Oil Quality Test\",\"Oil Quality Test contributor\",\"Condition meter=OIL-QT\" \"CONTRIBUTOR\",\"Thermograph (IR)\",\"Thermograph (IR)\",\"Thermograph (IR) contributor\",\"Condition meter=ST-THERM\" \"CONTRIBUTOR\",\"Bushing DGA analysis\",\"Bushing DGA Analysis\",\"Bushing DGA Analysis contributor\",\"Condition meter=B-DGAOA\" \"CONTRIBUTOR\",\"Furan oil analysis\",\"Furan Oil Analysis\",\"Furan Oil Analysis contributor\",\"Condition meter=FUR-OA\" \"CONTRIBUTOR\",\"DGA oil analysis\",\"DGA Oil Analysis\",\"DGA Oil Analysis contributor\",\"H2 meter=DGAR-H2,CH4 meter=DGAR-CH4,C2H6 meter=DGAR-C2H6,C2H4 meter=DGAR-C2H4,C2H2 meter=DGAR-C2H2,CO meter=DGAR-CO,CO2 meter=DGAR-CO2\" \"GROUP\", \"Transformer health index\",\"Group\",\"Transformer Health Index Formulation\", \"CONTRIBUTOR\",\"Tap changer tank condition\",\"Tap Changer Tank Condition\",\"Tap Changer Tank Condition contributor\",\"Condition meter=TANK-CON\" \"CONTRIBUTOR\",\"Tap changer tank leaks\",\"Tap Changer Tank Leaks\",\"Tap Changer Tank Leaks contributor\",\"Condition meter=TANK-L\" \"CONTRIBUTOR\",\"Tap changer gaskets, seals and pressure relief condition\",\"Tap Changer Gaskets, Seals and Pressure Relief Condition\",\"Tap Changer Gaskets, Seals and Pressure Relief Condition contributor\",\"Condition meter=GS-PR\" \"CONTRIBUTOR\",\"Tap changer LTC control and mechanism cabinet\",\"Tap Changer LTC Control and Mechanism Cabinet\",\"Tap Changer LTC Control and Mechanism Cabinet contributor\",\"Condition meter=LTC-CMC\" \"CONTRIBUTOR\",\"Tap changer control and mechanism cabinet component condition\",\"Tap Changer Control and Mechanism Cabinet Component Condition\",\"Tap Changer Control and Mechanism Cabinet Component Condition contributor\",\"Condition meter=CTRMEC-CO\" \"CONTRIBUTOR\",\"Overall tap changer condition\",\"Overall Tap Changer Condition\",\"Overall Tap Changer Condition contributor\",\"Condition meter=OVER-TCC\" \"CONTRIBUTOR\",\"Tap changer oil analysis (DGA Metal Content)\",\"Tap Changer Oil Analysis (DGA Metal Content)\",\"Tap Changer Oil Analysis (DGA Metal Content) contributor\",\"Condition meter=TC-OQT\" \"CONTRIBUTOR\",\"Tap changer oil quality test\",\"Tap Changer Oil Quality Test\",\"Tap Changer Oil Quality Test contributor\",\"Condition meter=TC-QT\" \"GROUP\", \"Tap changer health index\",\"Group\",\"Tap Changer Health Index Formulation\", \"CONTRIBUTOR\", \"Age\", \"Age\", \"Age function contributor\",\"\" \"CONTRIBUTOR\", \"Number of customer\", \"Number of Customer\", \"Number of Customer contributor\",\"NOC attribute=NUMBEROFCUSTOMERS,Feeder attribute=FEEDER\" \"SCORE\", \"Health\", \"Health Weighted\", \"Weighted health calculation\", \"SCORE\", \"Effective age\", \"Effective Age\", \"Effective Age of the asset\",\"Mean life=30\" \"SCORE\", \"End of life\", \"End Of Life\", \"End of Life of the asset\", \"SCORE\", \"Criticality\", \"Criticality\", \"Criticality of the asset\", \"SCORE\", \"Risk\", \"Risk\", \"Risk of the asset\", \"SCORE\", \"Duval triangle score\", \"Duval Triangle Score\",\"Duval triangle for dissolved gas analysis\", \"SCORE\", \"History of combustible gas concentration\", \"DGA Trend Score\",\"History of combustible gas concentration\", defaultsetup.dependencies = parent, child, role, weight \"Transformer health index\",\"Bushing condition\",,\"3\" \"Transformer health index\",\"Oil leaks\",,\"3\" \"Transformer health index\",\"Main Tank/Cabinets and control condition\",,\"3\" \"Transformer health index\",\"Conservator/Oil preservation system condition\",,\"3\" \"Transformer health index\",\"Radiators/Cooling system condition\",,\"3\" \"Transformer health index\",\"Foundation/Support Steel/Grounding condition\",,\"3\" \"Transformer health index\",\"Overall power transformer condition\",,\"8\" \"Transformer health index\",\"Winding doble test\",,\"14\" \"Transformer health index\",\"Oil quality test\",,\"10\" \"Transformer health index\",\"Thermograph (IR)\",,\"8\" \"Transformer health index\",\"Bushing DGA analysis\",,\"14\" \"Transformer health index\",\"Furan oil analysis\",,\"14\" \"Transformer health index\",\"DGA oil analysis\",,\"14\" \"Health\",\"Transformer health index\",,\"80\" \"Tap changer health index\",\"Tap changer tank condition\",,\"6\" \"Tap changer health index\",\"Tap changer tank leaks\",,\"6\" \"Tap changer health index\",\"Tap changer gaskets, seals and pressure relief condition\",,\"6\" \"Tap changer health index\",\"Tap changer LTC control and mechanism cabinet\",,\"6\" \"Tap changer health index\",\"Tap changer control and mechanism cabinet component condition\",,\"6\" \"Tap changer health index\",\"Overall tap changer condition\",,\"21\" \"Tap changer health index\",\"Tap changer oil analysis (DGA Metal Content)\",, \"28\" \"Tap changer health index\",\"Tap changer oil quality test\",,\"21\" \"Health\",\"Tap changer health index\",,\"20\" \"Criticality\", \"Number of customer\",,\"100\" \"Effective age\", \"Health\", \"HEALTH\", \"\" \"Effective age\", \"Age\", \"AGE\", \"\" \"End of life\", \"Effective age\", \"EFFECTIVEAGE\",\"\" \"Risk\", \"Criticality\", \"CRITICALITY\", \"\" \"Risk\", \"End of life\", \"EOL\", \"\" ....... [Group] type = GROUP desc = Group of contributors impl = common_calculate_weighted calctype = WEIGHT [Health Weighted] type = SCORE scoretype = HEALTH desc = Weighted scores from each contributor impl = common_calculate_weighted calctype = WEIGHT [End Of Life] type = SCORE scoretype = EOL desc = End of life of the asset impl = common_calculate_end_of_life calctype = NONE roles = EFFECTIVEAGE parameter.curve.name = Curve parameter.curve.type = string parameter.curve.desc = Curve of assets parameter.curve.default = 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100 [Effective Age] type = SCORE scoretype = EFFECTIVEAGE desc = Effective age score impl = common_calculate_effective_age calctype = NONE roles = HEALTH,AGE # parameter.<id>.<item> parameter.mean_life.name = Mean life parameter.mean_life.type = number parameter.mean_life.format = decimal parameter.mean_life.desc = mean life of the asset parameter.mean_life.default = 30 [Criticality] type = SCORE scoretype = CRITICALITY desc = Criticality score impl = common_calculate_weighted calctype = WEIGHT [Risk] type = SCORE scoretype = RISK desc = Risk score impl = common_calculate_risk roles = EOL,CRITICALITY calctype = NONE Below is the dependency of out of the box Substation Transformer scores.","title":"Substation Transformer Model Configuration"},{"location":"hpu_models/#substation-transformer-model-notebook","text":"For ST(Substation Transformer), notebook is IBM-Transformers-Tap-Changers-DGA-5.0.0.ipynb as configured in cfg file. Any permenant modification on notebook, will need save to a latest version to take affect, because each job binds with a version of the notebook, by default it's the Latest version.","title":"Substation Transformer Model Notebook"},{"location":"hpu_models/#st-watson-studio-job","text":"Job is Run-IBM-Transformers-Tap-Changers-DGA-4-0-0.Details and can be checked using the steps below. 1. Login to Watson Studio, enter the project, and click the Job tab, click the job defined in configruation file, and then click Edit Configuration , click Next and Next , we can see by default it binds to latest version and runtime is Default Python 3.8 , close the edit page by clicking X on the right corner. 2. Log can be checked by clicking on one of the history runs, either check directly on the page or download to local.","title":"ST Watson Studio Job"},{"location":"hpu_models/#customize-notebook-model-for-noc","text":"Users can change how the scores are calculated as needed in the Notebooks. For example, for customize the Criticality which is calculated 100% weight of NOC (Number Of Customers) by default. Login Watson Studio, enter the project, click the Assets tab, enter the notebook IBM-Transformers-Tap-Changers-DGA-5.0.0.ipynb ,find the cell which defined function calculate_number_of_customer , comment out the old code, and write new customize NOC functiion based on customer's own methodology. Then save a latest version. //Code example. @maximo_function def calculate_number_of_customer(context,targetType=None): //Input customized logic here...... logger = healthlib.get_logger() noc_attr = context.get_parameter(name='NOC attribute') logger.debug('Noc attribute=%s', noc_attr) noc = context.get_spec(noc_attr) logger.debug('noc=%s', noc) result = min(100,max(0, 100 * noc/10000)) return result","title":"Customize Notebook Model for NOC"},{"location":"hpu_models/#update-scheduler-for-cron-task-instance-created-during-score-group-set-up","text":"User can change the schedule by changing the crontask instance's schedule. 1. Login and go to Health and Predict Utilities application, click Scoring and DGA settings in the menu, and search for the score group just created, click to enter the group details page to get the group id which later will be used to find the corresponding crontask instance. 2. Click Administration administration to go to Administration page. Then click Cron Task Setup to enter the crontask application. 3. Search for AHSCORINGGROUP cron task. And click to enter the crontask detail page. User can trigger the analysis by clcik Reload Request under More actions , choose the crontask instance that matches score group id. User can also click calendar icon to update the schedule for the cron task instance which has the same id as group id.","title":"Update scheduler for cron task instance created during score group set up"},{"location":"hpu_models/#troubleshoot","text":"","title":"Troubleshoot"},{"location":"hpu_models/#enable-debug-mode","text":"For a small group of assets, user can enable debug mode for debugging the model. Login Watson Studio, enter the project, click the Assets tab, enter the notebook IBM-Transformers-Tap-Changers-DGA-5.0.0.ipynb , click the pencil icon to edit,find the cell healthlib.set_log_level(level='INFO') , change to healthlib.set_log_level(level='DEBUG') .Then save to a latest version. Login Health and Predict Utilities application, go to Scoring and DGA settings , enter the related group, click the Recalculate scores to trigger a new analysis. After the calculation finishes, go back to Watson Studio, click the Job tab, then click the correspoding job for the score group. A new page will open where user can edit the job and or check the job history. Click latest finished job history to check the debug logs.","title":"Enable Debug Mode"},{"location":"hpu_models/#run-notebook-directly-for-debugging-purpose","text":"If user want to directly run the notebook to calculate the score for debug purpose instead of the job, user can add some enviroment variables in notebook temporarily. 1. Login Watson Studio, enter the project, click the Assets tab, enter the notebook IBM-Transformers-Tap-Changers-DGA-5.0.0.ipynb , click the pencil icon to edit. Click plus button to add a new cell on top, and put below code sample with actual value. Here are some code examples for debugging . Code example for debugging on a certain score group. import os os.environ['maximo_context'] = '{\"maximoUrl\":\"https://<health or manage host>/maximo/\",\"maximoApiKey\":\"**************\",\"expgroupname\":\"1003\"}' Code example for debugging on an individule asset. import os os.environ['maximo_context'] = '{\"maximoUrl\":\"https://<health or manage host>/maximo/\",\"maximoApiKey\":\"**************\",\"expgroupname\":\"1003\",\"siteid\":\"***\",\"assetnum\":\"***\"}' maximoApiKey can be found in Application administration page. Login Health and Predict \u2013 Utilities and click the Application administration page, click to the Start Center and in the Go To section, click Administration.On the API Keys tab, search and find maxadmin's apikey. expgroupname can be found in score group detail page. For <health or manage host> in maximoUrl can be extracted from health url. 2. Click Run to run cell by cell or restart the kernel run the whole notebook. Note When debugging in notebook directly, do not save as latest version, since it's hardcoded. The corresponding job should instead get those inputs from Health during the runtime. Congratulation you learned about the Substation Transformer Models included with Health and Predict - Utilities (HPU) and create a Score Groups. You also can now modify, schedule and debug the model notebooks.","title":"Run Notebook Directly for Debugging Purpose"},{"location":"matrix/","text":"Asset Matrix Maximo HP Utilities includes matrix view for determing the distribution of assets based on scores and then take action to avoid imminent failures. In this exercise the Reliability Engineer uses HP Utilities to: View Matrix for Criticality and End of life, Criticality and Risk, Criticality and Health View the drilled in assets list and take action Config Matrix version Pre-requisites This lab requires the following A working Maximo Application Suite (MAS) 8.8+ environment with Maximo Manage, or another Enterprise Asset Management (EAM) system, Maximo Health, Maximo Health and Predict \u2013 Utilities (HPU), and Maximo Optimizer installed Make sure the exercise Understand Health and Predict - Utilities Models is done, so that Sample ST(Substation Transformer) assets have the EOL/Risk/Health scores Members of the EUSCORING security group can configure settings for the matrix , such as which version of the matrix is the default version and the colors and placement of cells. Please note that the MAS Worldwide (WW) demo environment is NOT a suitable environment for this lab. The WW demo environment is shared, and making ANY changes to that environment will impact other users\u2019 ability to demonstrate MAS. Introduction This lab is intended to demonstrate the Matrix view capability in HPU which is another view added in MAS v8.8 to the existing Grid view, Map view, Charts View. It allows Reliability engineer to esaily idenfity the high risk assets from a matrix distribution view and take actions based on the distributions. Reliability engineer can also easily config the different matrix versions, like to change the default version, disable version, change the matrix cells' color(category) etc. Navigate to Health and Predict - Utilities Action: Navigate to Health and Predict - Utilities (HPU). From the main MAS page, select the Industry solutions tab. Then click Health and Predict \u2013 Utilities menu. View Matrix for Criticality and End of life, Criticality and Risk, Criticality and Health Action: 1. From the asset grid view, click the Matrix icon, you will see the matrix, each cell contains the assets count which fall in the x-axis and y-axis range. For example, the red cell in the top right corner shows the assets that End of Life is high and Criticality is also High which means high risks. Besides cells, there are also several cards which is summarized count for the different categories of assets, normally High is for assets that need to take action in high priority. ![matrix view](./img/matrix_home.png) If there are too many assets in one cells or category, you can also use filter to reduce the counts. The followings are the detailed steps: click the filter icon, then select Type From the pop-up, find Substation Transformers , select it, and press OK . It may be necessary to use the search capability or scroll. Finally, press Apply , the Matrix count The default matrix version is Criticality and End of life, you can also click the dropdown on the top right corner to change to other matrix versions. View the drilled in assets list for one distribution Action: 1. Click any red cell of Matrix or 'High' need for action card with the blue text of number, you can see the detailed assets list. 2. In the drill in page, you can filter out the interested assets list by click the filter icon. 3. there are several actions that can be done in the drill in page: - Click one asset name, and go into asset detail page, create Work order or Service request - Add all assets to Asset Investment optimizer project - create a new project - add to existing project * please refer the Asset Investment Optimization for more details - select some assets by clicking the checkbox and create AIO project Config Matrix version We have by default configuration(including the Matrix cell category color/default version etc) for matrix versions, but those configuration can also be customized per business requirements. By default, High End of life with Criticality A/B are marked as High risk assets with red color, but for a short/mid-term maintainence plan, we can also add a new Matrix cell category color 'Medium High' to pay attentions. For this execise, we will change the cell color. Action: 1. Click the Config icon in the top right corner Click the Edit button under the Categories section Click the Add button to add a new category 'Medium High' by input the name, color, icon and click the order icon to adjust the sequence. Click the save button to save the changes Select the new added Matrix cell color category 'Medium High' and then click the cells that should be marked as the orange Click the save button, and the new Matrix view is updated Congratulations. You now have identified at risk assets from the matrix view and take actions to improve their condition.","title":"View and config Asset Matrix"},{"location":"matrix/#asset-matrix","text":"Maximo HP Utilities includes matrix view for determing the distribution of assets based on scores and then take action to avoid imminent failures. In this exercise the Reliability Engineer uses HP Utilities to: View Matrix for Criticality and End of life, Criticality and Risk, Criticality and Health View the drilled in assets list and take action Config Matrix version","title":"Asset Matrix"},{"location":"matrix/#pre-requisites","text":"This lab requires the following A working Maximo Application Suite (MAS) 8.8+ environment with Maximo Manage, or another Enterprise Asset Management (EAM) system, Maximo Health, Maximo Health and Predict \u2013 Utilities (HPU), and Maximo Optimizer installed Make sure the exercise Understand Health and Predict - Utilities Models is done, so that Sample ST(Substation Transformer) assets have the EOL/Risk/Health scores Members of the EUSCORING security group can configure settings for the matrix , such as which version of the matrix is the default version and the colors and placement of cells. Please note that the MAS Worldwide (WW) demo environment is NOT a suitable environment for this lab. The WW demo environment is shared, and making ANY changes to that environment will impact other users\u2019 ability to demonstrate MAS.","title":"Pre-requisites"},{"location":"matrix/#introduction","text":"This lab is intended to demonstrate the Matrix view capability in HPU which is another view added in MAS v8.8 to the existing Grid view, Map view, Charts View. It allows Reliability engineer to esaily idenfity the high risk assets from a matrix distribution view and take actions based on the distributions. Reliability engineer can also easily config the different matrix versions, like to change the default version, disable version, change the matrix cells' color(category) etc.","title":"Introduction"},{"location":"matrix/#navigate-to-health-and-predict-utilities","text":"Action: Navigate to Health and Predict - Utilities (HPU). From the main MAS page, select the Industry solutions tab. Then click Health and Predict \u2013 Utilities menu.","title":"Navigate to Health and Predict - Utilities"},{"location":"matrix/#view-matrix-for-criticality-and-end-of-life-criticality-and-risk-criticality-and-health","text":"Action: 1. From the asset grid view, click the Matrix icon, you will see the matrix, each cell contains the assets count which fall in the x-axis and y-axis range. For example, the red cell in the top right corner shows the assets that End of Life is high and Criticality is also High which means high risks. Besides cells, there are also several cards which is summarized count for the different categories of assets, normally High is for assets that need to take action in high priority. ![matrix view](./img/matrix_home.png) If there are too many assets in one cells or category, you can also use filter to reduce the counts. The followings are the detailed steps: click the filter icon, then select Type From the pop-up, find Substation Transformers , select it, and press OK . It may be necessary to use the search capability or scroll. Finally, press Apply , the Matrix count The default matrix version is Criticality and End of life, you can also click the dropdown on the top right corner to change to other matrix versions.","title":"View Matrix for Criticality and End of life, Criticality and Risk, Criticality and Health"},{"location":"matrix/#view-the-drilled-in-assets-list-for-one-distribution","text":"Action: 1. Click any red cell of Matrix or 'High' need for action card with the blue text of number, you can see the detailed assets list. 2. In the drill in page, you can filter out the interested assets list by click the filter icon. 3. there are several actions that can be done in the drill in page: - Click one asset name, and go into asset detail page, create Work order or Service request - Add all assets to Asset Investment optimizer project - create a new project - add to existing project * please refer the Asset Investment Optimization for more details - select some assets by clicking the checkbox and create AIO project","title":"View the drilled in assets list for one distribution"},{"location":"matrix/#config-matrix-version","text":"We have by default configuration(including the Matrix cell category color/default version etc) for matrix versions, but those configuration can also be customized per business requirements. By default, High End of life with Criticality A/B are marked as High risk assets with red color, but for a short/mid-term maintainence plan, we can also add a new Matrix cell category color 'Medium High' to pay attentions. For this execise, we will change the cell color. Action: 1. Click the Config icon in the top right corner Click the Edit button under the Categories section Click the Add button to add a new category 'Medium High' by input the name, color, icon and click the order icon to adjust the sequence. Click the save button to save the changes Select the new added Matrix cell color category 'Medium High' and then click the cells that should be marked as the orange Click the save button, and the new Matrix view is updated Congratulations. You now have identified at risk assets from the matrix view and take actions to improve their condition.","title":"Config Matrix version"},{"location":"prereqs/","text":"Pre-Requisite Instructions This Hands on Lab requires: Your instructor has provided you the data, Python scripts, functions and notebooks used in the lab. An account for IBM ID. If you don't have an IBM ID you can get one here : Click Login to MY IBM button Click Create an IBM ID link Access to a Maximo Application Suite v8.7 environment. Request access from your instructor. Access to Watson Studio to build and test your asset models. Request access from your instructor. Working knowledge of using Jupyter notebooks to edit and test models. See this reference Understanding of Pandas Python library for processing timeseries data. See these references. Tutorial on Using Pandas Basic Time Series Manipulation with Pandas Using Pandas timeseries and dates Internet access to these lab instructions User access to a Maximo Application Suite environment. Your Exercise facilitator can provide you with the information to access the environment. Test your access to the Maximo Application Suite environment. Optional Exercises You can skip Install and Configure App Connect exercise if you are loading data using notebooks or if your instructor has already loaded asset data into your environment. The Install and Configure App Connect exercise requires that you either use the provided App Connect Add On included with Maximo Application Suite or follow the Lab exercises instructions to install and setup App Connect.","title":"Pre-Requisites"},{"location":"prereqs/#pre-requisite-instructions","text":"This Hands on Lab requires: Your instructor has provided you the data, Python scripts, functions and notebooks used in the lab. An account for IBM ID. If you don't have an IBM ID you can get one here : Click Login to MY IBM button Click Create an IBM ID link Access to a Maximo Application Suite v8.7 environment. Request access from your instructor. Access to Watson Studio to build and test your asset models. Request access from your instructor. Working knowledge of using Jupyter notebooks to edit and test models. See this reference Understanding of Pandas Python library for processing timeseries data. See these references. Tutorial on Using Pandas Basic Time Series Manipulation with Pandas Using Pandas timeseries and dates Internet access to these lab instructions User access to a Maximo Application Suite environment. Your Exercise facilitator can provide you with the information to access the environment. Test your access to the Maximo Application Suite environment.","title":"Pre-Requisite Instructions"},{"location":"prereqs/#optional-exercises","text":"You can skip Install and Configure App Connect exercise if you are loading data using notebooks or if your instructor has already loaded asset data into your environment. The Install and Configure App Connect exercise requires that you either use the provided App Connect Add On included with Maximo Application Suite or follow the Lab exercises instructions to install and setup App Connect.","title":"Optional Exercises"},{"location":"release_notes/","text":"Contributors to IBM Maximo APM V8.7 Lab Carlos Ferreira - carlosyells@yahoo.com Hannah Carr Juan Gu - gujuan@cn.ibm.com Satish Narasimha - ssnarasi@in.ibm.com Kewei Yang John Douglas Amy Huang Amaresh Rajasekharan Lan Cao - caolan@cn.ibm.com Change Information Date By Description 2023-12-30 Jan Ekstr\u00f8m Restructured to work on Github Pages. 2022-06-16 Balaji Santhanakrishna, Carlos Ferreira and John Douglas Asset Health Scores 2022-06-16 Carlos Ferreira and Kewei Yang Added setup Watson Studio exercise. Wrote getting started and pre-requisites and overall editing of content. 2022-06-16 Juan Gu and Carlos Ferreira Added overview of Health and Predict - Utilities models. 2022-06-16 Satish Narasimha and Carlos Ferreira Added how to install and configure App Connect for use with Health and Predict asset data loading. 2022-07-01 Carlos Ferreira Data preparation lab and data dictionary lab. 2022-07-01 Hannah Carr Added how to upload asset failure history, sensor and device data and create a predict group using out of the box notebooks. 2022-07-13 John Douglas and Amy Huang Added AIO and Health Scoring Lab content.","title":"Release Notes"},{"location":"release_notes/#contributors-to-ibm-maximo-apm-v87-lab","text":"Carlos Ferreira - carlosyells@yahoo.com Hannah Carr Juan Gu - gujuan@cn.ibm.com Satish Narasimha - ssnarasi@in.ibm.com Kewei Yang John Douglas Amy Huang Amaresh Rajasekharan Lan Cao - caolan@cn.ibm.com","title":"Contributors to IBM Maximo APM V8.7 Lab"},{"location":"release_notes/#change-information","text":"Date By Description 2023-12-30 Jan Ekstr\u00f8m Restructured to work on Github Pages. 2022-06-16 Balaji Santhanakrishna, Carlos Ferreira and John Douglas Asset Health Scores 2022-06-16 Carlos Ferreira and Kewei Yang Added setup Watson Studio exercise. Wrote getting started and pre-requisites and overall editing of content. 2022-06-16 Juan Gu and Carlos Ferreira Added overview of Health and Predict - Utilities models. 2022-06-16 Satish Narasimha and Carlos Ferreira Added how to install and configure App Connect for use with Health and Predict asset data loading. 2022-07-01 Carlos Ferreira Data preparation lab and data dictionary lab. 2022-07-01 Hannah Carr Added how to upload asset failure history, sensor and device data and create a predict group using out of the box notebooks. 2022-07-13 John Douglas and Amy Huang Added AIO and Health Scoring Lab content.","title":"Change Information"},{"location":"setup_watson_studio/","text":"Setup Watson Studio In this exercise you will setup and configure Watson Studio to use the Health and Predict notebook templates. The templates can be used for detecting anomalies and predicting asset failures of assets and for other purposes using Health and Predict - Utilities. Get URL and User credentials to access Watson Studio. Create a project and add the setup notebook to your project in Watson Studio. Setup Database Connection to allow Watson Studio to access DB. Get URL to Download the Healh and Predict Notebooks . Create am environment to edit and run your notebooks. Add Notebook From File to Watson Studio Project. Download the Predict pmlib Python Library Documentation used for working with Predict algorithms and automating device and data tasks in Monitor. Get URL and User credentials to access Watson Studio Ask your Maximo Application Suite administrator to get your user name and password for Watson Studio, API keys and URL that you will use to connect to Watson Studio. You or he can use these steps to get them. To get the Watson Studio URL, login to Maximo Application Suite. Click on Adminstration Click on Configurations and Watson Studio Click on System After you create the Watson Studio User be sure to make note of the URL, user name and password. You will use it to login to Cloud Pak for Data later with it. Open a browser to the URL and use the credentials from the previous steps to login to Cloud Pak for Data. After logging in you see your Watson Studio Overview page. Note Ensure Datascience User Belongs to Predict Security Group. In Maximo Manage, add the user to the PREDICT and PREDICTGROUPING group in the user definition as shown in the screen below. Create a Project in Watson Studio Watson Studio projects are where you: - Keep your model templates - Data Assets - Train deploy and many the Models - Create and manage environment for training and deploying your models. Create a project so that you can add and setup Health, Predict and Utilities notebooks using Watson Studio. Click on 'All Projects' where you will then create a new project. Click 'New Project'. Accept default and click 'Next'. Click 'New Empty Project'. Enter a project name and description. Click Add to Project . This is how you will add the Predict notebook templates to your project that you download later in this exercise. Setup Database Connection in Watson Studio Setup database security to allow Watson Studio to access the Maximo Application Suite databases. Follow the instructions in the documentation to download the database security certificate file Database PEM file If your database was deployed within CP4D use the directions below. Open a separate browser window and login to Cloud Pak For Data Console to get the database pem file. Click on the Hamburger menu, Instances Select the database name used by Maximo Monitor. The database name should include IOT in the name. Click on Console to download the database pem file. If you receive an error saying the console hasn't been provisioned ask your IT Administrator to install it. Click on the Download SSL Certificate Return to the browser window that has Watson Studio Project you created earlier. Add the database pem file as a data asset. Drag and drop the database pem file into the data assets. !!! If your database was deployed outside of CP4D you will have to use the directions below. Login to Openshift Cluster. Select Project db2u , select workloads , select Secrets , search for db2u-certificate . Select it. In Details tab Data section choose ca.crt copy certificate. Save it in a text based file named database.pem on your location machine. You will upload this file to CP4D Watson Studio project later as a data asset. Get URL to Download the Health and Predict and Utilities Notebooks These notebooks templates are what you use to calculate asset health and risk scores, asset end of life probability, anomaly detection, predict EOL failure dates and more. The Health and Predict notebooks require programmatic access and credentials to access Maximo Application Suite. You will need these values to create the URL that allows you to download the Health, Predict and Utilities notebooks zip file. The URL looks like: https://`EXTERNAL_APM_API_BASEURL`/ibm/pmi/service/rest/ds/`APM_ID`/`APM_API_KEY`/file/download Environment Variable Find It In Used For APM_ID The value for the mxe.PMIId system property. Used to train and score all notebooks APM_API_BASEURL The root of the URL value for the PREDICTAPI endpoint. Used to train and score all notebooks EXTERNAL_APM_API_BASEURL The route location for the Predict project retrieved from the Red Hat\u00ae OpenShift\u00ae Container Platform. Used to download the notebooks APM_API_KEY The API key from MAS Integration Application to programatically access Predict APIs. Used to download and use the notebooks Get mxe.PMIId value used for APM_ID To get the value of mxe.PMIId, open a browser and access the Health and Predict application. See below example of where you can find these values in Health and Predict system properties. Click on Application Administration Click on System Configurations , Platform Configurations and System Properties . Click on Funnel icon to filter properties that begin with property name PMI. It should look like: APM_ID = mxe.PMIId = f3fake48 Get PREDICTAPI endpoint used for APM_API_BASEURL To get APM_API_BASEURL from the value from PREDICTAPI endpoint . You can find endpoints in Health and Predict Adminstration application by searching on End Points . Click on Application Administration Click in search field and search application for End Points Note the URL for the PREDICTAPI endpoint. - It should look like: APM_API_BASEURL = PREDICTAPI endpoint = https://main.predict.ivt11rel87.ivt.suite.maximo.com Get root location for the EXTERNAL_APM_API_BASEURL Open a browser and access the Openshift Console MAS is deployed on. For IBM Cloud deployments goto https://cloud.ibm.com , select your account from the drop down menu and click Clusters Under Resources click on your cluster resource. Click on Openshift Web Console Click on Project . Search on Predict and Click on Project Search Predict Navigate to Routes Search for masdev-masdemo-predict-api The URL should be under the location tab and look similar as the one below. https://masdev.predict.devtest.hpdevcloud-6xxxxxxxxxxxxxx91ab-0000.us-south.containers.appdomain.cloud/ibm/pmi/service Trim the URL end to get the APM_API_BASEURL by removing /ibm/pmi/service . It should look like: EXTERNAL_APM_API_BASEURL = https://masdev.predict.devtest.hpdevcloud-6xxxxxxxxxxxxxe91ab-0000.us-south.containers.appdomain.cloud Get APM_API_KEY API keys are used by the notebooks to make program calls to the Health and Predict APIs. API keys are created for specific users or programs using the Administration tools . 1. In Health and Predict and Utilities menus on the left, click on Application Administration to open the Start Center Click Administration and sub menu Administration Click on Integration menu to access the Start Center where you can create keys. Click on API Keys menu and the Add API Key button to create an API keys or select an API key from those available. Click Copy key to get APM_API_KEY string you need to create the URL to download the zip file of Predict Notebooks. Download the model template notebooks Using the key value pairs in the previous steps you wil create the URL to download the Predict notebooks from a browser. Replace key variable you collected in the previous steps with the values to create the download URL: For example: https://`EXTERNAL_APM_API_BASEURL`/ibm/pmi/service/rest/ds/`APM_ID`/`APM_API_KEY`/file/download EXTERNAL_APM_API_BASEURL = https://masws.predict.ivt09rel86.fake.suite.maximo.com APM_ID = f3fake48 APM_API_KEY = n7gssk_fake_l_fake_486_fake_967_fake_jm8 The final URL becomes: https://masws.predict.ivt09rel86.fake.suite.maximo.com/ibm/pmi/service/rest/ds/f3fake48/n7gssk_fake_l_fake_486_fake_967_fake_jm8/file/download Make note of the values and create the URL you can use in the browser to download the zip file. Here is an example download URL for Predict model notebook templates zip file using the values from the previous steps. Open a browser and use the URL to download and save the Predict Model templates zip file locally. Unzip the models file and then upload the notebooks one at a time into your Watson Studio Project Assets. In your finder or file explorer, double click on the zip file to extract the notebooks. Make note of where you unzipped the file, as you will need it for the next steps. Note Be sure to prepend your name initials to any model you upload to shared project areas when doing labs so you can remember which project notebook template was yours. Set up an Environment to train and test your models in Watson Studio The default environment is only 1 vCPU. You must have an environment with at least 4 vCPUs in order to train the Predict Models. In your Watson Studio project, create a 4 vCPU environment by clicking on environment and clicking the New enviornment definition link. Enter a name for the environment. Hit the plus button to increase the vCPUs to 4. Choose Python v3.8 for the Software version . Press the 'Create' button to create then environment. Add Notebook From File to a Watson Studio Project You can use the steps below to add any notebook from File to your Watson Studio Project. Notebooks are used to create scores, predictions and for other algorithms in Health and Predict - Utilities. In this exercise you will add a Predict Notebooks you will use to your Project. Select the WS - Predicted Failure Date-Survive Analysis.ipynb notebook template that you will use in the next exercise to predict failure dates of the pump. Add a Predict notebook by file option to your Watson Studio Project. Return to your Cloud Pak for Data project. Search for your project by name. Click on the project name link to open your project. Add one of Predict notebook you unzipped earlier. Click Add to Project and select notebook option. Click the From File tab. Drag and drop the notebook you would like to add to the area to add notebooks. To save time in the next exercise choose the notebook for WS - Predicted Failure Date-Survive Analysis replace WS with your initials when naming the notebook. Prepend your name initials to the name of the model file template you uploaded. Select the runtime environment you created in the previous step that has 4 vCPUs. Drag and drop your notebook template file into the area indicated below. Click on the Create button to create the notebook. Confirm that you see 4 vCPUs for the notebook as it starts. If the notebook has the wrong number of vCPUs you can change the environment by clicking on the 'information' icon and selecting the right Environment from the dropdown select box. If you had to change the environment , click the Confirm button to restart the notebook editor in Waston Studio To Stop and Restart a Notebook Template in a Watson Studio Project If your notebook environment fails to start you can restart the environment by following the steps below. Add one of the Predict notebook templates to your Watson Studio Project. Click the information icon, environment tab and restart from the Runtime Status select box. Confirm your selection to restart the notebook by pressing the Change button. Download Predict pmlib Python Library Documentation Predict pmlib Python Library is used for working with Predict algorithms and automating device and data tasks in Monitor.or open the Predicted Failure Data template notebook to your Project. Use the steps from the previous exercise Add Notebook From File to a Watson Studio Project Prepend your initials to the template. If you already have uploaded the notebook, open it with Watson Studio. You can download the documentation using a URL similar to the one you create in the previous Exercise for downloading the doc-8.5.1.zip that contains the html files for the pmilib documentation. For example: https://`EXTERNAL_APM_API_BASEURL`/ibm/pmi/service/rest/ds/`APM_ID`/`APM_API_KEY`/doc/download Unzip the doc-8.5.1.zip file you downloaded Click on the file index.html file you unzipped. The browser should open with the documentation below. Setup Environment Variables for Predict in Notebook Templates One of the earlier steps explained how to manually find the environment variables used in Predict to do things like download the zip file with the Predict Notebooks. When using a Predict Notebook in Watson Studio you can also programatically discover these environment variables since they are set for you in the Cloud Pack for Data Environment that was installed with Maximo Application Suite. Use the code below if it isn't already included in the notebook templates to get the required Predict environment variables. Sample Code import json import os # Try to open environment variables json file if it already exists. try: f = open('/project_data/data_asset/hc_Predict_Envs.json',) except: f = {} print(\"No execution json found, initialising with current notebook information\") data = json.load(f) f.close() os.environ['APM_ID'] = data['APM_ID'] os.environ['APM_API_BASEURL'] = data['APM_API_BASEURL'] os.environ['APM_API_KEY'] = data['APM_API_KEY'] # README: Change to true if Health/Predict are deployed on different cluster from this CP4D environment use_external = False if use_external: import os os.environ['USER_PROVIDED_HEALTH_URL'] = data['USER_PROVIDED_HEALTH_URL'] os.environ['USER_PROVIDED_DB_CONNECTION_STRING'] = data['USER_PROVIDED_DB_CONNECTION_STRING'] os.environ['USER_PROVIDED_URL'] = data['USER_PROVIDED_URL'] import os os.environ['SSL_VERIFY_APM'] = 'False' os.environ['SSL_VERIFY_AS'] = 'False' os.environ['TRUST_PREDICT'] = os.getenv('APM_API_BASEURL')[8:] print(os.getenv('TRUST_PREDICT')) main.predict.ivt11rel87.ivt.suite.maximo.com import os os.environ['TRUST_PREDICT'] = os.getenv('APM_API_BASEURL')[8:] print(os.getenv('TRUST_PREDICT')) PIP Install PMLib Predict in Notebook Templates Install the Predict Python Software Develop Kit (SDK) called PMLib using pip install. Sample Code # Initialize the Maximo-Predict environment variables import pmlib from pmlib import api api.init_environ() Using Watson Studio Library The Watson Studio Python Library named ibm_watson_studio_lib allows you to do to work with data assets in your project. Some examples you will learn later are reading and writing data from your project. Another example is getting the Watson Studio Project Information. You will use a Watson Studio Python library named ibm_watson_studio_lib that is available in your environment by default to get your project information. See this API reference for more information. Sample Code # Get the Watson Studio Project Information from ibm_watson_studio_lib import access_project_or_space wslib = access_project_or_space() project_name = wslib.here.get_name() wslib.show(project_name) project_id = wslib.here.get_ID() wslib.show(project_id) Congratulations you have seen how to upload, start and restart Predict notebook in Watson Studio. You have also learned how to download and access the pmilib documentation that you will use in the next exercises. Finally you learned how to use the ibm_watson_studio_lib to work with assets in your project. In the next exercises you will learn how to use these notebook templates to detect anomalies and predict asset failures. You will start by update and running setup notebooks to create asset types in Health and Predict.","title":"Setup Watson Studio for Predict"},{"location":"setup_watson_studio/#setup-watson-studio","text":"In this exercise you will setup and configure Watson Studio to use the Health and Predict notebook templates. The templates can be used for detecting anomalies and predicting asset failures of assets and for other purposes using Health and Predict - Utilities. Get URL and User credentials to access Watson Studio. Create a project and add the setup notebook to your project in Watson Studio. Setup Database Connection to allow Watson Studio to access DB. Get URL to Download the Healh and Predict Notebooks . Create am environment to edit and run your notebooks. Add Notebook From File to Watson Studio Project. Download the Predict pmlib Python Library Documentation used for working with Predict algorithms and automating device and data tasks in Monitor.","title":"Setup Watson Studio"},{"location":"setup_watson_studio/#get-url-and-user-credentials-to-access-watson-studio","text":"Ask your Maximo Application Suite administrator to get your user name and password for Watson Studio, API keys and URL that you will use to connect to Watson Studio. You or he can use these steps to get them. To get the Watson Studio URL, login to Maximo Application Suite. Click on Adminstration Click on Configurations and Watson Studio Click on System After you create the Watson Studio User be sure to make note of the URL, user name and password. You will use it to login to Cloud Pak for Data later with it. Open a browser to the URL and use the credentials from the previous steps to login to Cloud Pak for Data. After logging in you see your Watson Studio Overview page. Note Ensure Datascience User Belongs to Predict Security Group. In Maximo Manage, add the user to the PREDICT and PREDICTGROUPING group in the user definition as shown in the screen below.","title":"Get URL and User credentials to access Watson Studio"},{"location":"setup_watson_studio/#create-a-project-in-watson-studio","text":"Watson Studio projects are where you: - Keep your model templates - Data Assets - Train deploy and many the Models - Create and manage environment for training and deploying your models. Create a project so that you can add and setup Health, Predict and Utilities notebooks using Watson Studio. Click on 'All Projects' where you will then create a new project. Click 'New Project'. Accept default and click 'Next'. Click 'New Empty Project'. Enter a project name and description. Click Add to Project . This is how you will add the Predict notebook templates to your project that you download later in this exercise.","title":"Create a Project in Watson Studio"},{"location":"setup_watson_studio/#setup-database-connection-in-watson-studio","text":"Setup database security to allow Watson Studio to access the Maximo Application Suite databases. Follow the instructions in the documentation to download the database security certificate file Database PEM file If your database was deployed within CP4D use the directions below. Open a separate browser window and login to Cloud Pak For Data Console to get the database pem file. Click on the Hamburger menu, Instances Select the database name used by Maximo Monitor. The database name should include IOT in the name. Click on Console to download the database pem file. If you receive an error saying the console hasn't been provisioned ask your IT Administrator to install it. Click on the Download SSL Certificate Return to the browser window that has Watson Studio Project you created earlier. Add the database pem file as a data asset. Drag and drop the database pem file into the data assets. !!! If your database was deployed outside of CP4D you will have to use the directions below. Login to Openshift Cluster. Select Project db2u , select workloads , select Secrets , search for db2u-certificate . Select it. In Details tab Data section choose ca.crt copy certificate. Save it in a text based file named database.pem on your location machine. You will upload this file to CP4D Watson Studio project later as a data asset.","title":"Setup Database Connection in Watson Studio"},{"location":"setup_watson_studio/#get-url-to-download-the-health-and-predict-and-utilities-notebooks","text":"These notebooks templates are what you use to calculate asset health and risk scores, asset end of life probability, anomaly detection, predict EOL failure dates and more. The Health and Predict notebooks require programmatic access and credentials to access Maximo Application Suite. You will need these values to create the URL that allows you to download the Health, Predict and Utilities notebooks zip file. The URL looks like: https://`EXTERNAL_APM_API_BASEURL`/ibm/pmi/service/rest/ds/`APM_ID`/`APM_API_KEY`/file/download Environment Variable Find It In Used For APM_ID The value for the mxe.PMIId system property. Used to train and score all notebooks APM_API_BASEURL The root of the URL value for the PREDICTAPI endpoint. Used to train and score all notebooks EXTERNAL_APM_API_BASEURL The route location for the Predict project retrieved from the Red Hat\u00ae OpenShift\u00ae Container Platform. Used to download the notebooks APM_API_KEY The API key from MAS Integration Application to programatically access Predict APIs. Used to download and use the notebooks","title":"Get URL to Download the Health and Predict and Utilities Notebooks"},{"location":"setup_watson_studio/#get-mxepmiid-value-used-for-apm_id","text":"To get the value of mxe.PMIId, open a browser and access the Health and Predict application. See below example of where you can find these values in Health and Predict system properties. Click on Application Administration Click on System Configurations , Platform Configurations and System Properties . Click on Funnel icon to filter properties that begin with property name PMI. It should look like: APM_ID = mxe.PMIId = f3fake48","title":"Get mxe.PMIId value used for APM_ID"},{"location":"setup_watson_studio/#get-predictapi-endpoint-used-for-apm_api_baseurl","text":"To get APM_API_BASEURL from the value from PREDICTAPI endpoint . You can find endpoints in Health and Predict Adminstration application by searching on End Points . Click on Application Administration Click in search field and search application for End Points Note the URL for the PREDICTAPI endpoint. - It should look like: APM_API_BASEURL = PREDICTAPI endpoint = https://main.predict.ivt11rel87.ivt.suite.maximo.com","title":"Get PREDICTAPI endpoint used for APM_API_BASEURL"},{"location":"setup_watson_studio/#get-root-location-for-the-external_apm_api_baseurl","text":"Open a browser and access the Openshift Console MAS is deployed on. For IBM Cloud deployments goto https://cloud.ibm.com , select your account from the drop down menu and click Clusters Under Resources click on your cluster resource. Click on Openshift Web Console Click on Project . Search on Predict and Click on Project Search Predict Navigate to Routes Search for masdev-masdemo-predict-api The URL should be under the location tab and look similar as the one below. https://masdev.predict.devtest.hpdevcloud-6xxxxxxxxxxxxxx91ab-0000.us-south.containers.appdomain.cloud/ibm/pmi/service Trim the URL end to get the APM_API_BASEURL by removing /ibm/pmi/service . It should look like: EXTERNAL_APM_API_BASEURL = https://masdev.predict.devtest.hpdevcloud-6xxxxxxxxxxxxxe91ab-0000.us-south.containers.appdomain.cloud","title":"Get root location for the EXTERNAL_APM_API_BASEURL"},{"location":"setup_watson_studio/#get-apm_api_key","text":"API keys are used by the notebooks to make program calls to the Health and Predict APIs. API keys are created for specific users or programs using the Administration tools . 1. In Health and Predict and Utilities menus on the left, click on Application Administration to open the Start Center Click Administration and sub menu Administration Click on Integration menu to access the Start Center where you can create keys. Click on API Keys menu and the Add API Key button to create an API keys or select an API key from those available. Click Copy key to get APM_API_KEY string you need to create the URL to download the zip file of Predict Notebooks.","title":"Get APM_API_KEY"},{"location":"setup_watson_studio/#download-the-model-template-notebooks","text":"Using the key value pairs in the previous steps you wil create the URL to download the Predict notebooks from a browser. Replace key variable you collected in the previous steps with the values to create the download URL: For example: https://`EXTERNAL_APM_API_BASEURL`/ibm/pmi/service/rest/ds/`APM_ID`/`APM_API_KEY`/file/download EXTERNAL_APM_API_BASEURL = https://masws.predict.ivt09rel86.fake.suite.maximo.com APM_ID = f3fake48 APM_API_KEY = n7gssk_fake_l_fake_486_fake_967_fake_jm8 The final URL becomes: https://masws.predict.ivt09rel86.fake.suite.maximo.com/ibm/pmi/service/rest/ds/f3fake48/n7gssk_fake_l_fake_486_fake_967_fake_jm8/file/download Make note of the values and create the URL you can use in the browser to download the zip file. Here is an example download URL for Predict model notebook templates zip file using the values from the previous steps. Open a browser and use the URL to download and save the Predict Model templates zip file locally. Unzip the models file and then upload the notebooks one at a time into your Watson Studio Project Assets. In your finder or file explorer, double click on the zip file to extract the notebooks. Make note of where you unzipped the file, as you will need it for the next steps. Note Be sure to prepend your name initials to any model you upload to shared project areas when doing labs so you can remember which project notebook template was yours.","title":"Download the model template notebooks"},{"location":"setup_watson_studio/#set-up-an-environment-to-train-and-test-your-models-in-watson-studio","text":"The default environment is only 1 vCPU. You must have an environment with at least 4 vCPUs in order to train the Predict Models. In your Watson Studio project, create a 4 vCPU environment by clicking on environment and clicking the New enviornment definition link. Enter a name for the environment. Hit the plus button to increase the vCPUs to 4. Choose Python v3.8 for the Software version . Press the 'Create' button to create then environment.","title":"Set up an Environment to train and test your models in Watson Studio"},{"location":"setup_watson_studio/#add-notebook-from-file-to-a-watson-studio-project","text":"You can use the steps below to add any notebook from File to your Watson Studio Project. Notebooks are used to create scores, predictions and for other algorithms in Health and Predict - Utilities. In this exercise you will add a Predict Notebooks you will use to your Project. Select the WS - Predicted Failure Date-Survive Analysis.ipynb notebook template that you will use in the next exercise to predict failure dates of the pump. Add a Predict notebook by file option to your Watson Studio Project. Return to your Cloud Pak for Data project. Search for your project by name. Click on the project name link to open your project. Add one of Predict notebook you unzipped earlier. Click Add to Project and select notebook option. Click the From File tab. Drag and drop the notebook you would like to add to the area to add notebooks. To save time in the next exercise choose the notebook for WS - Predicted Failure Date-Survive Analysis replace WS with your initials when naming the notebook. Prepend your name initials to the name of the model file template you uploaded. Select the runtime environment you created in the previous step that has 4 vCPUs. Drag and drop your notebook template file into the area indicated below. Click on the Create button to create the notebook. Confirm that you see 4 vCPUs for the notebook as it starts. If the notebook has the wrong number of vCPUs you can change the environment by clicking on the 'information' icon and selecting the right Environment from the dropdown select box. If you had to change the environment , click the Confirm button to restart the notebook editor in Waston Studio","title":"Add Notebook From File to a Watson Studio Project"},{"location":"setup_watson_studio/#to-stop-and-restart-a-notebook-template-in-a-watson-studio-project","text":"If your notebook environment fails to start you can restart the environment by following the steps below. Add one of the Predict notebook templates to your Watson Studio Project. Click the information icon, environment tab and restart from the Runtime Status select box. Confirm your selection to restart the notebook by pressing the Change button.","title":"To Stop and Restart a Notebook Template in a Watson Studio Project"},{"location":"setup_watson_studio/#download-predict-pmlib-python-library-documentation","text":"Predict pmlib Python Library is used for working with Predict algorithms and automating device and data tasks in Monitor.or open the Predicted Failure Data template notebook to your Project. Use the steps from the previous exercise Add Notebook From File to a Watson Studio Project Prepend your initials to the template. If you already have uploaded the notebook, open it with Watson Studio. You can download the documentation using a URL similar to the one you create in the previous Exercise for downloading the doc-8.5.1.zip that contains the html files for the pmilib documentation. For example: https://`EXTERNAL_APM_API_BASEURL`/ibm/pmi/service/rest/ds/`APM_ID`/`APM_API_KEY`/doc/download Unzip the doc-8.5.1.zip file you downloaded Click on the file index.html file you unzipped. The browser should open with the documentation below.","title":"Download Predict pmlib Python Library Documentation"},{"location":"setup_watson_studio/#setup-environment-variables-for-predict-in-notebook-templates","text":"One of the earlier steps explained how to manually find the environment variables used in Predict to do things like download the zip file with the Predict Notebooks. When using a Predict Notebook in Watson Studio you can also programatically discover these environment variables since they are set for you in the Cloud Pack for Data Environment that was installed with Maximo Application Suite. Use the code below if it isn't already included in the notebook templates to get the required Predict environment variables. Sample Code import json import os # Try to open environment variables json file if it already exists. try: f = open('/project_data/data_asset/hc_Predict_Envs.json',) except: f = {} print(\"No execution json found, initialising with current notebook information\") data = json.load(f) f.close() os.environ['APM_ID'] = data['APM_ID'] os.environ['APM_API_BASEURL'] = data['APM_API_BASEURL'] os.environ['APM_API_KEY'] = data['APM_API_KEY'] # README: Change to true if Health/Predict are deployed on different cluster from this CP4D environment use_external = False if use_external: import os os.environ['USER_PROVIDED_HEALTH_URL'] = data['USER_PROVIDED_HEALTH_URL'] os.environ['USER_PROVIDED_DB_CONNECTION_STRING'] = data['USER_PROVIDED_DB_CONNECTION_STRING'] os.environ['USER_PROVIDED_URL'] = data['USER_PROVIDED_URL'] import os os.environ['SSL_VERIFY_APM'] = 'False' os.environ['SSL_VERIFY_AS'] = 'False' os.environ['TRUST_PREDICT'] = os.getenv('APM_API_BASEURL')[8:] print(os.getenv('TRUST_PREDICT')) main.predict.ivt11rel87.ivt.suite.maximo.com import os os.environ['TRUST_PREDICT'] = os.getenv('APM_API_BASEURL')[8:] print(os.getenv('TRUST_PREDICT'))","title":"Setup Environment Variables for Predict in Notebook Templates"},{"location":"setup_watson_studio/#pip-install-pmlib-predict-in-notebook-templates","text":"Install the Predict Python Software Develop Kit (SDK) called PMLib using pip install. Sample Code # Initialize the Maximo-Predict environment variables import pmlib from pmlib import api api.init_environ()","title":"PIP Install PMLib Predict in Notebook Templates"},{"location":"setup_watson_studio/#using-watson-studio-library","text":"The Watson Studio Python Library named ibm_watson_studio_lib allows you to do to work with data assets in your project. Some examples you will learn later are reading and writing data from your project. Another example is getting the Watson Studio Project Information. You will use a Watson Studio Python library named ibm_watson_studio_lib that is available in your environment by default to get your project information. See this API reference for more information. Sample Code # Get the Watson Studio Project Information from ibm_watson_studio_lib import access_project_or_space wslib = access_project_or_space() project_name = wslib.here.get_name() wslib.show(project_name) project_id = wslib.here.get_ID() wslib.show(project_id) Congratulations you have seen how to upload, start and restart Predict notebook in Watson Studio. You have also learned how to download and access the pmilib documentation that you will use in the next exercises. Finally you learned how to use the ibm_watson_studio_lib to work with assets in your project. In the next exercises you will learn how to use these notebook templates to detect anomalies and predict asset failures. You will start by update and running setup notebooks to create asset types in Health and Predict.","title":"Using Watson Studio Library"},{"location":"utilities_EOL/","text":"Create End of Life Curve Maximo Predict comes with notebook templates to assist in streamlining data uploads to Maximo. This notebook will create the End of Life Curve using provided csv files. These instructions use the notebook named 4_PMI - End of Life Curve HPU.ipynb file with the Substation Transformer for Health and Predict for Utilities Demo Assets. Note that this uses simulated Pump Data for the sensor readings. In this exercise you will use Watson Studio and Health and Predict - Utilities to: Upload the and Run the End of Life Curve Notebook using a template to Train and Display an End of Life Curve Confirm the Data Has been uploaded for your assets Note You must complete the previous exercise for Setup Watson Studio before you start this exercise. Pre-requisites Review Predict documentation for the list of available models . Ensure your MAS Predict environment is running and you have access. Try your server URL that might look something like: https://main.predict.ivt11rel87.ivt.suite.myhost.com/ibm/pmi/service/rest/system/info Ensure you have Access to Asset data files for the Health and Predict Utilities Demo Data Complete the Load Data into Manage lab for the Utilities data. Complete the Load Utilities Health Scores via Notebook lab Complete the Create Utilities Predict Group and Upload Sensor Data lab Have the following information from the previous lab: Predict_Envs.JSON and Fast_Execution.JSON Note It is best to perform this lab in your own Watson Studio Project created using Setup Watson Studio instructions. If you are using a shared project, ensure you append each file uploaded with your initials and update the file paths in the notebooks to include that change. Upload and Start the End of Life Curve Notebook Upload or open the End of Life Curve template notebook to your Project. Use the steps from the previous exercise Add Notebook From File to a Watson Studio Project If you are using a shared project, rename the notebook template by prepending your initials to the template. If this is done, ensure any paths or file names within the notebook are updated as well. If you already have uploaded the notebook, open it with Watson Studio. Select the 4_PMI - End of Life Curve HPU notebook template. Open the notebook. Click on the pencil icon next to your notebook. If the notebook fails to start, restart it. Click on the i icon , Environment tab, Running status drop down select box and choose Restart Run the Notebook Install the Maximo Predict SDK Read the introduction to the End of Life Curve Notebook. Run the first cell to define the requirements and some environment variables to run this notebook. This cell also checks that the precursor notebook has been run. Run the next cell to set the asset_group_id from the stored asset group id in the JSON file produced from the Fast Start Data Loader notebook. Ensure the printed asset group ID matches your asset group. Run the next cell to define the API keys used to call Maximo Predict from the Predict_Envs.JSON file Skip the next cell. It should be commented out, but it would be used to define the API and Predict Environment variables manually if the Predict_Envs.JSON file was not available. Run the next cell to import the os, trim the provided base url to be used when downloading pmlib later in the notebook and used to contact the environment via API. Run the following two cells to uninstall and reinstall the pmlib library. This is done to ensure you have the correct version. Set up the Model Training Pipeline, Train, Register and Enable the Model Run the first cell define the model settings for the Pipeline. Run the next cell to train the model. Some models take time to train. Once that process is complete, register the model to your asset group by running the next cell Finally, Run the next cell to enable it and determine how often it will be run in monitor. This is the last cell to be run in this notebook. Confirm Model Registration Navigate to Maximo Health and Predict for Utilities within your environment Use the left-hand menu to go into Predict Grouping Select your asset group Click into your asset group and ensure you have End of Life Curve listed under Trained instances registered for this group and select an asset to go to the Health Dashboard Scroll down and expand the Predict section to ensure the End of Life Curve is visible. Note Recall in the Create Utilities Predict Group and Upload Sensor Data lab only some assets have sensor data. If an asset does not have sensor data, it will not have Predict data Congratulations you have created an End of Life Curve and associated it to your assets!","title":"Train and Register End of Life Curve for Utilities Assets"},{"location":"utilities_EOL/#create-end-of-life-curve","text":"Maximo Predict comes with notebook templates to assist in streamlining data uploads to Maximo. This notebook will create the End of Life Curve using provided csv files. These instructions use the notebook named 4_PMI - End of Life Curve HPU.ipynb file with the Substation Transformer for Health and Predict for Utilities Demo Assets. Note that this uses simulated Pump Data for the sensor readings. In this exercise you will use Watson Studio and Health and Predict - Utilities to: Upload the and Run the End of Life Curve Notebook using a template to Train and Display an End of Life Curve Confirm the Data Has been uploaded for your assets Note You must complete the previous exercise for Setup Watson Studio before you start this exercise.","title":"Create End of Life Curve"},{"location":"utilities_EOL/#pre-requisites","text":"Review Predict documentation for the list of available models . Ensure your MAS Predict environment is running and you have access. Try your server URL that might look something like: https://main.predict.ivt11rel87.ivt.suite.myhost.com/ibm/pmi/service/rest/system/info Ensure you have Access to Asset data files for the Health and Predict Utilities Demo Data Complete the Load Data into Manage lab for the Utilities data. Complete the Load Utilities Health Scores via Notebook lab Complete the Create Utilities Predict Group and Upload Sensor Data lab Have the following information from the previous lab: Predict_Envs.JSON and Fast_Execution.JSON Note It is best to perform this lab in your own Watson Studio Project created using Setup Watson Studio instructions. If you are using a shared project, ensure you append each file uploaded with your initials and update the file paths in the notebooks to include that change.","title":"Pre-requisites"},{"location":"utilities_EOL/#upload-and-start-the-end-of-life-curve-notebook","text":"Upload or open the End of Life Curve template notebook to your Project. Use the steps from the previous exercise Add Notebook From File to a Watson Studio Project If you are using a shared project, rename the notebook template by prepending your initials to the template. If this is done, ensure any paths or file names within the notebook are updated as well. If you already have uploaded the notebook, open it with Watson Studio. Select the 4_PMI - End of Life Curve HPU notebook template. Open the notebook. Click on the pencil icon next to your notebook. If the notebook fails to start, restart it. Click on the i icon , Environment tab, Running status drop down select box and choose Restart","title":"Upload and Start the End of Life Curve Notebook"},{"location":"utilities_EOL/#run-the-notebook","text":"","title":"Run the Notebook"},{"location":"utilities_EOL/#install-the-maximo-predict-sdk","text":"Read the introduction to the End of Life Curve Notebook. Run the first cell to define the requirements and some environment variables to run this notebook. This cell also checks that the precursor notebook has been run. Run the next cell to set the asset_group_id from the stored asset group id in the JSON file produced from the Fast Start Data Loader notebook. Ensure the printed asset group ID matches your asset group. Run the next cell to define the API keys used to call Maximo Predict from the Predict_Envs.JSON file Skip the next cell. It should be commented out, but it would be used to define the API and Predict Environment variables manually if the Predict_Envs.JSON file was not available. Run the next cell to import the os, trim the provided base url to be used when downloading pmlib later in the notebook and used to contact the environment via API. Run the following two cells to uninstall and reinstall the pmlib library. This is done to ensure you have the correct version.","title":"Install the Maximo Predict SDK"},{"location":"utilities_EOL/#set-up-the-model-training-pipeline-train-register-and-enable-the-model","text":"Run the first cell define the model settings for the Pipeline. Run the next cell to train the model. Some models take time to train. Once that process is complete, register the model to your asset group by running the next cell Finally, Run the next cell to enable it and determine how often it will be run in monitor. This is the last cell to be run in this notebook.","title":"Set up the Model Training Pipeline, Train, Register and Enable the Model"},{"location":"utilities_EOL/#confirm-model-registration","text":"Navigate to Maximo Health and Predict for Utilities within your environment Use the left-hand menu to go into Predict Grouping Select your asset group Click into your asset group and ensure you have End of Life Curve listed under Trained instances registered for this group and select an asset to go to the Health Dashboard Scroll down and expand the Predict section to ensure the End of Life Curve is visible. Note Recall in the Create Utilities Predict Group and Upload Sensor Data lab only some assets have sensor data. If an asset does not have sensor data, it will not have Predict data Congratulations you have created an End of Life Curve and associated it to your assets!","title":"Confirm Model Registration"},{"location":"utilities_Failure_Probability/","text":"Create Failure Probability Model Maximo Predict comes with notebook templates to assist in streamlining data uploads to Maximo. This notebook will create the Failure Probability using provided csv files. These instructions use the notebook named 6_PMI-Failure Probability-BinaryClassification-HPU file with the Substation Transformer for Health and Predict for Utilities Demo Assets. Note that this uses simulated Pump Data for the sensor readings. In this exercise you will use Watson Studio and Health and Predict - Utilities to: Upload the and Run the Failure Probability Notebook using a template to Train and Display a Failure Probability value Confirm the Data Has been uploaded for your assets Note You must complete the previous exercise for Setup Watson Studio before you start this exercise. Pre-requisites Review Predict documentation for the list of available models . Ensure your MAS Predict environment is running and you have access. Try your server URL that might look something like: https://main.predict.ivt11rel87.ivt.suite.myhost.com/ibm/pmi/service/rest/system/info Ensure you have Access to Asset data files for the Health and Predict Utilities Demo Data Complete the Load Data into Manage lab for the Utilities data. Complete the Load Utilities Health Scores via Notebook lab Complete the Create Utilities Predict Group and Upload Sensor Data lab Have the following information from the previous lab: Predict_Envs.JSON and Fast_Execution.JSON Note It is best to perform this lab in your own Watson Studio Project created using Setup Watson Studio instructions. If you are using a shared project, ensure you append each file uploaded with your initials and update the file paths in the notebooks to include that change. Upload and Start the Predicted Failure Date Notebook Upload or open the Failure Probability template notebook to your Project. Use the steps from the previous exercise Add Notebook From File to a Watson Studio Project If you are using a shared project, rename the notebook template by prepending your initials to the template. If this is done, ensure any paths or file names within the notebook are updated as well. If you already have uploaded the notebook, open it with Watson Studio. Select the 6_PMI-Failure Probability-BinaryClassification-HPU notebook template. Open the notebook. Click on the pencil icon next to your notebook. If the notebook fails to start, restart it. Click on the i icon , Environment tab, Running status drop down select box and choose Restart Run the Notebook Install the Maximo Predict SDK Read the introduction to the Failure Probability Notebook. Run the first cell to install pyspark and set up the error logs. Run the second cell to define the requirements and some environment variables to run this notebook. This cell also checks that the precursor notebook has been run. Additionally, this cell sets the device_type and the asset_group_id from the stored device type and asset group id in the JSON file produced from the Fast Start Data Loader notebook. Ensure the printed values match your asset group and device. Run the next cell to uninstall the pmlib library. This is done to ensure the correct version is installed. Run the next cell to define the API keys used to call Maximo Predict from the Predict_Envs.JSON file Skip the next cell. It should be commented out, but it would be used to define the API and Predict Environment variables manually if the Predict_Envs.JSON file was not available. Run the next cell to import the os, trim the provided base url to be used when downloading pmlib later in the notebook and used to contact the environment via API. Skip the next cell. It should be commented out. This cell is used to hardcode some API information that is not needed here. Run the following five cells to reinstall the pmlib and import sklearn and other necessary libraries. Set up the Model Training Pipeline, Train, Register and Enable the Model Run the first to import pmlib library Run the second cell to define the sensor readings columns to be considered in the model Skip the next few cells until you reach the How to Custom Model section. In this section, we customize the pipeline settings and the models to be considered. Run the first cell to import the necessary models for the pipeline Run the next cell to transform the desired features and define some additional settings for the pipeline. Some of these settings include determining which models to consider and how to process the features Skip the next cell, those are some alternate settings. Run the next cell to define the pipeline and standard settings for the modeling process Run the next cell to train the model. This cell can take some time for some models. Once this process is complete, run the following cell to register the model to your asset group. Finally, Run the next cell to enable it and determine how often it will be run in monitor. This is the last cell to be run in this notebook. Confirm Model Registration Navigate to Maximo Health and Predict for Utilities within your environment Use the left-hand menu to go into Predict Grouping Select your asset group Click into your asset group and ensure you have Failure Probability listed under Trained instances registered for this group and select an asset to go to the Health Dashboard Scroll down and expand the Predict section to ensure the Failure Probability , Failure Probability Trend and Factors that Contribute to Failures is visible. Note Recall in the Create Utilities Predict Group and Upload Sensor Data lab only some assets have sensor data. If an asset does not have sensor data, it will not have Predict data. Additionally, most the assets with data will have a Predicted Failure date of 0 \\plusminus x The following assets should have a future failure date when the notebook is ran: Congratulations you have created a Failure Probability model and associated it to your assets!","title":"Train and Register Failure Probability for Utilities Assets"},{"location":"utilities_Failure_Probability/#create-failure-probability-model","text":"Maximo Predict comes with notebook templates to assist in streamlining data uploads to Maximo. This notebook will create the Failure Probability using provided csv files. These instructions use the notebook named 6_PMI-Failure Probability-BinaryClassification-HPU file with the Substation Transformer for Health and Predict for Utilities Demo Assets. Note that this uses simulated Pump Data for the sensor readings. In this exercise you will use Watson Studio and Health and Predict - Utilities to: Upload the and Run the Failure Probability Notebook using a template to Train and Display a Failure Probability value Confirm the Data Has been uploaded for your assets Note You must complete the previous exercise for Setup Watson Studio before you start this exercise.","title":"Create Failure Probability Model"},{"location":"utilities_Failure_Probability/#pre-requisites","text":"Review Predict documentation for the list of available models . Ensure your MAS Predict environment is running and you have access. Try your server URL that might look something like: https://main.predict.ivt11rel87.ivt.suite.myhost.com/ibm/pmi/service/rest/system/info Ensure you have Access to Asset data files for the Health and Predict Utilities Demo Data Complete the Load Data into Manage lab for the Utilities data. Complete the Load Utilities Health Scores via Notebook lab Complete the Create Utilities Predict Group and Upload Sensor Data lab Have the following information from the previous lab: Predict_Envs.JSON and Fast_Execution.JSON Note It is best to perform this lab in your own Watson Studio Project created using Setup Watson Studio instructions. If you are using a shared project, ensure you append each file uploaded with your initials and update the file paths in the notebooks to include that change.","title":"Pre-requisites"},{"location":"utilities_Failure_Probability/#upload-and-start-the-predicted-failure-date-notebook","text":"Upload or open the Failure Probability template notebook to your Project. Use the steps from the previous exercise Add Notebook From File to a Watson Studio Project If you are using a shared project, rename the notebook template by prepending your initials to the template. If this is done, ensure any paths or file names within the notebook are updated as well. If you already have uploaded the notebook, open it with Watson Studio. Select the 6_PMI-Failure Probability-BinaryClassification-HPU notebook template. Open the notebook. Click on the pencil icon next to your notebook. If the notebook fails to start, restart it. Click on the i icon , Environment tab, Running status drop down select box and choose Restart","title":"Upload and Start the Predicted Failure Date Notebook"},{"location":"utilities_Failure_Probability/#run-the-notebook","text":"","title":"Run the Notebook"},{"location":"utilities_Failure_Probability/#install-the-maximo-predict-sdk","text":"Read the introduction to the Failure Probability Notebook. Run the first cell to install pyspark and set up the error logs. Run the second cell to define the requirements and some environment variables to run this notebook. This cell also checks that the precursor notebook has been run. Additionally, this cell sets the device_type and the asset_group_id from the stored device type and asset group id in the JSON file produced from the Fast Start Data Loader notebook. Ensure the printed values match your asset group and device. Run the next cell to uninstall the pmlib library. This is done to ensure the correct version is installed. Run the next cell to define the API keys used to call Maximo Predict from the Predict_Envs.JSON file Skip the next cell. It should be commented out, but it would be used to define the API and Predict Environment variables manually if the Predict_Envs.JSON file was not available. Run the next cell to import the os, trim the provided base url to be used when downloading pmlib later in the notebook and used to contact the environment via API. Skip the next cell. It should be commented out. This cell is used to hardcode some API information that is not needed here. Run the following five cells to reinstall the pmlib and import sklearn and other necessary libraries.","title":"Install the Maximo Predict SDK"},{"location":"utilities_Failure_Probability/#set-up-the-model-training-pipeline-train-register-and-enable-the-model","text":"Run the first to import pmlib library Run the second cell to define the sensor readings columns to be considered in the model Skip the next few cells until you reach the How to Custom Model section. In this section, we customize the pipeline settings and the models to be considered. Run the first cell to import the necessary models for the pipeline Run the next cell to transform the desired features and define some additional settings for the pipeline. Some of these settings include determining which models to consider and how to process the features Skip the next cell, those are some alternate settings. Run the next cell to define the pipeline and standard settings for the modeling process Run the next cell to train the model. This cell can take some time for some models. Once this process is complete, run the following cell to register the model to your asset group. Finally, Run the next cell to enable it and determine how often it will be run in monitor. This is the last cell to be run in this notebook.","title":"Set up the Model Training Pipeline, Train, Register and Enable the Model"},{"location":"utilities_Failure_Probability/#confirm-model-registration","text":"Navigate to Maximo Health and Predict for Utilities within your environment Use the left-hand menu to go into Predict Grouping Select your asset group Click into your asset group and ensure you have Failure Probability listed under Trained instances registered for this group and select an asset to go to the Health Dashboard Scroll down and expand the Predict section to ensure the Failure Probability , Failure Probability Trend and Factors that Contribute to Failures is visible. Note Recall in the Create Utilities Predict Group and Upload Sensor Data lab only some assets have sensor data. If an asset does not have sensor data, it will not have Predict data. Additionally, most the assets with data will have a Predicted Failure date of 0 \\plusminus x The following assets should have a future failure date when the notebook is ran: Congratulations you have created a Failure Probability model and associated it to your assets!","title":"Confirm Model Registration"},{"location":"utilities_Failure_date/","text":"Create Predicted Failure Date Maximo Predict comes with notebook templates to assist in streamlining data uploads to Maximo. This notebook will create the Predicted Failure Date using provided csv files. These instructions use the notebook named 5_PMI - Predicted Failure Date-Smart Regression-HPU file with the Substation Transformer for Health and Predict for Utilities Demo Assets. Note that this uses simulated Pump Data for the sensor readings. In this exercise you will use Watson Studio and Health and Predict - Utilities to: Upload the and Run the Predicted Failure Notebook using a template to Train and Display a Predicted Failure Date Confirm the Data Has been uploaded for your assets Note You must complete the previous exercise for Setup Watson Studio before you start this exercise. Pre-requisites Review Predict documentation for the list of available models . Ensure your MAS Predict environment is running and you have access. Try your server URL that might look something like: https://main.predict.ivt11rel87.ivt.suite.myhost.com/ibm/pmi/service/rest/system/info Ensure you have Access to Asset data files for the Health and Predict Utilities Demo Data Complete the Load Data into Manage lab for the Utilities data. Complete the Load Utilities Health Scores via Notebook lab Complete the Create Utilities Predict Group and Upload Sensor Data lab Have the following information from the previous lab: Predict_Envs.JSON and Fast_Execution.JSON Note It is best to perform this lab in your own Watson Studio Project created using Setup Watson Studio instructions. If you are using a shared project, ensure you append each file uploaded with your initials and update the file paths in the notebooks to include that change. Upload and Start the Predicted Failure Date Notebook Upload or open the Predicted Failure Date template notebook to your Project. Use the steps from the previous exercise Add Notebook From File to a Watson Studio Project If you are using a shared project, rename the notebook template by prepending your initials to the template. If this is done, ensure any paths or file names within the notebook are updated as well. If you already have uploaded the notebook, open it with Watson Studio. Select the 5_PMI - Predicted Failure Date-Smart Regression-HPU notebook template. Open the notebook. Click on the pencil icon next to your notebook. If the notebook fails to start, restart it. Click on the i icon , Environment tab, Running status drop down select box and choose Restart Run the Notebook Install the Maximo Predict SDK Read the introduction to the Predicted Failure Date Notebook. Run the first cell to define the requirements and some environment variables to run this notebook. This cell also checks that the precursor notebook has been run. Additionally, this cell sets the device_type and the asset_group_id from the stored device type and asset group id in the JSON file produced from the Fast Start Data Loader notebook. Ensure the printed values match your asset group and device. Run the next cell to uninstall the pmlib and srom libraries. This is done to ensure the correct version is installed. Run the next cell to define the API keys used to call Maximo Predict from the Predict_Envs.JSON file Run the next cell to import the os, trim the provided base url to be used when downloading pmlib later in the notebook and used to contact the environment via API.. Run the following cell to reinstall the pmlib library. Run the next four cells to import the srom , sklearn and other necessary packages and libraries Set up the Model Training Pipeline, Train, Register and Enable the Model Run the first to import pmlib library Run the second cell to define the sensor readings columns to be considered in the model Run the next cell to import the models to be tested and trained Run the next cell to view the asset group the desired features will be used in the model training pipeline. Run the next cell to define the model settings for the Pipeline. Run the next cell to train the model. Some models take time to train. Once that process is complete, run the next cell to view the resulting dataframe Run the following cell to register the model to your asset group by running the next cell Finally, Run the next cell to enable it and determine how often it will be run in monitor. This is the last cell to be run in this notebook. Confirm Model Registration Navigate to Maximo Health and Predict for Utilities within your environment Use the left-hand menu to go into Predict Grouping Select your asset group Click into your asset group and ensure you have Predicted Failure Date listed under Trained instances registered for this group and select an asset to go to the Health Dashboard Ensure Next Failure box is populated at the top of the dashboard. Notice that most of these assets will have 0 in that box Scroll down and expand the Predict section to ensure the Predicted Failure Date is visible. Note Recall in the Create Utilities Predict Group and Upload Sensor Data lab only some assets have sensor data. If an asset does not have sensor data, it will not have Predict data. Additionally, most the assets with data will have a Predicted Failure date of 0 \\plusminus x The following assets should have a future failure date when the notebook is ran: Congratulations you have created a Predicted Failure Date model and associated it to your assets!","title":"Train and Register Predicted Failure Date for Utilities Assets"},{"location":"utilities_Failure_date/#create-predicted-failure-date","text":"Maximo Predict comes with notebook templates to assist in streamlining data uploads to Maximo. This notebook will create the Predicted Failure Date using provided csv files. These instructions use the notebook named 5_PMI - Predicted Failure Date-Smart Regression-HPU file with the Substation Transformer for Health and Predict for Utilities Demo Assets. Note that this uses simulated Pump Data for the sensor readings. In this exercise you will use Watson Studio and Health and Predict - Utilities to: Upload the and Run the Predicted Failure Notebook using a template to Train and Display a Predicted Failure Date Confirm the Data Has been uploaded for your assets Note You must complete the previous exercise for Setup Watson Studio before you start this exercise.","title":"Create Predicted Failure Date"},{"location":"utilities_Failure_date/#pre-requisites","text":"Review Predict documentation for the list of available models . Ensure your MAS Predict environment is running and you have access. Try your server URL that might look something like: https://main.predict.ivt11rel87.ivt.suite.myhost.com/ibm/pmi/service/rest/system/info Ensure you have Access to Asset data files for the Health and Predict Utilities Demo Data Complete the Load Data into Manage lab for the Utilities data. Complete the Load Utilities Health Scores via Notebook lab Complete the Create Utilities Predict Group and Upload Sensor Data lab Have the following information from the previous lab: Predict_Envs.JSON and Fast_Execution.JSON Note It is best to perform this lab in your own Watson Studio Project created using Setup Watson Studio instructions. If you are using a shared project, ensure you append each file uploaded with your initials and update the file paths in the notebooks to include that change.","title":"Pre-requisites"},{"location":"utilities_Failure_date/#upload-and-start-the-predicted-failure-date-notebook","text":"Upload or open the Predicted Failure Date template notebook to your Project. Use the steps from the previous exercise Add Notebook From File to a Watson Studio Project If you are using a shared project, rename the notebook template by prepending your initials to the template. If this is done, ensure any paths or file names within the notebook are updated as well. If you already have uploaded the notebook, open it with Watson Studio. Select the 5_PMI - Predicted Failure Date-Smart Regression-HPU notebook template. Open the notebook. Click on the pencil icon next to your notebook. If the notebook fails to start, restart it. Click on the i icon , Environment tab, Running status drop down select box and choose Restart","title":"Upload and Start the Predicted Failure Date Notebook"},{"location":"utilities_Failure_date/#run-the-notebook","text":"","title":"Run the Notebook"},{"location":"utilities_Failure_date/#install-the-maximo-predict-sdk","text":"Read the introduction to the Predicted Failure Date Notebook. Run the first cell to define the requirements and some environment variables to run this notebook. This cell also checks that the precursor notebook has been run. Additionally, this cell sets the device_type and the asset_group_id from the stored device type and asset group id in the JSON file produced from the Fast Start Data Loader notebook. Ensure the printed values match your asset group and device. Run the next cell to uninstall the pmlib and srom libraries. This is done to ensure the correct version is installed. Run the next cell to define the API keys used to call Maximo Predict from the Predict_Envs.JSON file Run the next cell to import the os, trim the provided base url to be used when downloading pmlib later in the notebook and used to contact the environment via API.. Run the following cell to reinstall the pmlib library. Run the next four cells to import the srom , sklearn and other necessary packages and libraries","title":"Install the Maximo Predict SDK"},{"location":"utilities_Failure_date/#set-up-the-model-training-pipeline-train-register-and-enable-the-model","text":"Run the first to import pmlib library Run the second cell to define the sensor readings columns to be considered in the model Run the next cell to import the models to be tested and trained Run the next cell to view the asset group the desired features will be used in the model training pipeline. Run the next cell to define the model settings for the Pipeline. Run the next cell to train the model. Some models take time to train. Once that process is complete, run the next cell to view the resulting dataframe Run the following cell to register the model to your asset group by running the next cell Finally, Run the next cell to enable it and determine how often it will be run in monitor. This is the last cell to be run in this notebook.","title":"Set up the Model Training Pipeline, Train, Register and Enable the Model"},{"location":"utilities_Failure_date/#confirm-model-registration","text":"Navigate to Maximo Health and Predict for Utilities within your environment Use the left-hand menu to go into Predict Grouping Select your asset group Click into your asset group and ensure you have Predicted Failure Date listed under Trained instances registered for this group and select an asset to go to the Health Dashboard Ensure Next Failure box is populated at the top of the dashboard. Notice that most of these assets will have 0 in that box Scroll down and expand the Predict section to ensure the Predicted Failure Date is visible. Note Recall in the Create Utilities Predict Group and Upload Sensor Data lab only some assets have sensor data. If an asset does not have sensor data, it will not have Predict data. Additionally, most the assets with data will have a Predicted Failure date of 0 \\plusminus x The following assets should have a future failure date when the notebook is ran: Congratulations you have created a Predicted Failure Date model and associated it to your assets!","title":"Confirm Model Registration"},{"location":"utilities_anomaly_detection/","text":"Create Utilities Anomaly Detection Model Maximo Predict comes with notebook templates to assist in streamlining data uploads to Maximo. This notebook will create the following resources using provided csv files: Anomaly Score Anomaly Score History These instructions use the notebook named 3_PMI - Anomaly Detection -UnSupervised-HPU.ipynb file with the Substation Transformer for Health and Predict for Utilities Demo Assets. Note that this uses simulated Pump Data for the sensor readings. In this exercise you will use Watson Studio and Health and Predict - Utilities to: Upload the and Run the Anomaly Detection Notebook using a template to Train and Display an Anomaly Detection Model Confirm the Data Has been uploaded for your assets Note You must complete the previous exercise for Setup Watson Studio before you start this exercise. Pre-requisites Review Predict documentation for the list of available models . Ensure your MAS Predict environment is running and you have access. Try your server URL that might look something like: https://main.predict.ivt11rel87.ivt.suite.myhost.com/ibm/pmi/service/rest/system/info Ensure you have Access to Asset data files for the Health and Predict Utilities Demo Data Complete the Load Data into Manage lab for the Utilities data. Complete the Load Utilities Health Scores via Notebook lab Complete the Create Utilities Predict Group and Upload Sensor Data lab Have the following information from the previous lab: Predict_Envs.JSON and Fast_Execution.JSON Note It is best to perform this lab in your own Watson Studio Project created using Setup Watson Studio instructions. If you are using a shared project, ensure you append each file uploaded with your initials and update the file paths in the notebooks to include that change. Upload and Start the Anomaly Detection Unsupervised Notebook Upload or open the Anomaly Detection template notebook to your Project. Use the steps from the previous exercise Add Notebook From File to a Watson Studio Project If you are using a shared project, rename the notebook template by prepending your initials to the template. If this is done, ensure any paths or file names within the notebook are updated as well. If you already have uploaded the notebook, open it with Watson Studio. Select the 3_PMI - Anomaly Detection -UnSupervised-HPU.ipynb notebook template. Open the notebook. Click on the pencil icon next to your notebook If the notebook fails to start, restart it. Click on the i icon , Environment tab, Running status drop down select box and choose Restart Run the Notebook Install the Maximo Predict SDK Run the cell to uninstall the libraries. This is done to ensure the right version is installed later in the process. Run the next cell to define the requirements and some environment variables to run this notebook. This cell also checks that the precusor notebook has been run Run the next cell to define the API keys used to call Maximo Predict from the Predict_Envs.JSON file Run the next two cells to import the os, trim the provided base url to be used when downloading pmlib in the second cell Run the final 4 cells in this section to import the pmlib , srom , and logging libraries Set up the Model Training Pipeline Run the first cell to obtain the Asset Group ID from the JSON file produced in the Create Utilities Predict Group and Upload Sensor Data lab. Note that it prints out the Predict Group ID after being extracted. Run the next cell to extract the device type and the desired features to be considered in the anomaly model. Run the next cell to define the scoring strategy. There are three different scoring strategies shown to choose from. Run the following cell to import all the anomaly detection models to be run through the pipeline and other functions necessary for this process Run the following two cells to define the model pipeline for the determined features. This cell defines the settings to be used within the model algorithm during the training process. Run the next cells to define the model group containting the pipeline, and the asset group id that the model will be trained on Train, Register and Enable the Model Run the first cell to train the model. Some models take time to train. Once that process is complete, register the model to your asset group by running the next cell Finally, Run the next cell to enable it and determine how often it will be run in monitor. This is the last cell to be run in this notebook. Confirm Model Registration Navigate to Maximo Health and Predict for Utilities within your environment Use the left-hand menu to go into Predict Grouping Select your asset group Click into your asset group and ensure you have the Anomaly Detection Model listed under Trained instances registered for this group and select an asset to go to the Health Dashboard Scroll down and expand the Predict section to ensure the anomaly detection history and the anomaly detection score is visible. Note Recall in the Create Utilities Predict Group and Upload Sensor Data lab only some assets have sensor data. If an asset does not have sensor data, it will not have Predict data Congratulations you have created an Anomaly Detection model and associated it to your assets!","title":"Train and Register Anomaly Detection Model for Utilities Assets"},{"location":"utilities_anomaly_detection/#create-utilities-anomaly-detection-model","text":"Maximo Predict comes with notebook templates to assist in streamlining data uploads to Maximo. This notebook will create the following resources using provided csv files: Anomaly Score Anomaly Score History These instructions use the notebook named 3_PMI - Anomaly Detection -UnSupervised-HPU.ipynb file with the Substation Transformer for Health and Predict for Utilities Demo Assets. Note that this uses simulated Pump Data for the sensor readings. In this exercise you will use Watson Studio and Health and Predict - Utilities to: Upload the and Run the Anomaly Detection Notebook using a template to Train and Display an Anomaly Detection Model Confirm the Data Has been uploaded for your assets Note You must complete the previous exercise for Setup Watson Studio before you start this exercise.","title":"Create Utilities Anomaly Detection Model"},{"location":"utilities_anomaly_detection/#pre-requisites","text":"Review Predict documentation for the list of available models . Ensure your MAS Predict environment is running and you have access. Try your server URL that might look something like: https://main.predict.ivt11rel87.ivt.suite.myhost.com/ibm/pmi/service/rest/system/info Ensure you have Access to Asset data files for the Health and Predict Utilities Demo Data Complete the Load Data into Manage lab for the Utilities data. Complete the Load Utilities Health Scores via Notebook lab Complete the Create Utilities Predict Group and Upload Sensor Data lab Have the following information from the previous lab: Predict_Envs.JSON and Fast_Execution.JSON Note It is best to perform this lab in your own Watson Studio Project created using Setup Watson Studio instructions. If you are using a shared project, ensure you append each file uploaded with your initials and update the file paths in the notebooks to include that change.","title":"Pre-requisites"},{"location":"utilities_anomaly_detection/#upload-and-start-the-anomaly-detection-unsupervised-notebook","text":"Upload or open the Anomaly Detection template notebook to your Project. Use the steps from the previous exercise Add Notebook From File to a Watson Studio Project If you are using a shared project, rename the notebook template by prepending your initials to the template. If this is done, ensure any paths or file names within the notebook are updated as well. If you already have uploaded the notebook, open it with Watson Studio. Select the 3_PMI - Anomaly Detection -UnSupervised-HPU.ipynb notebook template. Open the notebook. Click on the pencil icon next to your notebook If the notebook fails to start, restart it. Click on the i icon , Environment tab, Running status drop down select box and choose Restart","title":"Upload and Start the Anomaly Detection Unsupervised Notebook"},{"location":"utilities_anomaly_detection/#run-the-notebook","text":"","title":"Run the Notebook"},{"location":"utilities_anomaly_detection/#install-the-maximo-predict-sdk","text":"Run the cell to uninstall the libraries. This is done to ensure the right version is installed later in the process. Run the next cell to define the requirements and some environment variables to run this notebook. This cell also checks that the precusor notebook has been run Run the next cell to define the API keys used to call Maximo Predict from the Predict_Envs.JSON file Run the next two cells to import the os, trim the provided base url to be used when downloading pmlib in the second cell Run the final 4 cells in this section to import the pmlib , srom , and logging libraries","title":"Install the Maximo Predict SDK"},{"location":"utilities_anomaly_detection/#set-up-the-model-training-pipeline","text":"Run the first cell to obtain the Asset Group ID from the JSON file produced in the Create Utilities Predict Group and Upload Sensor Data lab. Note that it prints out the Predict Group ID after being extracted. Run the next cell to extract the device type and the desired features to be considered in the anomaly model. Run the next cell to define the scoring strategy. There are three different scoring strategies shown to choose from. Run the following cell to import all the anomaly detection models to be run through the pipeline and other functions necessary for this process Run the following two cells to define the model pipeline for the determined features. This cell defines the settings to be used within the model algorithm during the training process. Run the next cells to define the model group containting the pipeline, and the asset group id that the model will be trained on","title":"Set up the Model Training Pipeline"},{"location":"utilities_anomaly_detection/#train-register-and-enable-the-model","text":"Run the first cell to train the model. Some models take time to train. Once that process is complete, register the model to your asset group by running the next cell Finally, Run the next cell to enable it and determine how often it will be run in monitor. This is the last cell to be run in this notebook.","title":"Train, Register and Enable the Model"},{"location":"utilities_anomaly_detection/#confirm-model-registration","text":"Navigate to Maximo Health and Predict for Utilities within your environment Use the left-hand menu to go into Predict Grouping Select your asset group Click into your asset group and ensure you have the Anomaly Detection Model listed under Trained instances registered for this group and select an asset to go to the Health Dashboard Scroll down and expand the Predict section to ensure the anomaly detection history and the anomaly detection score is visible. Note Recall in the Create Utilities Predict Group and Upload Sensor Data lab only some assets have sensor data. If an asset does not have sensor data, it will not have Predict data Congratulations you have created an Anomaly Detection model and associated it to your assets!","title":"Confirm Model Registration"},{"location":"utilities_devicedata/","text":"Create Utilities Predict Group and Upload Sensor Data Maximo Predict comes with notebook templates to assist in streamlining data uploads to Maximo. This notebook will create the following resources using provided csv files: Device Data in Monitor Device Asset Mapping Predict Groups These instructions use the notebook named 2_FastStartLoader-Predict.ipynb file with the Substation Transformer for Health and Predict for Utilities Demo Assets. Note that this uses simulated Pump Data for the sensor readings. In this exercise you will use Watson Studio and Health and Predict - Utilities to: Gather notebook and CSV files for all data to be uploaded Upload the and Run the Fast Start HPU Data Loader Notebooks using a template to upload new Device Data and Predict Groups into Maximo Confirm the Data Has been uploaded for your assets Handle Errors that may come up in the process Note You must complete the previous exercise for Setup Watson Studio before you start this exercise. Pre-requisites Review Predict documentation for the list of available models . Ensure your MAS Predict environment is running and you have access. Try your server URL that might look something like: https://main.predict.ivt11rel87.ivt.suite.myhost.com/ibm/pmi/service/rest/system/info Ensure you have Access to Asset data files for the Health and Predict Utilities Demo Data Complete the Load Data into Manage lab for the Utilities data. Complete the Load Utilities Health Scores via Notebook lab Have the following information from the previous lab: SITE_ID Note It is best to perform this lab in your own Watson Studio Project created using Setup Watson Studio instructions. If you are using a shared project, ensure you append each file uploaded with your initials and update the file paths in the notebooks to include that change. Gather notebooks and CSV Files Ensure you have the 2_FastStartLoader-Predict.ipynb notebook from the github as outlined in Load Data into Manage . In that folder, ensure you have 3 csv files under csv > predict_csv_st containing asset installation information, asset failure dates and sensor data Open the hpu_st_failure_data_afm_vel_timeshifted_v17.csv and update the Site ID to your site ID from Load Data into Manage In the notebooks folder there should be a file titled 2_FastStartLoader-Predict.ipynb Upload and Start the Fast Start Data Loader Notebook Upload or open the Fast Start Data Loader template notebook to your Project. Use the steps from the previous exercise Add Notebook From File to a Watson Studio Project Rename the notebook template by prepending your initials to the template. If you already have uploaded the notebook, open it with Watson Studio. Select the 2_FastStartLoader-Predict.ipynb notebook template. Open the notebook. Click on the pencil icon next to your notebook If the notebook fails to start, restart it. Click on the i icon , Environment tab, Running status drop down select box and choose Restart Run the Notebook Run the first cell two cells. These cells are setting up the files required to complete the notebook. Read the introduction for details on the notebook and how it fits into the Maximo Predict process. Ensure you have a 'Predict_Envs.json' file uploaded. If one is not provided, follow the instructions in set up Watson Studio under the 'Get URL' section to gather the APM_ID , APM_API_BASE_URL , and APM_API_KEY to create a JSON file containing the credentials and upload to Watson Studio with your initials prepended to the file name. Run the cell to open the JSON file. Run the cell to uninstall the pmlib. This is done to ensure the right version is installed later in the process. Run the following two cells to set up variables required for the environment and the structure of the JSON file that will be stored on completion of the notebook. Note that both should produce an output without error. Run the following 3 cells to install pmlib and import the additional required libraries Update default_site_id = 'EULARGE1' to default_site_id = '{your site id}' Run the cell to define your device type name, site id, and your asset group label. Make a note of the resulting output. This is the asset group label that will be the name of your predict group. Run the following cell to import the csv containing the asset data and update the dataframe's data types Run the next cell to import the sensor data and update the data frame to match the desired format. This will replace the device type with the one defined two cells above and adds the asset id for each row. Run the following cell to rename the timestamp column to the desired name and data type. Run the following cell to create a list of the different Device Ids that will be created. Note that not all the assets have an associated device data. Run the next cell to upload the failure data as a dataframe Run the next cell to create add the devices to the asset data table imported in step 10 Run the following cell to construct the asset device mapping table that will be needed for later in the notebook Run the next 6 cells to delete the data. These cells do NOT have to be run if this is the first time uploading data. If you need to re-upload the sensor data or recreate the group then the cells are required to be run. The final cell has a 5 minute delay to ensure the data gets fully deleted. Notice there is a commented out cell that would delete your assets. This is because we uploaded assets using the Load Data into Manage and did not want to delete the extra data we uploaded. Run the next cell following the delete cells to import the Maximo api calls and clean up the data frames. Run the next cell to confirm the asset_group_label_afm that will be the name of your predict group The next few cells will be inserting the asset data into Maximo. Run the first cell to confirm the asset data to be imported Run the next two cells to shift the time of the sensor data to two days ago (to be more recent) and the failure dates accordingly Note that the data is now in the current year The next two commented out cells will create the assets and asset attributes. Since this information was uploaded earlier in the lab, they do not have to be run Run the next cell to check if the failure code exists in your organization. If it does not, it will create one. Run the next cell to import the asset failure history Run the following cell to define the functions to create the asset group and filter for that group Run the next cell to use those functions to create the asset group filter and create teh asset group. Run the next cell to get the asset group id for the recently created predict group. This will be stored in a json file and used in future notebooks. Run the final cell in this section to view and note the asset group id Run the first cell in the Setup IOT Devices section to update the column headers and view the dataframe along with the amount of data to be uploaded Run the following cell to load in the training data for the models. This will set up the IOT devices and the associated sensor data. Run the next cell to view the asset device mappings to be uploaded Run the next cell to load the asset device mappings Run the final three cells to save and view the data in the fast_execution.json file. Ensure the asset_group_id and the 34. Run the final three cells to save and view the data in the fast_execution.json file. Ensure the asset_group_id and the device_type match the values displayed throughout the notebook The remaining cells will create scoring data for the predict group created. This is not being done since in the following labs, models will be created and assets will be scored for the created predict group at that time. Confirm Data Upload and Prediction Groups Confirm that the historical data was uploaded to Monitor. Confirm that the Prediction group was created and linked to the model notebook template you created. Navigate to Maximo Health and Predict for Utilities within your environment Use the left-hand menu to go into Predict Grouping Ensure your asset group is available in the list and confirm your asset is available within the group. Navigate to IOT within your environment. Under devices , search to ensure your device is there Navigate to Device Types and find your device type. Check that your physical and logical interfaces are active. Navigate to Monitor and ensure your devices have data Error Handling Update DateFrame Header If you receive an object attribute error for pandas, with a column header initialized in Part 2 step 10 listed similar to: Then follow these steps to replace your dataframe header to resolve this error. 1. Click into the cell that resulted in an error. In the menu, go to Insert > Cell Above Rename the columns by adding the following code in the cell: {DataFrame_to_Change}.rename(columns={'{current_column_header}': site_id_col_name}, inplace=True) {DataFrame_to_Change}.head() Run the cell. The output should show the new header in the table. For example: in order to change the failure_data_afm_df column header from 'site' to the preferred header: Congratulations you have loaded historical data and created Predict Groups linking your device's metrics inputs to list of assets and notebook template that will be used to score predictions using Predict with Monitor device data!","title":"Create Utilities Predict Group and Upload Sensor Data"},{"location":"utilities_devicedata/#create-utilities-predict-group-and-upload-sensor-data","text":"Maximo Predict comes with notebook templates to assist in streamlining data uploads to Maximo. This notebook will create the following resources using provided csv files: Device Data in Monitor Device Asset Mapping Predict Groups These instructions use the notebook named 2_FastStartLoader-Predict.ipynb file with the Substation Transformer for Health and Predict for Utilities Demo Assets. Note that this uses simulated Pump Data for the sensor readings. In this exercise you will use Watson Studio and Health and Predict - Utilities to: Gather notebook and CSV files for all data to be uploaded Upload the and Run the Fast Start HPU Data Loader Notebooks using a template to upload new Device Data and Predict Groups into Maximo Confirm the Data Has been uploaded for your assets Handle Errors that may come up in the process Note You must complete the previous exercise for Setup Watson Studio before you start this exercise.","title":"Create Utilities Predict Group and Upload Sensor Data"},{"location":"utilities_devicedata/#pre-requisites","text":"Review Predict documentation for the list of available models . Ensure your MAS Predict environment is running and you have access. Try your server URL that might look something like: https://main.predict.ivt11rel87.ivt.suite.myhost.com/ibm/pmi/service/rest/system/info Ensure you have Access to Asset data files for the Health and Predict Utilities Demo Data Complete the Load Data into Manage lab for the Utilities data. Complete the Load Utilities Health Scores via Notebook lab Have the following information from the previous lab: SITE_ID Note It is best to perform this lab in your own Watson Studio Project created using Setup Watson Studio instructions. If you are using a shared project, ensure you append each file uploaded with your initials and update the file paths in the notebooks to include that change.","title":"Pre-requisites"},{"location":"utilities_devicedata/#gather-notebooks-and-csv-files","text":"Ensure you have the 2_FastStartLoader-Predict.ipynb notebook from the github as outlined in Load Data into Manage . In that folder, ensure you have 3 csv files under csv > predict_csv_st containing asset installation information, asset failure dates and sensor data Open the hpu_st_failure_data_afm_vel_timeshifted_v17.csv and update the Site ID to your site ID from Load Data into Manage In the notebooks folder there should be a file titled 2_FastStartLoader-Predict.ipynb","title":"Gather notebooks and CSV Files"},{"location":"utilities_devicedata/#upload-and-start-the-fast-start-data-loader-notebook","text":"Upload or open the Fast Start Data Loader template notebook to your Project. Use the steps from the previous exercise Add Notebook From File to a Watson Studio Project Rename the notebook template by prepending your initials to the template. If you already have uploaded the notebook, open it with Watson Studio. Select the 2_FastStartLoader-Predict.ipynb notebook template. Open the notebook. Click on the pencil icon next to your notebook If the notebook fails to start, restart it. Click on the i icon , Environment tab, Running status drop down select box and choose Restart","title":"Upload and Start the Fast Start Data Loader Notebook"},{"location":"utilities_devicedata/#run-the-notebook","text":"Run the first cell two cells. These cells are setting up the files required to complete the notebook. Read the introduction for details on the notebook and how it fits into the Maximo Predict process. Ensure you have a 'Predict_Envs.json' file uploaded. If one is not provided, follow the instructions in set up Watson Studio under the 'Get URL' section to gather the APM_ID , APM_API_BASE_URL , and APM_API_KEY to create a JSON file containing the credentials and upload to Watson Studio with your initials prepended to the file name. Run the cell to open the JSON file. Run the cell to uninstall the pmlib. This is done to ensure the right version is installed later in the process. Run the following two cells to set up variables required for the environment and the structure of the JSON file that will be stored on completion of the notebook. Note that both should produce an output without error. Run the following 3 cells to install pmlib and import the additional required libraries Update default_site_id = 'EULARGE1' to default_site_id = '{your site id}' Run the cell to define your device type name, site id, and your asset group label. Make a note of the resulting output. This is the asset group label that will be the name of your predict group. Run the following cell to import the csv containing the asset data and update the dataframe's data types Run the next cell to import the sensor data and update the data frame to match the desired format. This will replace the device type with the one defined two cells above and adds the asset id for each row. Run the following cell to rename the timestamp column to the desired name and data type. Run the following cell to create a list of the different Device Ids that will be created. Note that not all the assets have an associated device data. Run the next cell to upload the failure data as a dataframe Run the next cell to create add the devices to the asset data table imported in step 10 Run the following cell to construct the asset device mapping table that will be needed for later in the notebook Run the next 6 cells to delete the data. These cells do NOT have to be run if this is the first time uploading data. If you need to re-upload the sensor data or recreate the group then the cells are required to be run. The final cell has a 5 minute delay to ensure the data gets fully deleted. Notice there is a commented out cell that would delete your assets. This is because we uploaded assets using the Load Data into Manage and did not want to delete the extra data we uploaded. Run the next cell following the delete cells to import the Maximo api calls and clean up the data frames. Run the next cell to confirm the asset_group_label_afm that will be the name of your predict group The next few cells will be inserting the asset data into Maximo. Run the first cell to confirm the asset data to be imported Run the next two cells to shift the time of the sensor data to two days ago (to be more recent) and the failure dates accordingly Note that the data is now in the current year The next two commented out cells will create the assets and asset attributes. Since this information was uploaded earlier in the lab, they do not have to be run Run the next cell to check if the failure code exists in your organization. If it does not, it will create one. Run the next cell to import the asset failure history Run the following cell to define the functions to create the asset group and filter for that group Run the next cell to use those functions to create the asset group filter and create teh asset group. Run the next cell to get the asset group id for the recently created predict group. This will be stored in a json file and used in future notebooks. Run the final cell in this section to view and note the asset group id Run the first cell in the Setup IOT Devices section to update the column headers and view the dataframe along with the amount of data to be uploaded Run the following cell to load in the training data for the models. This will set up the IOT devices and the associated sensor data. Run the next cell to view the asset device mappings to be uploaded Run the next cell to load the asset device mappings Run the final three cells to save and view the data in the fast_execution.json file. Ensure the asset_group_id and the 34. Run the final three cells to save and view the data in the fast_execution.json file. Ensure the asset_group_id and the device_type match the values displayed throughout the notebook The remaining cells will create scoring data for the predict group created. This is not being done since in the following labs, models will be created and assets will be scored for the created predict group at that time.","title":"Run the Notebook"},{"location":"utilities_devicedata/#confirm-data-upload-and-prediction-groups","text":"Confirm that the historical data was uploaded to Monitor. Confirm that the Prediction group was created and linked to the model notebook template you created. Navigate to Maximo Health and Predict for Utilities within your environment Use the left-hand menu to go into Predict Grouping Ensure your asset group is available in the list and confirm your asset is available within the group. Navigate to IOT within your environment. Under devices , search to ensure your device is there Navigate to Device Types and find your device type. Check that your physical and logical interfaces are active. Navigate to Monitor and ensure your devices have data","title":"Confirm Data Upload and Prediction Groups"},{"location":"utilities_devicedata/#error-handling","text":"","title":"Error Handling"},{"location":"utilities_devicedata/#update-dateframe-header","text":"If you receive an object attribute error for pandas, with a column header initialized in Part 2 step 10 listed similar to: Then follow these steps to replace your dataframe header to resolve this error. 1. Click into the cell that resulted in an error. In the menu, go to Insert > Cell Above Rename the columns by adding the following code in the cell: {DataFrame_to_Change}.rename(columns={'{current_column_header}': site_id_col_name}, inplace=True) {DataFrame_to_Change}.head() Run the cell. The output should show the new header in the table. For example: in order to change the failure_data_afm_df column header from 'site' to the preferred header: Congratulations you have loaded historical data and created Predict Groups linking your device's metrics inputs to list of assets and notebook template that will be used to score predictions using Predict with Monitor device data!","title":"Update DateFrame Header"},{"location":"utilities_score_notebook/","text":"Load Utilities Health Scores via Notebook Maximo Predict comes with notebook templates to assist in streamlining data uploads of the industry standard health score for utilities assets into Maximo Health. This notebook will Create a health scoring group and the associated health, risk, criticality, effective age, end of life, duval triangle and the history of combustible gases scores. These instructions will be based off using the '1_Create-HPU-ScoreGroups.ipynb' file with the Substation Transformer Health and Predict for Utilities Demo Assets. In this exercise you will use Watson Studio, Manage and Predict to: Upload the and Run the HPU Health Score Group notebook using a template to upload new Asset and Location Data to Maximo Manage. Confirm Scoring groups have been created and scores have been calculated Handle Errors that may come up in the process Note You must complete the previous exercise for Setup Watson Studio before you start this exercise. This notebook can only be run once per environment per site with the same set of assets. Pre-requisites Review Predict documentation for the list of available models . Ensure your MAS Predict environment is running and you have access. Try your server URL that might look something like: https://main.predict.ivt11rel87.ivt.suite.myhost.com/ibm/pmi/service/rest/system/info Ensure you have Access to Asset data files for the Health and Predict Utilities Demo Data Complete the Load Data into Manage lab for the Utilities data. Have the following information from the previous lab: MX_BASE_URL , API_KEY , SITE_ID and ORG_ID Note It is best to perform this lab in your own Watson Studio Project created using Setup Watson Studio instructions. If you are using a shared project, ensure you append each file uploaded with your initials and update the file paths in the notebooks to include that change. Upload files and run the Data Loader Notebook Load Data into Manage lab to your project. Use the steps from the previous exercise Add Notebook From File to a Watson Studio Project . Select the 1_Create-HPU-ScoreGroups.ipynb notebook template. Click on the pencil icon next to your notebook to open it in edit mode. If the notebook fails to start, restart it. Click on the i icon , Environment tab, Running status dropdown select box and choose Restart Run the first cell to import packages Add the MX_BASE_URL and API_KEY from the previous lab to cell 2 Update the site id value to your SITE_ID and the prefix value to your org id ORG_ID in the second cell Uncomment the asset class you will be uploading. In this lab we will be focusing on only Substation Transformer, so the first ASSET_CLASS list containing only one item is uncommented. If we were uploading all demo asset classes available in the github, uncomment the second section. If you have additional assets, use the third list and uncomment as needed. Here are two ways to comment out a cell: add a # to the beginning of each line or add ''' to the beginning and end of a section of code for it to be ignored when run Run the next cell to define the API call for Maximo Run the next 3 cells to define function for creating the following: The query that will be used to build the health scores Get the scores list and activate the scores Create the asset group, create scores for the asset group and clean up Run the next cell to delete any existing asset score groups for your data. If none exists, the cell will output None . Run the next cell to create the query for the Asset Scoring Group. This query will be made up of Asset Type and Site ID Run the next cell to create the Asset Scoring Group using the query from the previous cell, Build the scores from the Industry Standard Provided notebooks, and activate the scores. Confirm Proper Data Upload The following steps will confirm that the data was uploaded properly Navigate to Maximo Health and Predict for Utilities for the provided environment Go to the Scoring and DGA Settings application within Maximo H&PU Search for your Org or Site and notice that there are two score groups created - One for Assets and One for Locations. Notice the calculation type is Connect group to notebook since the scores are built via notebooks for the specific Asset Classification 4. Click into the Score Groups and notice all the score types created via the Asset Type specific notebook listed in the Group Details section 5. Click Recalculate Scores and allow the scores to calculate 6. Click into any asset and see that the scores have calculated Congratulations you have seen how to upload Health and Predict for utilities data via a notebook. You have also gained experience using Jupyter Notebooks in Watson Studio! In the next exercises you will learn how to use the 1_Create-HPU-ScoreGroups.ipynb Notebook template to create health scores for Health and Predict for Utilities assets and associate the asset notebook to that created group.","title":"Create Health Scores Using Utilities Notebooks"},{"location":"utilities_score_notebook/#load-utilities-health-scores-via-notebook","text":"Maximo Predict comes with notebook templates to assist in streamlining data uploads of the industry standard health score for utilities assets into Maximo Health. This notebook will Create a health scoring group and the associated health, risk, criticality, effective age, end of life, duval triangle and the history of combustible gases scores. These instructions will be based off using the '1_Create-HPU-ScoreGroups.ipynb' file with the Substation Transformer Health and Predict for Utilities Demo Assets. In this exercise you will use Watson Studio, Manage and Predict to: Upload the and Run the HPU Health Score Group notebook using a template to upload new Asset and Location Data to Maximo Manage. Confirm Scoring groups have been created and scores have been calculated Handle Errors that may come up in the process Note You must complete the previous exercise for Setup Watson Studio before you start this exercise. This notebook can only be run once per environment per site with the same set of assets.","title":"Load Utilities Health Scores via Notebook"},{"location":"utilities_score_notebook/#pre-requisites","text":"Review Predict documentation for the list of available models . Ensure your MAS Predict environment is running and you have access. Try your server URL that might look something like: https://main.predict.ivt11rel87.ivt.suite.myhost.com/ibm/pmi/service/rest/system/info Ensure you have Access to Asset data files for the Health and Predict Utilities Demo Data Complete the Load Data into Manage lab for the Utilities data. Have the following information from the previous lab: MX_BASE_URL , API_KEY , SITE_ID and ORG_ID Note It is best to perform this lab in your own Watson Studio Project created using Setup Watson Studio instructions. If you are using a shared project, ensure you append each file uploaded with your initials and update the file paths in the notebooks to include that change.","title":"Pre-requisites"},{"location":"utilities_score_notebook/#upload-files-and-run-the-data-loader-notebook","text":"Load Data into Manage lab to your project. Use the steps from the previous exercise Add Notebook From File to a Watson Studio Project . Select the 1_Create-HPU-ScoreGroups.ipynb notebook template. Click on the pencil icon next to your notebook to open it in edit mode. If the notebook fails to start, restart it. Click on the i icon , Environment tab, Running status dropdown select box and choose Restart Run the first cell to import packages Add the MX_BASE_URL and API_KEY from the previous lab to cell 2 Update the site id value to your SITE_ID and the prefix value to your org id ORG_ID in the second cell Uncomment the asset class you will be uploading. In this lab we will be focusing on only Substation Transformer, so the first ASSET_CLASS list containing only one item is uncommented. If we were uploading all demo asset classes available in the github, uncomment the second section. If you have additional assets, use the third list and uncomment as needed. Here are two ways to comment out a cell: add a # to the beginning of each line or add ''' to the beginning and end of a section of code for it to be ignored when run Run the next cell to define the API call for Maximo Run the next 3 cells to define function for creating the following: The query that will be used to build the health scores Get the scores list and activate the scores Create the asset group, create scores for the asset group and clean up Run the next cell to delete any existing asset score groups for your data. If none exists, the cell will output None . Run the next cell to create the query for the Asset Scoring Group. This query will be made up of Asset Type and Site ID Run the next cell to create the Asset Scoring Group using the query from the previous cell, Build the scores from the Industry Standard Provided notebooks, and activate the scores.","title":"Upload files and run the Data Loader Notebook"},{"location":"utilities_score_notebook/#confirm-proper-data-upload","text":"The following steps will confirm that the data was uploaded properly Navigate to Maximo Health and Predict for Utilities for the provided environment Go to the Scoring and DGA Settings application within Maximo H&PU Search for your Org or Site and notice that there are two score groups created - One for Assets and One for Locations. Notice the calculation type is Connect group to notebook since the scores are built via notebooks for the specific Asset Classification 4. Click into the Score Groups and notice all the score types created via the Asset Type specific notebook listed in the Group Details section 5. Click Recalculate Scores and allow the scores to calculate 6. Click into any asset and see that the scores have calculated Congratulations you have seen how to upload Health and Predict for utilities data via a notebook. You have also gained experience using Jupyter Notebooks in Watson Studio! In the next exercises you will learn how to use the 1_Create-HPU-ScoreGroups.ipynb Notebook template to create health scores for Health and Predict for Utilities assets and associate the asset notebook to that created group.","title":"Confirm Proper Data Upload"}]}