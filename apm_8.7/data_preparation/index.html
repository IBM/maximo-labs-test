<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="author" content="Carlos Ferreira & Contributors" /><link rel="canonical" href="https://ibm.github.io/maximo-labs/data_preparation/" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>Data Preparation - Maximo APM V8.7 Hands On Lab</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Data Preparation";
        var mkdocs_page_input_path = "data_preparation.md";
        var mkdocs_page_url = "/maximo-labs/data_preparation/";
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> Maximo APM V8.7 Hands On Lab
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="" href="../..">Get back to Maximo Labs</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Maximo APM V8.7.0 Lab</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="..">Welcome to the Lab</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../get_started/">Get Started</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../prereqs/">Pre-Requisites</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Exercises</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../setup_watson_studio/">Setup Watson Studio for Predict</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../hpu_models/">Understand Health and Predict - Utilities Models</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="#">Data Preparation</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#download-pump-data-and-import-to-watson-studio-notebook">Download Pump Data and Import to Watson Studio Notebook</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#add-the-data-preparation-notebook-to-watson-studio">Add the Data Preparation Notebook to Watson Studio</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#set-environment-variables">Set Environment Variables</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#verify-environment-variables">Verify Environment Variables</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#prepare-asset-information-data">Prepare Asset Information Data</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#create-an-asset-information-file">Create an Asset Information File</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#prepare-asset-metrics-data">Prepare Asset Metrics Data</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#create-an-asset-metrics-file">Create an Asset Metrics File</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#prepare-asset-failure-data">Prepare Asset Failure Data</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#create-an-asset-failure-file">Create an Asset Failure File</a>
    </li>
        </ul>
    </li>
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../asset_data_loader/">Load Utilities Data Into Manage</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../utilities_score_notebook/">Create Health Scores Using Utilities Notebooks</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../utilities_devicedata/">Create Utilities Predict Group and Upload Sensor Data</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../utilities_anomaly_detection/">Train and Register Anomaly Detection Model for Utilities Assets</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../utilities_EOL/">Train and Register End of Life Curve for Utilities Assets</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../utilities_Failure_date/">Train and Register Predicted Failure Date for Utilities Assets</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../utilities_Failure_Probability/">Train and Register Failure Probability for Utilities Assets</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../data_dictionary/">Pump Data Dictionary</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../fast_start_loader/">Load Pump Data Into Monitor</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../health_score/">Asset Health Scoring</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../asset_investment/">Asset Investment Optimization</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../appconnect_install/">Install and Configure App Connect</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">About</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../release_notes/">Release Notes</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../copyright">Copyright</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">Maximo APM V8.7 Hands On Lab</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">Exercises</li>
      <li class="breadcrumb-item active">Data Preparation</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="data-preparation-and-loading-using-notebooks">Data Preparation and Loading Using Notebooks</h1>
<p>In this exercise you will use Predict libraries and notebook in Watson Studio to:</p>
<ul>
<li><a href="#download_data">Download Pump Data and Import into Watson Studio Notebook</a> from Kaggle website</li>
<li><a href="#data_preparation">Add the data prepration notebook template</a> included with this lab to prepare the pump data.</li>
<li><a href="#asset_information_file">Create an asset information file</a> to describe the pump used in later exercises for EOL Curve algorithm. </li>
<li><a href="#asset_metrics_file">Create an asset metrics file</a> used to train and test the Failure Prediction Date algorithm.</li>
<li><a href="#asset_failure_file">Create an asset failure file</a> used to train and test the Failure Prediction Date algorithm.</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Be sure to prepend your initials on all the data asset files you create in this exercise so that you can be sure you are creating the files correctly.</p>
</div>
<h2 id="download-pump-data-and-import-to-watson-studio-notebook">Download Pump Data and Import to Watson Studio Notebook</h2>
<p><a name="download_data"></a></p>
<ol>
<li>
<p>Download data from <a href="https://www.kaggle.com/datasets/nphantawee/pump-sensor-data?resource=download">Kaggle</a>. Name the file <code>kaggle-pump-sensor.csv</code>.  If the file is already present in your project you can skip this step.</p>
</li>
<li>
<p>Click on <code>Assets</code> tab.  Click on <code>Add to Project</code> button.  Select <code>Data</code>.  Browse to and select the CSV file you downloaded from the Kaggle Web site. Alternatively just drag the CSV file into data asset project on the right. 
<img alt="Dowload_Pump_data" src="../img/p64.png" /></p>
</li>
</ol>
<h2 id="add-the-data-preparation-notebook-to-watson-studio">Add the Data Preparation Notebook to Watson Studio</h2>
<p><a name="data_preparation"></a></p>
<p>Data preparation involves cleaning data,  reshaping the data columns and rows into the format and values needed for each notebook template.   In some cases it involves removing rows or columns that have invalid or blank values (NaN).  Or imputing values to replace blank values (NaN).  The data preparation notebook has already been created for you for use. </p>
<ol>
<li>
<p>Use the steps from the previous exercises <a href="add-notebook-to-studio">Add Notebook From File to a Watson Studio Project</a> to add the <code>data_preparation.ipynb</code>to your Watson Studio Project or the Project suggested by your facilitator.  Rename your notebook by pre-pending your initials to the notebook. <br />
Use the steps below to understand or recreate the notebook yourself.</p>
</li>
<li>
<p>Create a <code>new notebook from file</code> to prepare the date to be used by Predict for predicting failures.  Browse to open the <code>./notebooks/data_preparation.ipynb</code> be sure to pre-pend your initials and pick the v4CPU Python 3.8 environment. </p>
</li>
<li>
<p>Study each notebook cell in the data_preparation notebook.  The first cell loads needed libraries to process the data using Pandas and Numpy which are open source libraries used to analyze and process timeseries data. The explanation of these libraries is outside the scope of this lab and is a pre-requisite.</p>
</li>
</ol>
<p><strong>Sample Code</strong></p>
<pre><code>import pandas as pd
import numpy as np
import time
import sys
</code></pre>
<ol>
<li>The next cell sets the display values to be able to see the data tables and logs in the Jupyter notebook for <code>df head()</code></li>
</ol>
<p><strong>Sample Code</strong></p>
<pre><code>pd.set_option('display.max_columns', None)
pd.set_option('max_colwidth', 1000)
pd.set_option('max_rows', 100)
pd.set_option('display.max_rows', 100)
pd.set_option('display.max_columns', 100)
</code></pre>
<ol>
<li>
<p>Insert the code to load the <code>kaggle-pump-sensor.csv</code> that you uploaded earlier in the exercise. Click on the <code>code generator icon</code> at the top of Watson Studio.  Click on the <code>kaggle-pump-sensor.csv</code> file you downloaded earlier and named <code>kaggle-pump-sensor.csv</code>.</p>
</li>
<li>
<p>The code is inserted into a new cell below where you are currently active.
<img alt="Code" src="../img/p50.png" /></p>
</li>
</ol>
<h3 id="set-environment-variables">Set Environment Variables</h3>
<p>Set the environment variables you will use throughout data preparation.  See <a href="../setup_watson_studio/">Setup Watson Studio</a> for how to find these values.</p>
<p><strong>Sample Code</strong></p>
<pre><code>ASSET_ID                 =  ID of each asset ie pump in your CSV files.
APM_ID                   =  Value for the mxe.PMIId system property.                                                         | Used to train and score all notebooks  | 
APM_API_BASEURL          =  Root of the URL value for the PREDICTAPI endpoint.                                               | Used to train and score all notebooks  |
EXTERNAL_APM_API_BASEURL =  Route location for the Predict project retrieved from the Red Hat® OpenShift® Container Platform. | Used to download the notebooks         |
APM_API_KEY              =  API Key to make secure programmatic calls to APM

import os 
os.environ['ASSET_ID'] = 'your_asset_id'
os.environ['APM_ID'] = 'your_APM_ID' 
os.environ['APM_API_BASEURL'] = 'your_https://main.fake.suite.maximo.com/maximo/'
os.environ['EXTERNAL_APM_API_BASEURL'] = 'your_https://main.fake.maximo.com/maximo/'
os.environ['APM_API_KEY'] = 'your_APM_API_KEY'
</code></pre>
<h3 id="verify-environment-variables">Verify Environment Variables</h3>
<p>You can check the environment variables and reference them by using the auto insert code in Watson Studio.  Click on the code generator icon at the top of Watson Studio.  Click on the sensor data csv file you loaded earlier and nameed 'kaggle-pump-sensor.csv'  </p>
<p><img alt="Insert Environment Variables" src="../img/p52.png" /></p>
<h2 id="prepare-asset-information-data">Prepare Asset Information Data</h2>
<p><a name="asset_information_file"></a></p>
<p>The Asset Information file is used for End Of Life Curve.   This step can be skipped if you don't want to create an End of Life Curve in Predict.</p>
<p>You must load metadata describing your asset and meter data describing the timeseries metrics and failure dates.  There are 3 files needed.  Each file is described below.</p>
<p>To load asset data into Health you must have asset date. an anomaly model or failure prediction model using Predict you must include For model training using Predict you must include this file.  If you are using Health and have an existing installation of Manage</p>
<p>Asset information data is time series data that should have the following column formats:</p>
<table>
<thead>
<tr>
<th>Column Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>asset_id</td>
<td>String that is the unique asset identifier like ST_1393137</td>
</tr>
<tr>
<td>installation_date</td>
<td>String for timestamp of reading Predict supports formats like date 1998-03-28 or date time 2008-01-08 00:00:00</td>
</tr>
<tr>
<td>decommission_date</td>
<td>String for timestamp of reading Predict supports formats like 2008-01-08 00:00:00</td>
</tr>
</tbody>
</table>
<p><strong>Example CSV File:</strong></p>
<pre><code>asset_id,installation_date,decommission_date
ST_1393137,1998-03-28,
ST_1393138,1999-03-28,
ST_1400501,2002-01-01,
ST_1400502,1978-01-01,
ST_1400503,1988-01-01,2017-01-01
ST_1400504,1972-02-01,2013-09-01
ST_1400505,1978-04-01,2018-09-01
ST_1400506,1985-12-01,2000-09-01
ST_1400507,1990-01-01,2020-09-01
ST_1400508,1982-12-01,2021-01-01
ST_1400517,2004-05-29,
ST_1400518,2001-01-26,
ST_1400519,2004-03-11,
</code></pre>
<h3 id="create-an-asset-information-file">Create an Asset Information File</h3>
<p>Create an asset information file for the pump data.  Since the Kaggle pump data is for a single pump you can create a file with a single asset.  Since the pump data doesn't have asset decommission dates you can leave them blank.</p>
<p>In this step you will create the CSV file and save it to your project assets in Watson Studio.   You will use a Watson Studio Python library named <code>ibm_watson_studio_lib</code> that is available in your environment by default.  See this <a href="https://www.ibm.com/docs/en/cloud-paks/cp-data/4.0?topic=lib-watson-studio-python">API reference</a> for more information. </p>
<p><strong>Sample Code:</strong></p>
<pre><code>ASSET_INFO_FILE = "pumps_asset_info.csv"
asset_info_list = [ ['pump_00',pd.Timestamp('2008-01-08'),""]]
df_asset_info = pd.DataFrame(asset_info_list, columns=['asset_id','installation_date','decommission_date'])
print(df_asset_info)

from ibm_watson_studio_lib import access_project_or_space
wslib = access_project_or_space()
wslib.save_data(ASSET_INFO_FILE, df_asset_info.to_csv(index=False).encode())
</code></pre>
<p><strong>Example CSV File that will be created:</strong></p>
<pre><code>asset_id,installation_date,decommission_date
pump_00,2008-01-08,
</code></pre>
<h2 id="prepare-asset-metrics-data">Prepare Asset Metrics Data</h2>
<p><a name="asset_metrics_file"></a></p>
<p>Asset metrics data is time series data that must have the following column formats:</p>
<table>
<thead>
<tr>
<th>Column Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>timestamp</td>
<td>String for timestamp of reading Predict supports like YYYY-MM-DD HH:MM:SS  2008-01-08 00:00:00</td>
</tr>
<tr>
<td>asset_id</td>
<td>String that is the unique asset identifier like ST_1393137</td>
</tr>
<tr>
<td>replace_with_your_metric_name</td>
<td>String, float, integer values for the metric name that has time series value of the metric. Add columns for each</td>
</tr>
<tr>
<td>deviceid</td>
<td>The device identifier for the  pump devices pump00 and pump01</td>
</tr>
<tr>
<td>devicetype</td>
<td>Type of device or asset type.  For example SubmersiblePump</td>
</tr>
</tbody>
</table>
<p><strong>Example CSV File:</strong></p>
<pre><code>timestamp, asset_id,VELOCITYX,VELOCITYY,VELOCITYZ,MOTORTEMP,WINDINGTEMP,CURRENT,PRESSURE,LOAD,deviceid,devicetype
2008-01-08 00:00:00,ST_1393137,2.789723591922755e-05,1.6746073164430882e-05,8.339162527937205e-05,100.83577170779785,44.35493000421977,248.35431420298488,236.06861760559738,119.19549771099527,ST_1393137,Pump
2008-01-08 00:00:00,ST_1400503,1.8955077909665885e-05,5.310167683286737e-05,4.929701336603421e-05,117.40003242411258,59.44633346537405,198.43270265068318,135.58041388401696,363.32438733010264,ST_1400503,Pump
2008-01-08 00:00:00,ST_1393138,5.383833971733809e-05,8.621918766532621e-05,0.00022628816228392745,56.84127240243945,85.39674348536191,320.10652050792254,116.96629884075016,348.63962293620796,ST_1393138,Pump
2008-01-08 00:00:00,ST_1400504,0.0001924944000548656,1.1741761162809006e-06,8.175834516599423e-05,119.5450558945755,94.7939330989897,236.70840492432868,32.6440692097963,312.4522186383818,ST_1400504,Pump
2008-01-08 00:00:00,ST_1400501,0.003545132038944409,6.876746074246931e-07,0.0036784498219412103,45.59886793076733,23.05892702945967,286.74721509016484,180.20107874577167,231.70223738465447,ST_1400501,Pump
2008-01-08 00:05:00,ST_1400504,0.00019302373395002626,0.00016932421485671423,0.00013430225226540582,190.6814045868194,37.57188465045573,137.3792392640947,299.6397304979968,159.14737257788806,ST_1400504,Pump
2008-01-08 00:05:00,ST_1400503,2.0484241964768835e-05,0.00010325648402054188,5.190215923800423e-05,54.63392121323369,36.27128188087939,300.653034213001,255.42177133667667,354.67651009829115,ST_1400503,Pump
2008-01-08 00:05:00,ST_1393137,6.366443036021074e-05,7.064831711578456e-05,0.00011524493308429085,54.97140429029558,38.663214620823275,227.54222031273997,156.7913987644162,130.128691037622,ST_1393137,Pump
2008-01-08 00:05:00,ST_1393138,0.00013067224960744417,0.0008823036374320248,0.00032697196744563284,93.54844644228176,1.0334067253278365,201.09726853381162,177.26721567826152,464.38594263559753,ST_1393138,Pump
2008-01-08 00:05:00,ST_1400501,0.006280909664161449,0.0010025129547774347,0.004949649433126646,120.43190732195221,56.22655349254132,103.56854139558924,149.58631977664385,327.4758640952711,ST_1400501,Pump
2008-01-08 00:10:00,ST_1400504,0.00020046116700583871,0.00023040699143567206,0.00019016599105797782,26.21601912040133,17.065778325053998,283.1600018147578,83.84456591349925,214.12986021619156,ST_1400504,Pump
2008-01-08 00:10:00,ST_1393137,7.602581095239591e-05,7.9852673251668e-05,0.00012796988361707395,34.50644451498961,71.16775071874916,187.36661322063892,213.0005900404975,78.99669369869281,ST_1393137,Pump
2008-01-08 00:10:00,ST_1400503,8.657794445832145e-05,0.00013001986273436517,7.091561697253335e-05,74.35723049281981,48.2234783756648,126.26599720968146,177.59628306468898,258.13878219243736,ST_1400503,Pump
2008-01-08 00:10:00,ST_1400501,0.010575435663603527,0.0014778309163699932,0.005209847134218125,98.86547795829622,36.977105925193136,178.05030077180396,79.52583077900974,243.4138352490094,ST_1400501,Pump
</code></pre>
<h3 id="create-an-asset-metrics-file">Create an Asset Metrics File</h3>
<p><a name="asset_metrics_file"></a></p>
<p>Since the Kaggle pump data is for a single pump you can create a file with a single asset.  Since the pump data doesn't have decommission dates you can leave them blank.
Also since not all the columns are needed to make a failure prediction we can reduce the columns down to the minimum number.   Reduce the 'data_df_1' that you read in earlier and add the required columns for <code>ASSET_ID</code>,<code>deviceid</code>, <code>devicetype</code>.</p>
<p>Select only the columns that are needed for pump predicting failure.</p>
<p><strong>Sample Code:</strong></p>
<pre><code>pump_df = data_df_1[['timestamp','sensor_10', 'sensor_04','sensor_02', 'sensor_12','sensor_05', 'sensor_00','sensor_11', 'sensor_13','sensor_06', 'sensor_01','sensor_09', 'sensor_26']]
</code></pre>
<p>Assign constant values for the columns that are needed for pump predicting failure for <code>asset_id</code>, <code>deviceid</code> and <code>devicetype</code> </p>
<p><strong>Sample Code:</strong></p>
<pre><code>print(os.getenv('ASSET_ID'))
# Add a column for deviceType DeviceID and Asset_ID
pump_df['asset_id'] = os.getenv('ASSET_ID')
pump_df['deviceid'] = os.getenv('ASSET_ID')
pump_df['devicetype'] = os.getenv('DEVICE_TYPE') 
pump_df.head()
</code></pre>
<h2 id="prepare-asset-failure-data">Prepare Asset Failure Data</h2>
<p><a name="asset_failure_file"></a></p>
<p>Asset failure data is time series data that describes when the asset failure periods happen.   Asset failure data must have the  column formats in the table below.</p>
<p>The failure dates includes the failure CSV data which identifies the start and end of failure dates for each asset id with the following columns:</p>
<table>
<thead>
<tr>
<th>Column Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>fail_date</td>
<td>String for timestamp of day 2008-01-08  and  day-time 2008-01-08 00:10:00 that the asset failed.</td>
</tr>
<tr>
<td>asset_id</td>
<td>String that is the unique asset identifier like ST_1393137</td>
</tr>
<tr>
<td>description</td>
<td>String,describes the failure cause or condition.</td>
</tr>
<tr>
<td>failure_code</td>
<td>String that identifies the fault.</td>
</tr>
<tr>
<td>problem_code</td>
<td>String that desribes the problem code for troubleshooting.</td>
</tr>
<tr>
<td>site_id</td>
<td>String of where the asset is located</td>
</tr>
<tr>
<td>failure_record</td>
<td>Integer that identifies the Manage record identifier failure instance of failure types.</td>
</tr>
</tbody>
</table>
<p><strong>Example CSV File:</strong></p>
<pre><code>fail_date,asset_id,description,failure_code,problem_code,site_id,failure_record
2008-01-08,ST_1393137,Pump stopped due to failure,PUMPS,STOPPED,DIST1,1
2008-02-10,ST_1393137,Pump stopped due to failure,PUMPS,STOPPED,DIST1,1
2008-03-11,ST_1393137,Pump stopped due to failure,PUMPS,STOPPED,DIST1,1
2008-04-09,ST_1393137,Pump stopped due to failure,PUMPS,STOPPED,DIST1,1
2008-05-06,ST_1393137,Pump stopped due to failure,PUMPS,STOPPED,DIST1,1
2008-05-18,ST_1393137,Pump stopped due to failure,PUMPS,STOPPED,DIST1,1
2008-06-04,ST_1393137,Pump stopped due to failure,PUMPS,STOPPED,DIST1,1
2008-06-30,ST_1393137,Pump stopped due to failure,PUMPS,STOPPED,DIST1,1
2008-01-24,ST_1393138,Pump stopped due to failure,PUMPS,STOPPED,DIST1,1
</code></pre>
<h3 id="create-an-asset-failure-file">Create an Asset Failure File</h3>
<p>Create an asset failure file for the pump data.  Since the Kaggle pump data is for a single pump you can create a file with a single asset.  Since the pump data doesn't have asset decommission dates you can leave them blank.</p>
<p>In this step you will create the CSV file and save it to your project assets in Watson Studio.   You will use a Watson Studio Python library named <code>ibm_watson_studio_lib</code> that is available in your environment by default.  See this <a href="https://www.ibm.com/docs/en/cloud-paks/cp-data/4.0?topic=lib-watson-studio-python">API reference</a> for more information. </p>
<p>Review the code cells to understand how to drop columns and add columns to using Pandas to create the right format for the Asset Failure CSV file.</p>
<p>Congratulations.  You now have the pump data files in the files and format required for evaluating algorithm and prediction performance in the next exercises.</p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../hpu_models/" class="btn btn-neutral float-left" title="Understand Health and Predict - Utilities Models"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../asset_data_loader/" class="btn btn-neutral float-right" title="Load Utilities Data Into Manage">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../hpu_models/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../asset_data_loader/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
