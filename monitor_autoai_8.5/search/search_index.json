{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the IBM Maximo Monitor Auto AI Lab (Version: 8.5) You will learn about Monitor's capabilities to use AutoAI to identify and deploy a prediction machine learning model to Maximo Application Suite In this lab we will show you how to use AutoAI to identify, train and then deploy to a prediction machine learning model to Maximo Asset Monitor. You will learn how to: Use the provided Jupyter notebook that will contain Python code to train, test and deploy machine learning model to Maximo Asset Monitor Use the provided Maximo Asset Monitor custom function to make predictions as new time series data is received in Maximo Asset Monitor Create Asset Types and devices using simulated pump data. Create an Asset Type and Asset dashboards to see the pump data and model predictions in Monitor Prerequisites This Hands on Lab requires: Your instructor can provide you the data, example Python Scripts, functions and Notebooks. An account for IBM ID and An IBM Cloud Account Trial here Access to a Maximo Asset Monitor environment. Request access from your instructor. Understand Virtual Environments Setup a local development environment. Check if you instructor has already provided you access to one. Introduction to using Jupyter Notebooks Understanding of Pandas for Time series data processing: https://medium.com/analytics-vidhya/module-6-pandas-5b053ee1e1a1 Basic Time Series Manipulation with Pandas Time series / date functionality Internet access to these tutorial directions Steps Follow the Getting Started instructions on the next page. Learn more This tutorial is part of the Maximo Hands On Labs for Data scientists and Developers. Maximo Application Suite : Enjoyed this Tutorial? Check out our other Maximo Code Patterns . Knowledge Center Maximo Application Suite Documentation License This Hands on Lab is licensed under the Apache Software License, Version 2. Separate third party code objects invoked within this lab are licensed by their respective providers pursuant to their own separate licenses. Contributions are subject to the Apache Software License, Version 2 .","title":"Welcome to the Maximo Auto AI Hands on Lab"},{"location":"#welcome-to-the-ibm-maximo-monitor-auto-ai-labversion-85","text":"You will learn about Monitor's capabilities to use AutoAI to identify and deploy a prediction machine learning model to Maximo Application Suite In this lab we will show you how to use AutoAI to identify, train and then deploy to a prediction machine learning model to Maximo Asset Monitor. You will learn how to: Use the provided Jupyter notebook that will contain Python code to train, test and deploy machine learning model to Maximo Asset Monitor Use the provided Maximo Asset Monitor custom function to make predictions as new time series data is received in Maximo Asset Monitor Create Asset Types and devices using simulated pump data. Create an Asset Type and Asset dashboards to see the pump data and model predictions in Monitor","title":"Welcome to the IBM Maximo Monitor Auto AI Lab(Version: 8.5)"},{"location":"#prerequisites","text":"This Hands on Lab requires: Your instructor can provide you the data, example Python Scripts, functions and Notebooks. An account for IBM ID and An IBM Cloud Account Trial here Access to a Maximo Asset Monitor environment. Request access from your instructor. Understand Virtual Environments Setup a local development environment. Check if you instructor has already provided you access to one. Introduction to using Jupyter Notebooks Understanding of Pandas for Time series data processing: https://medium.com/analytics-vidhya/module-6-pandas-5b053ee1e1a1 Basic Time Series Manipulation with Pandas Time series / date functionality Internet access to these tutorial directions","title":"Prerequisites"},{"location":"#steps","text":"Follow the Getting Started instructions on the next page.","title":"Steps"},{"location":"#learn-more","text":"This tutorial is part of the Maximo Hands On Labs for Data scientists and Developers. Maximo Application Suite : Enjoyed this Tutorial? Check out our other Maximo Code Patterns . Knowledge Center Maximo Application Suite Documentation","title":"Learn more"},{"location":"#license","text":"This Hands on Lab is licensed under the Apache Software License, Version 2. Separate third party code objects invoked within this lab are licensed by their respective providers pursuant to their own separate licenses. Contributions are subject to the Apache Software License, Version 2 .","title":"License"},{"location":"create_dashboards/","text":"Create and View Dashboards In these exercises you create the dashboards in Monitor. - Create an Asset dashboard provides individual asset performance for the pump selected. - View an Asset dashboard - Create an Asset Type dashboard that summarizes performance across multiple assets of type pump_co Create Asset Dashboard in Monitor In Monitor, click Setup tile Enter pump_co in the search field and then click pump_co Click on the link for 111137F8 Click Dashboards tab Click : icon and select edit to edit the dashboard Click import icon Browse to the dashboards folder and select the asset-instance-dashbard.json file Click Save and close button View Asset Dashboard in Monitor Click Monitor menu Search for pump_co in the search field Click 111137F8 asset Click Asset Metrics Dashboard tab View dashboard Congratulations you imported and viewed an Asset Dashboard. Create Summary Asset Type Dashboard in Monitor In Monitor, click Setup menu Enter pump_co in the search field and then click pump_co in results. Then click Manage Asset Types link Click Dashboards tab Make note of the Daily Time grain selected. This means that the dashboard will aggregate calculations for the 24 hours. So the maximum, minimum, mean and last values will be calculated for the last 24 hours. Dimensions selected are used to further filter the displacyed calculated metrics just for those assets. Select the serialNumber dimension. This will allow you to choose just one asset of that type in the dashboard. Click Add Dashboard button Make note of the Daily Time grain selected. This means that the dashboard will aggregate calculations for the 24 hours. So the maximum, minimum, mean and last values will be calculated for the last 24 hours. Dimensions selected are used to further filter the displacyed calculated metrics just for those assets. Select the serialNumber dimension. This will allow you to choose just one asset of that type in the dashboard. Click Next button Select pump_mode and last from the Methods drop down field to calculate the last value in the last 24 hour day. Then click on Configure Dashboard button Browse to the dashboards folder and select the asset-instance-dashbard.json file Click Create button Monitor is processing the metric calculations for the selected aggregation period. Note the Preparing Dashboards message Return back to this screen to see the dashboard once the calculations have completed processing. Congratulations you imported and created an Asset Type Dashboard that calculated aggregated values for a selected time period Monitor provide hourly, daily, monthly and yearly aggregation periods you can use on the dashboard.","title":"6. Create Dashboards"},{"location":"create_dashboards/#create-and-view-dashboards","text":"In these exercises you create the dashboards in Monitor. - Create an Asset dashboard provides individual asset performance for the pump selected. - View an Asset dashboard - Create an Asset Type dashboard that summarizes performance across multiple assets of type pump_co","title":"Create and View Dashboards"},{"location":"create_dashboards/#create-asset-dashboard-in-monitor","text":"In Monitor, click Setup tile Enter pump_co in the search field and then click pump_co Click on the link for 111137F8 Click Dashboards tab Click : icon and select edit to edit the dashboard Click import icon Browse to the dashboards folder and select the asset-instance-dashbard.json file Click Save and close button","title":"Create Asset Dashboard in Monitor"},{"location":"create_dashboards/#view-asset-dashboard-in-monitor","text":"Click Monitor menu Search for pump_co in the search field Click 111137F8 asset Click Asset Metrics Dashboard tab View dashboard Congratulations you imported and viewed an Asset Dashboard.","title":"View Asset Dashboard in Monitor"},{"location":"create_dashboards/#create-summary-asset-type-dashboard-in-monitor","text":"In Monitor, click Setup menu Enter pump_co in the search field and then click pump_co in results. Then click Manage Asset Types link Click Dashboards tab Make note of the Daily Time grain selected. This means that the dashboard will aggregate calculations for the 24 hours. So the maximum, minimum, mean and last values will be calculated for the last 24 hours. Dimensions selected are used to further filter the displacyed calculated metrics just for those assets. Select the serialNumber dimension. This will allow you to choose just one asset of that type in the dashboard. Click Add Dashboard button Make note of the Daily Time grain selected. This means that the dashboard will aggregate calculations for the 24 hours. So the maximum, minimum, mean and last values will be calculated for the last 24 hours. Dimensions selected are used to further filter the displacyed calculated metrics just for those assets. Select the serialNumber dimension. This will allow you to choose just one asset of that type in the dashboard. Click Next button Select pump_mode and last from the Methods drop down field to calculate the last value in the last 24 hour day. Then click on Configure Dashboard button Browse to the dashboards folder and select the asset-instance-dashbard.json file Click Create button Monitor is processing the metric calculations for the selected aggregation period. Note the Preparing Dashboards message Return back to this screen to see the dashboard once the calculations have completed processing. Congratulations you imported and created an Asset Type Dashboard that calculated aggregated values for a selected time period Monitor provide hourly, daily, monthly and yearly aggregation periods you can use on the dashboard.","title":"Create Summary Asset Type Dashboard in Monitor"},{"location":"create_device_types/","text":"Setup Device Types In this exercise you will create the pump Device Type and data in Monitor IOT Platform that will receive the simulated pump data in the lab. Create a Pump Device Type in Monitor. You can create Device Type in the UI or Programmatically. Create Pump Device Types in UI To be able to ingest device data using Monitor you must first define the format of the data using a Device Type. In this exercise you will, create a Device Type named pump_co and 2 Devices named 11111096 and 111137F8 . Login to Monitor from the Maximo Application Suite Navigator page. Click Click Connect devices tile or click On the Connect menu Click Open Platform Service application in the top-right corner to open the Watson IoT Platform tenant associated with this Monitor tenant in a separate browser tab. Go to the Device Types menu, and click Add Device Type . Note Make sure to replace co in the device type name with your own initials. Enter pump_co in the Name and Description fields - where co should be replaced with your initials. Note that for the rest of this lab, Click Next . Enter pump_co in the Manufacturer and Device Class fields. Later you can Dimensions that can be used in Monitor to filter and aggregate assets in Summary Dashboards . Click Finish to save your changes.","title":"2. Create Device Types"},{"location":"create_device_types/#setup-device-types","text":"In this exercise you will create the pump Device Type and data in Monitor IOT Platform that will receive the simulated pump data in the lab. Create a Pump Device Type in Monitor. You can create Device Type in the UI or Programmatically.","title":"Setup Device Types"},{"location":"create_device_types/#create-pump-device-types-in-ui","text":"To be able to ingest device data using Monitor you must first define the format of the data using a Device Type. In this exercise you will, create a Device Type named pump_co and 2 Devices named 11111096 and 111137F8 . Login to Monitor from the Maximo Application Suite Navigator page. Click Click Connect devices tile or click On the Connect menu Click Open Platform Service application in the top-right corner to open the Watson IoT Platform tenant associated with this Monitor tenant in a separate browser tab. Go to the Device Types menu, and click Add Device Type . Note Make sure to replace co in the device type name with your own initials. Enter pump_co in the Name and Description fields - where co should be replaced with your initials. Note that for the rest of this lab, Click Next . Enter pump_co in the Manufacturer and Device Class fields. Later you can Dimensions that can be used in Monitor to filter and aggregate assets in Summary Dashboards . Click Finish to save your changes.","title":"Create Pump Device Types in UI"},{"location":"create_devices/","text":"Create Devices In this exercise you will crete the devices that will store the simulated pump data being sent to Monitor. Create two pump Devices named 11111096 and 111137F8 for the Device Type named pump_co . Note Remember to replace co in the device type name with your own initials. Create Devices Stay in the Monitor Watson IoT Platform service, go to the Devices menu Click Add Device . On the Add Device page, select your just-created pump_co as Device Type and enter 11111096 in Device ID . After adding that device you will repeat the following steps for a second device with ID 111137F8 Replace co with your initials for the device type you created. Click Next . On the Device Information page, leave the Serial Number value blank and enter the Device ID 11111096 and other information you want, click Next. Depending on the version of IOTP the Groups tab may be present, accept the defaults, click Next . On the Security page, accept the defaults, click Next . On the Summary page, accept the defaults, click Finish . Save the device summary token information. You will need it later when you connect your simulator to send data. ``` Organization ID your org id Device Type pump_co Device ID 111137F8 Authentication Method use-token-auth Authentication Token your token Organization ID your org id Device Type pump_co Device ID 11111096 Authentication Method use-token-auth Authentication Token your token `` 9. Click Back and repeat above steps 1. to 6. for 1 more Pump with Device ID = 111137F8`. On Devices , Click Browse tab menu. Click the funnel icon. Enter pump_co in the Search field for Device Type , and you will now see your 2 pump Devices for pump_co . You have now created the required pump_co Device Type and the 2 pump devices 11111096 and 111137F8 we will use in this lab.","title":"3. Create Devices"},{"location":"create_devices/#create-devices","text":"In this exercise you will crete the devices that will store the simulated pump data being sent to Monitor. Create two pump Devices named 11111096 and 111137F8 for the Device Type named pump_co . Note Remember to replace co in the device type name with your own initials.","title":"Create Devices"},{"location":"create_devices/#create-devices_1","text":"Stay in the Monitor Watson IoT Platform service, go to the Devices menu Click Add Device . On the Add Device page, select your just-created pump_co as Device Type and enter 11111096 in Device ID . After adding that device you will repeat the following steps for a second device with ID 111137F8 Replace co with your initials for the device type you created. Click Next . On the Device Information page, leave the Serial Number value blank and enter the Device ID 11111096 and other information you want, click Next. Depending on the version of IOTP the Groups tab may be present, accept the defaults, click Next . On the Security page, accept the defaults, click Next . On the Summary page, accept the defaults, click Finish . Save the device summary token information. You will need it later when you connect your simulator to send data. ``` Organization ID your org id Device Type pump_co Device ID 111137F8 Authentication Method use-token-auth Authentication Token your token Organization ID your org id Device Type pump_co Device ID 11111096 Authentication Method use-token-auth Authentication Token your token `` 9. Click Back and repeat above steps 1. to 6. for 1 more Pump with Device ID = 111137F8`. On Devices , Click Browse tab menu. Click the funnel icon. Enter pump_co in the Search field for Device Type , and you will now see your 2 pump Devices for pump_co . You have now created the required pump_co Device Type and the 2 pump devices 11111096 and 111137F8 we will use in this lab.","title":"Create Devices"},{"location":"create_interfaces/","text":"Create Physical & Logical Interfaces IoT device data must be mapped from physical devices that are reading the metrics on assets to a logical interfaces that represent that whole asset or system you will monitor. Physical Interfaces are what are used to save the device data into the Monitor. Logical Interfaces are what Monitor uses to create asset types and assets with their corresponding metric values. In this exercise you will use Monitor to create: Create the Physical Interface Create the Logical Interface Create the Physical Interface Note Alternate option for step 5 is to click Use Last Event Cache enter the name of the device ID 111137F8 . Which ever you have in your data. pump_co event will appear if you already have the simulator running. This corresponds to the Python device simulator script you will run in the next exercise. See image for Event cache Still in the Watson IoT Platform, go to the Device Types tab menu, search then select pump_co , Click on the Interface tab menu and click Create Physical Interface button. Enter the name pump_co_pi , Click Next . Click Create event type button If your pump simulator is sending data you can wait for the dialog to fill in with your event data. Otherwise you can set the payload by click on Create event type button. Add Device Event Type to the Physical Interface by uploading a json file that contains a payload similar to the one below. Replace co with your initials for your eventID. { \"EventName\": \"event\", \"EventDescription\": \"Device event\", \"EventID\": \"pump_co\", \"Payload\": { \"evt_timestamp\": \"2020-01-19T03:59:53.03Z\", \"speed\": 1124, \"head\": 54.424, \"pump_mode\": \"a\", \"flow\": 115.934, \"voltage\": 274, \"POWER\": 2.664, \"CURRENT\": 8.69 } } In the dialog click on Import link and drag the event_template.json file into the dialog. Click the Add button Click the Add Property button. You must change the type from string to timestamp for the evet_timestamp . Click Select button. click the 3 dots on the evet_timestamp row. Click edit pencil icon Click select box for Event named. Click the check box next to evt_timestamp and change the Event , Data Type to String(Date Time) Click Done . Click Done . Again. You now are able to save the device data that is sent from any device to this Device Type physical interface named pump_co_pi . Stay on the current page and continue to the next exercise below. Create the Logical Interface Logical interfaces allow you to map the metrics from the physical device types into a single Entity Type for Monitor. Click Create Logical Interface button. Change the default name pump_co_li , click Next . Tick the Allow Additional Properties to ON and then Click Add Property button. Click the Select button for the evt_timestamp . In the dialog Type field, select String (date-time) and click Save button. Click Add Property again for all the remaining metrics leaving the values as is shown below. ) ) Click Next , click link No event notifications change to All events and click the x to close the dialog box. Click Apply , then Done . Click Activate twice. Click Done . You now are able to create dashboards and calculated metrics using the device data that is sent by any device into Monitor. You must wait upto 10 minutes to start seeing your devices show up in Monitor.","title":"5. Create Interfaces"},{"location":"create_interfaces/#create-physical-logical-interfaces","text":"IoT device data must be mapped from physical devices that are reading the metrics on assets to a logical interfaces that represent that whole asset or system you will monitor. Physical Interfaces are what are used to save the device data into the Monitor. Logical Interfaces are what Monitor uses to create asset types and assets with their corresponding metric values. In this exercise you will use Monitor to create: Create the Physical Interface Create the Logical Interface","title":"Create Physical &amp; Logical Interfaces"},{"location":"create_interfaces/#create-the-physical-interface","text":"Note Alternate option for step 5 is to click Use Last Event Cache enter the name of the device ID 111137F8 . Which ever you have in your data. pump_co event will appear if you already have the simulator running. This corresponds to the Python device simulator script you will run in the next exercise. See image for Event cache Still in the Watson IoT Platform, go to the Device Types tab menu, search then select pump_co , Click on the Interface tab menu and click Create Physical Interface button. Enter the name pump_co_pi , Click Next . Click Create event type button If your pump simulator is sending data you can wait for the dialog to fill in with your event data. Otherwise you can set the payload by click on Create event type button. Add Device Event Type to the Physical Interface by uploading a json file that contains a payload similar to the one below. Replace co with your initials for your eventID. { \"EventName\": \"event\", \"EventDescription\": \"Device event\", \"EventID\": \"pump_co\", \"Payload\": { \"evt_timestamp\": \"2020-01-19T03:59:53.03Z\", \"speed\": 1124, \"head\": 54.424, \"pump_mode\": \"a\", \"flow\": 115.934, \"voltage\": 274, \"POWER\": 2.664, \"CURRENT\": 8.69 } } In the dialog click on Import link and drag the event_template.json file into the dialog. Click the Add button Click the Add Property button. You must change the type from string to timestamp for the evet_timestamp . Click Select button. click the 3 dots on the evet_timestamp row. Click edit pencil icon Click select box for Event named. Click the check box next to evt_timestamp and change the Event , Data Type to String(Date Time) Click Done . Click Done . Again. You now are able to save the device data that is sent from any device to this Device Type physical interface named pump_co_pi . Stay on the current page and continue to the next exercise below.","title":"Create the Physical Interface"},{"location":"create_interfaces/#create-the-logical-interface","text":"Logical interfaces allow you to map the metrics from the physical device types into a single Entity Type for Monitor. Click Create Logical Interface button. Change the default name pump_co_li , click Next . Tick the Allow Additional Properties to ON and then Click Add Property button. Click the Select button for the evt_timestamp . In the dialog Type field, select String (date-time) and click Save button. Click Add Property again for all the remaining metrics leaving the values as is shown below. ) ) Click Next , click link No event notifications change to All events and click the x to close the dialog box. Click Apply , then Done . Click Activate twice. Click Done . You now are able to create dashboards and calculated metrics using the device data that is sent by any device into Monitor. You must wait upto 10 minutes to start seeing your devices show up in Monitor.","title":"Create the Logical Interface"},{"location":"create_model/","text":"Create Prediction Models Prediction models are useful for understanding when an asset is performing differently than expected. By measuring the deviation between the actual asset metric value versus the predicted metric value you can be alerted to a anomaly with your asset. Monitor includes out of the box anomaly models . Monitor includes alerts that are triggered when a conditional expression for a metric deviation exceeds a threshold value specified for the asset. In some cases you might want to make a customized model that can provide asset specific metric predictions and alerts. Creating models can be a manual and difficult process. It starts with finding candidate algorithms that best fit the specific case. Do we know all the appropriate algorithms? Then, we must prepare the data by converting any non-numeric fields to numerical values. Do we need to do additional feature engineering? How do we tune all the hyper-parameters for each of the chosen algorithms? AutoAI takes care of all those steps for us and gives us a set of ranked models to choose from. With all the details provided, choosing the best model becomes easy and we can go on with implementing our business solution. More than one algorithms can fit the business problem. Model creation might require more feature engineering. Model creation requires hyper-parameters tuning AutoAI removes the complexity of model creation. It allows you to run an experiment to determine what is the best model for your classification or linear regression problem. In this exercise you will: Confirm you have already created and IBM ID here Create a Watson Studio Service in IBM Cloud. Create a Watson Studio Project in IBM Cloud Watson Studio Service. Add Data Assets for the pumps. Associate a Watson Machine Learning Service to your Watson Studio Service Project. Perform an Auto AI Experiment to Identify a prediction model using Watson Studio using the provided pump training data. Assess each models performance and Choose a Prediction Model Create a Watson Studio Service Create a Watson Studio Service for your data scientist needs. Open a browser and login to Watson Studio. Watson Studio Cloud runs as IBM Cloud Pak\u00ae for Data as a Service which is included with Maximo Application Suite. the title as \"IBM Watson Studio\" or \"IBM Cloud Pak for Data\". The user interface is the same no matter what name it comes under. After logging into IBM Cloud , click create resource button Search on Watson Studio and then click on Watson Studio tile Make note of the geographic region in the drop down box. Select the Standard v1 plan otherwise choose the lite plan. Click the Create button Open Watson Studio by clicking on the Get Started button to launch Watson Studio . Congratulations you are now in Watson Studio and can start working on your datascience projects. Create a Project Create a Watson Studio Project to hold your data and models and run Auto AI Experiments. A project us where you can place your \u201cassets\u201d like training data and run Auto AI experiments. In the left menu, click Create a project link Click empty project . tile option. Enter the project name: student01 or a name you can remember later. Optionally, enter the description \"Monitor AutoAI Hands On Lab Pump Models\". Click Create button. Congratulations you have created a Watson Studio Project to organize your Model Data and artifacts. Add Data Assets In this exercise you will use pump data to run an AutoAI Experiment. The pump data provided by the instructor in the file named PumpData.csv is a comma separated version file that has two pump device data metric readings: Metric Name Metric Description evt_timestamp Reading timestamp metric data was read by sensor speed Pump impeller speed head Pump head device_id The device identifier for the 2 pump devices 11111096 and 111137F8 pump_mode Pump mode a for automatic or h for manually operated by hand flow Pump flow voltage Pump voltage POWER Pump power consumption CURRENT Pump current The value we want to predict is POWER . An anomaly could occur then a pump is blocked or bearings have failed which would make the POWER be greater even while still having the low values for the other metrics like flow . In the next exercises you will see how AutoAI will help us understand which of these metrics have the greatest impact on predicting POWER . In Watson Studio, in your project created in the last exercise, click Add to Project button. Click the Data option. The data window on the right side of your project is ready to load data. Drop the file provided by the instructor in the github repo named maximo-auto_ai_pump_data_111137F8.csv in to the load window or use the browse option to locate the file on your machine. Upload a second asset data file named maximo-auto_ai_pump_data_11111096.csv for the second pump 11111096 . Click the Assets Tab You should now see your Data assets for the two pumps. Congratulations you have imported pump data for the two pumps into a Watson Studio Project. You are ready to start creating models by running an Auto AI Experiment. Associate a Watson Machine Learning Service Before we can use AutoAI, we need to have a Watson Machine Learning service in our project. Add a Watson Machine Learning service to the project. There are multiple plans available. For this lab, we use the lite plan that provides the capabilities we need for free. You will likely only be able to run one AutoAI experiment with the Lite plan so carefully follow the instructions. Select the Settings tab. Scroll down to the Associated services section. If there is no machine learning service, click Add services , Select Watson from the drop down Associate service click New service button. Search on Machine learning and click on Machine Learning tile option Scroll down and select the Standard plan v2 or if not available select Lite plan then click Create Button Select your new machine learning service by clicking in the check box and then clicking x to close the dialog window. Close the dialog window. You have associated a machine learning service with Watson Studio. Congratulations you can now run Auto AI experiments using Watson Studio Project. You are ready to start creating models. Perform an Auto AI Experiment AutoAI can help you choose the right classification or regression algorithm use. You choose the type of algorithm to analyze, provide Auto AI your data and what you want to predict. It then runs a pipeline to identify what are the relevant dependent features(metrics) to make a prediction. It summarizes the performance and accuracy of each algorithm it considered in a ranked ordered list. The steps below show you how to perform an Auto AI Experiment to identify a regression model to predict power consumption. A regression model provides scoring or prediction for continuous values. You can learn more about how pumps work in this Video Make sure you are in the right IBM Cloud account in the top right of the screen, otherwise AutoAI might not show up as an option. Click Add to Project and click AutoAI experiment . Note Make sure to replace co in the device type name with your own initials. Enter project name 111137F8-power-co . click Create button. Replace co with your own initials since in the next exercise you will be training and deploying your model to a shared service and want to make the name is unique. Make sure your Watson Machine Learning service is selected. Click Add a datasource and select from project button. Select the input data. Click Select from project. Click maximo-auto_ai_pump_data_111137F8.csv . Click Select asset . AutoAI detects that it is a decimal value that contains continuous time series values and selects a Regression model. Select no to create a time series forecast. Select the column to predict POWER . Click the Run experiment button. The execution goes through multiple steps and generates multiple pipeline runs of with Extra Trees Regessor , LGBM and other models. This process can take 3 - 10 minutes. Congratulations you now know how to run AutoAI Experiments. In the next exercise you will assess the experiment results and choose a model to use for predicting power for each pump. Choose a Prediction Model Watson Studio can identify what are the correlated metrics that have the greatest impact in predicting a metric. It also provides overall accuracy of the model performance. Finally it gives you a ranked ordered list of the models that are best fits for making a prediction. Review the pipeline leader board for which algorithms performed best. Click on the Extra Trees Regressor algorithm. there maybe more than one. Select the one that doesn't have feature engineering. The Auto AI experiment Model Evatluation Measures provides mean absolute error, root mean squared error and other measures. These were used to determine what was the most effective algorithm. 4 Click Model Information shows what the target prediction metric was POWER . It also shows how many features were considered to be important to predicting pump power consumption. 5 Click Feature Importance to see which features are most important to predicting pump power consumption. Note them down these will become the input arguments to our prediction model. Also note how only 4 of the 8 total features were found to impact the power prediction. Click `Save As button Notice how Auto AI give you two options for saving your algorithm. You can save as a Model that gets deployed and you can begin scoring in your Watson Machine Learning service. There is a separate code pattern that shows how you can call Watson Machine learning using a custom function. See this code pattern . You can also save the algorithm as Notebook. Hit the Cancel button. You will use the provided Juypter Notebook to test, train and deploy your own Extra Trees Regressor algorithm to Monitor in the next lab. When you're done, click Back and click New Auto AI experiment . Repeat the previous steps with the other pump data maximo-auto_ai_pump_data_11111096.csv you previously added to your Watson Studio project. Congratulations you know have identified the the best model for each pump . You also have identified that speed, head, voltage, flow, and current are the input arguement needed for your model to be able to predict power. The next lab exercise provides you a Jupter Notebook named maximo_auto_ai-extra-trees-pump.ipynb that will allow you to train, test and deploy the an Extra Trees Regressor algorigthm prediction model into to Monitor.","title":"7. Identify Model"},{"location":"create_model/#create-prediction-models","text":"Prediction models are useful for understanding when an asset is performing differently than expected. By measuring the deviation between the actual asset metric value versus the predicted metric value you can be alerted to a anomaly with your asset. Monitor includes out of the box anomaly models . Monitor includes alerts that are triggered when a conditional expression for a metric deviation exceeds a threshold value specified for the asset. In some cases you might want to make a customized model that can provide asset specific metric predictions and alerts. Creating models can be a manual and difficult process. It starts with finding candidate algorithms that best fit the specific case. Do we know all the appropriate algorithms? Then, we must prepare the data by converting any non-numeric fields to numerical values. Do we need to do additional feature engineering? How do we tune all the hyper-parameters for each of the chosen algorithms? AutoAI takes care of all those steps for us and gives us a set of ranked models to choose from. With all the details provided, choosing the best model becomes easy and we can go on with implementing our business solution. More than one algorithms can fit the business problem. Model creation might require more feature engineering. Model creation requires hyper-parameters tuning AutoAI removes the complexity of model creation. It allows you to run an experiment to determine what is the best model for your classification or linear regression problem. In this exercise you will: Confirm you have already created and IBM ID here Create a Watson Studio Service in IBM Cloud. Create a Watson Studio Project in IBM Cloud Watson Studio Service. Add Data Assets for the pumps. Associate a Watson Machine Learning Service to your Watson Studio Service Project. Perform an Auto AI Experiment to Identify a prediction model using Watson Studio using the provided pump training data. Assess each models performance and Choose a Prediction Model","title":"Create Prediction Models"},{"location":"create_model/#create-a-watson-studio-service","text":"Create a Watson Studio Service for your data scientist needs. Open a browser and login to Watson Studio. Watson Studio Cloud runs as IBM Cloud Pak\u00ae for Data as a Service which is included with Maximo Application Suite. the title as \"IBM Watson Studio\" or \"IBM Cloud Pak for Data\". The user interface is the same no matter what name it comes under. After logging into IBM Cloud , click create resource button Search on Watson Studio and then click on Watson Studio tile Make note of the geographic region in the drop down box. Select the Standard v1 plan otherwise choose the lite plan. Click the Create button Open Watson Studio by clicking on the Get Started button to launch Watson Studio . Congratulations you are now in Watson Studio and can start working on your datascience projects.","title":"Create a Watson Studio Service"},{"location":"create_model/#create-a-project","text":"Create a Watson Studio Project to hold your data and models and run Auto AI Experiments. A project us where you can place your \u201cassets\u201d like training data and run Auto AI experiments. In the left menu, click Create a project link Click empty project . tile option. Enter the project name: student01 or a name you can remember later. Optionally, enter the description \"Monitor AutoAI Hands On Lab Pump Models\". Click Create button. Congratulations you have created a Watson Studio Project to organize your Model Data and artifacts.","title":"Create a Project"},{"location":"create_model/#add-data-assets","text":"In this exercise you will use pump data to run an AutoAI Experiment. The pump data provided by the instructor in the file named PumpData.csv is a comma separated version file that has two pump device data metric readings: Metric Name Metric Description evt_timestamp Reading timestamp metric data was read by sensor speed Pump impeller speed head Pump head device_id The device identifier for the 2 pump devices 11111096 and 111137F8 pump_mode Pump mode a for automatic or h for manually operated by hand flow Pump flow voltage Pump voltage POWER Pump power consumption CURRENT Pump current The value we want to predict is POWER . An anomaly could occur then a pump is blocked or bearings have failed which would make the POWER be greater even while still having the low values for the other metrics like flow . In the next exercises you will see how AutoAI will help us understand which of these metrics have the greatest impact on predicting POWER . In Watson Studio, in your project created in the last exercise, click Add to Project button. Click the Data option. The data window on the right side of your project is ready to load data. Drop the file provided by the instructor in the github repo named maximo-auto_ai_pump_data_111137F8.csv in to the load window or use the browse option to locate the file on your machine. Upload a second asset data file named maximo-auto_ai_pump_data_11111096.csv for the second pump 11111096 . Click the Assets Tab You should now see your Data assets for the two pumps. Congratulations you have imported pump data for the two pumps into a Watson Studio Project. You are ready to start creating models by running an Auto AI Experiment.","title":"Add Data Assets"},{"location":"create_model/#associate-a-watson-machine-learning-service","text":"Before we can use AutoAI, we need to have a Watson Machine Learning service in our project. Add a Watson Machine Learning service to the project. There are multiple plans available. For this lab, we use the lite plan that provides the capabilities we need for free. You will likely only be able to run one AutoAI experiment with the Lite plan so carefully follow the instructions. Select the Settings tab. Scroll down to the Associated services section. If there is no machine learning service, click Add services , Select Watson from the drop down Associate service click New service button. Search on Machine learning and click on Machine Learning tile option Scroll down and select the Standard plan v2 or if not available select Lite plan then click Create Button Select your new machine learning service by clicking in the check box and then clicking x to close the dialog window. Close the dialog window. You have associated a machine learning service with Watson Studio. Congratulations you can now run Auto AI experiments using Watson Studio Project. You are ready to start creating models.","title":"Associate a Watson Machine Learning Service"},{"location":"create_model/#perform-an-auto-ai-experiment","text":"AutoAI can help you choose the right classification or regression algorithm use. You choose the type of algorithm to analyze, provide Auto AI your data and what you want to predict. It then runs a pipeline to identify what are the relevant dependent features(metrics) to make a prediction. It summarizes the performance and accuracy of each algorithm it considered in a ranked ordered list. The steps below show you how to perform an Auto AI Experiment to identify a regression model to predict power consumption. A regression model provides scoring or prediction for continuous values. You can learn more about how pumps work in this Video Make sure you are in the right IBM Cloud account in the top right of the screen, otherwise AutoAI might not show up as an option. Click Add to Project and click AutoAI experiment . Note Make sure to replace co in the device type name with your own initials. Enter project name 111137F8-power-co . click Create button. Replace co with your own initials since in the next exercise you will be training and deploying your model to a shared service and want to make the name is unique. Make sure your Watson Machine Learning service is selected. Click Add a datasource and select from project button. Select the input data. Click Select from project. Click maximo-auto_ai_pump_data_111137F8.csv . Click Select asset . AutoAI detects that it is a decimal value that contains continuous time series values and selects a Regression model. Select no to create a time series forecast. Select the column to predict POWER . Click the Run experiment button. The execution goes through multiple steps and generates multiple pipeline runs of with Extra Trees Regessor , LGBM and other models. This process can take 3 - 10 minutes. Congratulations you now know how to run AutoAI Experiments. In the next exercise you will assess the experiment results and choose a model to use for predicting power for each pump.","title":"Perform an Auto AI Experiment"},{"location":"create_model/#choose-a-prediction-model","text":"Watson Studio can identify what are the correlated metrics that have the greatest impact in predicting a metric. It also provides overall accuracy of the model performance. Finally it gives you a ranked ordered list of the models that are best fits for making a prediction. Review the pipeline leader board for which algorithms performed best. Click on the Extra Trees Regressor algorithm. there maybe more than one. Select the one that doesn't have feature engineering. The Auto AI experiment Model Evatluation Measures provides mean absolute error, root mean squared error and other measures. These were used to determine what was the most effective algorithm. 4 Click Model Information shows what the target prediction metric was POWER . It also shows how many features were considered to be important to predicting pump power consumption. 5 Click Feature Importance to see which features are most important to predicting pump power consumption. Note them down these will become the input arguments to our prediction model. Also note how only 4 of the 8 total features were found to impact the power prediction. Click `Save As button Notice how Auto AI give you two options for saving your algorithm. You can save as a Model that gets deployed and you can begin scoring in your Watson Machine Learning service. There is a separate code pattern that shows how you can call Watson Machine learning using a custom function. See this code pattern . You can also save the algorithm as Notebook. Hit the Cancel button. You will use the provided Juypter Notebook to test, train and deploy your own Extra Trees Regressor algorithm to Monitor in the next lab. When you're done, click Back and click New Auto AI experiment . Repeat the previous steps with the other pump data maximo-auto_ai_pump_data_11111096.csv you previously added to your Watson Studio project. Congratulations you know have identified the the best model for each pump . You also have identified that speed, head, voltage, flow, and current are the input arguement needed for your model to be able to predict power. The next lab exercise provides you a Jupter Notebook named maximo_auto_ai-extra-trees-pump.ipynb that will allow you to train, test and deploy the an Extra Trees Regressor algorigthm prediction model into to Monitor.","title":"Choose a Prediction Model"},{"location":"deploy_prediction_model_function/","text":"Deploy and Configure a PredictionModel Custom Function in Monitor Note Skip steps 1, 2, 3, 4 and 5 if you are in the Think2021 Hands on Lab session. These steps have already been done for you. In this exercise you deploy a Monitor Custom Function to call the Prediction Model to make prediction. Custom Functions are stored in Github Repositories. Functions must be added to an Asset Type and scheduled in a pipeline to run. Here is the Architecture flow for this tutorial. In order for Maximo Monitor pipeline to access private Github repositories you must create a token. Login to Github. Create a personal access token for your custom function repository using these instructions Append the token to the URL in function.py See the already updated URL for the custom function to call the PredictionModel in the ai_prediction/functions.py PACKAGE_URL = 'git+https://yourtoken@github.com/yourgithub/maximo_autoai.git' Save and commit the changes to the github repo. git add ./custom/functions.py git commit -m \"my function changes\" git push origin master Custom Functions are stored in Github Repositories. They are added to a Monitor catalog by registering them. Register the function using this script. python3 ./scripts/register_RredictionModel_function.py After registering the function in Monitor, you can add the PredictionModel custom function from the catalog to pump_co Asset Type. This will enable the function to run every 5 minutes and make a prediction using latest meter readings. Navigate to the Setup menu. Search for and pick the pump_co asset type and click on the Setup Asset Type Link Click the + icon to add a data item function as a calculated metric to your Asset Type. Search for the PredictionModel function. Set the value for the Model Name to the one you used in the earlier exercise Deploy and Configure a Prediction Model Custom Function in Monitor that includes your initials. modelname = power_random_forest_yourinitials.mod Each Asset can have multiple associated metrics which track sensor readings over time. Since the model you created requires speed , flow , voltage , CURRENT to predict POWER Select the those as input metrics to the function. Click the Next button. Set the name of the Output metric name to power_prediction This will have the predicted power value returned from your Model invoked by your PredictionModel custom function. The pipeline is scheduled to run ever 5 mins by default. You must wait five minute for the pipeline to execute and calculate your","title":"9. Deploy Model"},{"location":"deploy_prediction_model_function/#deploy-and-configure-a-predictionmodel-custom-function-in-monitor","text":"Note Skip steps 1, 2, 3, 4 and 5 if you are in the Think2021 Hands on Lab session. These steps have already been done for you. In this exercise you deploy a Monitor Custom Function to call the Prediction Model to make prediction. Custom Functions are stored in Github Repositories. Functions must be added to an Asset Type and scheduled in a pipeline to run. Here is the Architecture flow for this tutorial. In order for Maximo Monitor pipeline to access private Github repositories you must create a token. Login to Github. Create a personal access token for your custom function repository using these instructions Append the token to the URL in function.py See the already updated URL for the custom function to call the PredictionModel in the ai_prediction/functions.py PACKAGE_URL = 'git+https://yourtoken@github.com/yourgithub/maximo_autoai.git' Save and commit the changes to the github repo. git add ./custom/functions.py git commit -m \"my function changes\" git push origin master Custom Functions are stored in Github Repositories. They are added to a Monitor catalog by registering them. Register the function using this script. python3 ./scripts/register_RredictionModel_function.py After registering the function in Monitor, you can add the PredictionModel custom function from the catalog to pump_co Asset Type. This will enable the function to run every 5 minutes and make a prediction using latest meter readings. Navigate to the Setup menu. Search for and pick the pump_co asset type and click on the Setup Asset Type Link Click the + icon to add a data item function as a calculated metric to your Asset Type. Search for the PredictionModel function. Set the value for the Model Name to the one you used in the earlier exercise Deploy and Configure a Prediction Model Custom Function in Monitor that includes your initials. modelname = power_random_forest_yourinitials.mod Each Asset can have multiple associated metrics which track sensor readings over time. Since the model you created requires speed , flow , voltage , CURRENT to predict POWER Select the those as input metrics to the function. Click the Next button. Set the name of the Output metric name to power_prediction This will have the predicted power value returned from your Model invoked by your PredictionModel custom function. The pipeline is scheduled to run ever 5 mins by default. You must wait five minute for the pipeline to execute and calculate your","title":"Deploy and Configure a PredictionModel Custom Function in Monitor"},{"location":"get_started/","text":"Summary In this Maximo Auto AI Lab you wil learn how to use Auto AI to identify a prediction machine learning model that you can train and then deploy to Maximo Asset Monitor. You will learn how to: Use the provided Jupyter notebook that will contain Python code to train, test and deploy machine learning model to Maximo Asset Monitor Use the provided Maximo Asset Monitor custom function to make predictions as new time series data is received in Maximo Asset Monitor Create Asset Types and devices using simulated pump data. Create an Asset Type and Asset dashboards to see the pump data and model predictions in Monitor Description Maximo Asset Monitor provides a powerful analytics platform to ingest time series data from a variety of historians and devices. Monitor includes a variety of model functions that can be use to predict performance of assets or detect performance anomalies. Sometimes however you may want to create custom machine learning models to make predictions or classifications using asset data. With Auto AI the process of selecting the right model and identifying the right feature inputs to make metric prediction is greatly simplified. The intended audience for this tutorial are developers and data scientists who would like to analyze their data in Maximo Asset Monitor using customized machine learning models that are deployed in the Maximo Asset Monitor Service schedule pipeline. Pump Data and Devices To apply AI and Monitor assets you will create 2 pump devices 11111096 and 111137F8 . To simulate sending data to the pumps, you can use the provided Python script pump_simulator.py to send device data to Monitor IOT Platform. This lab uses real pump device data in the csv file named maximo-auto_ai_pump_all_data.csv . The two pump device data metric readings that will sent are: Metric Name Metric Description evt_timestamp Reading timestamp metric data was read by sensor speed Pump impeller speed head Pump head device_id The device identifier for the 2 pump devices 11111096 and 111137F8 pump_mode Pump mode a for automatic or h for manually operated by hand flow Pump flow voltage Pump voltage POWER Pump power consumption CURRENT Pump current Note If your lab is instructor led steps 1, 2, 3, 4, 5, 6 and 9 have already been done for you in the environment provide to you by your instructor. You should only do steps 7, 8 and 10. Exercises Find the detailed instructions in the each exercise below: Setup Local Environment Create Device Types Create Devices Send Simulated Pump Data Create Physical and Logical Interfaces Create Dashboards in Maximo Asset Monitor using simulated pump data Identify Prediction Models to predict Power consumption using Watson Studio Auto AI Train Test and Deploy Models in Monitor to Monitor using Juypter Notebook Deploy and Configure a PredictionModel Custom Function in Monitor Update Dashboards with power prediction calculated metric in Maximo Asset Monitor Architecture Here is the Architecture flow for this tutorial","title":"Get Started"},{"location":"get_started/#summary","text":"In this Maximo Auto AI Lab you wil learn how to use Auto AI to identify a prediction machine learning model that you can train and then deploy to Maximo Asset Monitor. You will learn how to: Use the provided Jupyter notebook that will contain Python code to train, test and deploy machine learning model to Maximo Asset Monitor Use the provided Maximo Asset Monitor custom function to make predictions as new time series data is received in Maximo Asset Monitor Create Asset Types and devices using simulated pump data. Create an Asset Type and Asset dashboards to see the pump data and model predictions in Monitor","title":"Summary"},{"location":"get_started/#description","text":"Maximo Asset Monitor provides a powerful analytics platform to ingest time series data from a variety of historians and devices. Monitor includes a variety of model functions that can be use to predict performance of assets or detect performance anomalies. Sometimes however you may want to create custom machine learning models to make predictions or classifications using asset data. With Auto AI the process of selecting the right model and identifying the right feature inputs to make metric prediction is greatly simplified. The intended audience for this tutorial are developers and data scientists who would like to analyze their data in Maximo Asset Monitor using customized machine learning models that are deployed in the Maximo Asset Monitor Service schedule pipeline.","title":"Description"},{"location":"get_started/#pump-data-and-devices","text":"To apply AI and Monitor assets you will create 2 pump devices 11111096 and 111137F8 . To simulate sending data to the pumps, you can use the provided Python script pump_simulator.py to send device data to Monitor IOT Platform. This lab uses real pump device data in the csv file named maximo-auto_ai_pump_all_data.csv . The two pump device data metric readings that will sent are: Metric Name Metric Description evt_timestamp Reading timestamp metric data was read by sensor speed Pump impeller speed head Pump head device_id The device identifier for the 2 pump devices 11111096 and 111137F8 pump_mode Pump mode a for automatic or h for manually operated by hand flow Pump flow voltage Pump voltage POWER Pump power consumption CURRENT Pump current Note If your lab is instructor led steps 1, 2, 3, 4, 5, 6 and 9 have already been done for you in the environment provide to you by your instructor. You should only do steps 7, 8 and 10.","title":"Pump Data and Devices"},{"location":"get_started/#exercises","text":"Find the detailed instructions in the each exercise below: Setup Local Environment Create Device Types Create Devices Send Simulated Pump Data Create Physical and Logical Interfaces Create Dashboards in Maximo Asset Monitor using simulated pump data Identify Prediction Models to predict Power consumption using Watson Studio Auto AI Train Test and Deploy Models in Monitor to Monitor using Juypter Notebook Deploy and Configure a PredictionModel Custom Function in Monitor Update Dashboards with power prediction calculated metric in Maximo Asset Monitor","title":"Exercises"},{"location":"get_started/#architecture","text":"Here is the Architecture flow for this tutorial","title":"Architecture"},{"location":"release_notes/","text":"About Contributors to the Maximo Monitor Auto AI Lab Carlos Ferreira - carlos.ferreira1@ibm.com References https://github.com/ibm-watson-iot/iot-python/tree/master/samples/simpleDevice Change Information Date By Description 2024-01-02 Jan Ekstr\u00f8m Restructured to work on Github Pages. 2021-10-13 Carlos Ferreira Incorporated testing feedback from Christophe Lucas. Ready for test","title":"Release Notes"},{"location":"release_notes/#about","text":"","title":"About"},{"location":"release_notes/#contributors-to-the-maximo-monitor-auto-ai-lab","text":"Carlos Ferreira - carlos.ferreira1@ibm.com","title":"Contributors to the Maximo Monitor Auto AI Lab"},{"location":"release_notes/#references","text":"https://github.com/ibm-watson-iot/iot-python/tree/master/samples/simpleDevice","title":"References"},{"location":"release_notes/#change-information","text":"Date By Description 2024-01-02 Jan Ekstr\u00f8m Restructured to work on Github Pages. 2021-10-13 Carlos Ferreira Incorporated testing feedback from Christophe Lucas. Ready for test","title":"Change Information"},{"location":"send_device_simulated_data/","text":"Send Device Simulated Data In these exercises you will start sending pump data to Monitor IOT Platform. This will allow us to make predictions on power in the later exercises. Update environment settings for pump devices. Start Python Simulator for the 1 of devices. Verify the Device data is being received by Monitor. Update Environment Settings The simulator needs to know the name of your organization, device type, device id and security Token. Edit the file named .env_example and save it as .env using the values below. Get the Organization, API Key and API Token from your MAS Administrator. Here is an example of the format of an example credentials file. { \"tenantId\": \"your_TENANTID\", \"_db_schema\": \"your_SCHEMA\", \"db2\": { \"username\": \"your_DBUSERID\", \"password\": \"your_DBPASSWORD\", \"databaseName\": \"your_DBNAME\", \"security\": \"SSL\", \"port\": your_DBPORT, \"httpsUrl\": \"https://your_DBURL\", \"host\": \"yourDBURL\" }, \"iotp\": { \"asHost\": \"your_TENANTID.api.monitor.your_TENANTNAME.your_TENANTNAME.cloud:443\", \"apiKey\": \"your_IOTP_APIKEY\", \"apiToken\": \"your_IOTP_APITOKEN\" } } Get the values for fields like TOKEN , DEVICE_TYPE for the devices you created in the Create Devices exercise for the 1 of pump devices 111137F8 For SOURCE_DEVICE_ID this is the name of the Device ID in the source data csv file. See example file provided by the instructor named /data/maximo-auto_ai_pump_data_111137F8.csv For DEVICE_ID this is the name of the Device ID in the Monitor. Start the Python Simulator This exercise includes Python Simulator that reads a csv file maximo-auto_ai_pump_data_111137F8.csv . with the pump data and sends the rows of data for the pump device you specified in the previous exercise. The event_payload.json looks like: json { \"evt_timestamp\": \"2020-01-19T03:59:53.03Z\", \"speed\": 1141, \"head\": 61.298, \"pump_mode\": \"a\", \"flow\": 1226.936, \"voltage\": 438, \"POWER\": 18.93, \"CURRENT\": 32.6 } 1. If you are using PyCharm as your Integrated Development Environment select pump_simulator.py and right mouse click select Run pump_simulator.py If you are using a local virtual environment cd into ../scripts and invoke the script by typing the following command: python3 pump_simulator.py Verify the Device data To be able to ingest device data using Monitor you must first define the format of the data using a Device Type. In this exercise you will, create a Device Type named pump_co and 2 Devices named 11111096 and 111137F8 . Login to Monitor from the Maximo Application Suite Navigator page. Click Click Connect devices tile Or click On the Connect menu Click Open Platform Service application in the top-right corner to open the Watson IoT Platform tenant associated with this Monitor tenant in a separate browser tab. Go to the Devices menu. Enter the Device ID 111137F8 in the search box. Click Recent Events . It might take a moment to get values as shown in the image below. Optionally you can repeat this exercise with the other pump 11111096 using it's training data Congratulations you now pump device data flowing that you will use make a prediction model and monitor in dashboards.","title":"4. Send Simulated Data"},{"location":"send_device_simulated_data/#send-device-simulated-data","text":"In these exercises you will start sending pump data to Monitor IOT Platform. This will allow us to make predictions on power in the later exercises. Update environment settings for pump devices. Start Python Simulator for the 1 of devices. Verify the Device data is being received by Monitor.","title":"Send Device Simulated Data"},{"location":"send_device_simulated_data/#update-environment-settings","text":"The simulator needs to know the name of your organization, device type, device id and security Token. Edit the file named .env_example and save it as .env using the values below. Get the Organization, API Key and API Token from your MAS Administrator. Here is an example of the format of an example credentials file. { \"tenantId\": \"your_TENANTID\", \"_db_schema\": \"your_SCHEMA\", \"db2\": { \"username\": \"your_DBUSERID\", \"password\": \"your_DBPASSWORD\", \"databaseName\": \"your_DBNAME\", \"security\": \"SSL\", \"port\": your_DBPORT, \"httpsUrl\": \"https://your_DBURL\", \"host\": \"yourDBURL\" }, \"iotp\": { \"asHost\": \"your_TENANTID.api.monitor.your_TENANTNAME.your_TENANTNAME.cloud:443\", \"apiKey\": \"your_IOTP_APIKEY\", \"apiToken\": \"your_IOTP_APITOKEN\" } } Get the values for fields like TOKEN , DEVICE_TYPE for the devices you created in the Create Devices exercise for the 1 of pump devices 111137F8 For SOURCE_DEVICE_ID this is the name of the Device ID in the source data csv file. See example file provided by the instructor named /data/maximo-auto_ai_pump_data_111137F8.csv For DEVICE_ID this is the name of the Device ID in the Monitor.","title":"Update Environment Settings"},{"location":"send_device_simulated_data/#start-the-python-simulator","text":"This exercise includes Python Simulator that reads a csv file maximo-auto_ai_pump_data_111137F8.csv . with the pump data and sends the rows of data for the pump device you specified in the previous exercise. The event_payload.json looks like: json { \"evt_timestamp\": \"2020-01-19T03:59:53.03Z\", \"speed\": 1141, \"head\": 61.298, \"pump_mode\": \"a\", \"flow\": 1226.936, \"voltage\": 438, \"POWER\": 18.93, \"CURRENT\": 32.6 } 1. If you are using PyCharm as your Integrated Development Environment select pump_simulator.py and right mouse click select Run pump_simulator.py If you are using a local virtual environment cd into ../scripts and invoke the script by typing the following command: python3 pump_simulator.py","title":"Start the Python Simulator"},{"location":"send_device_simulated_data/#verify-the-device-data","text":"To be able to ingest device data using Monitor you must first define the format of the data using a Device Type. In this exercise you will, create a Device Type named pump_co and 2 Devices named 11111096 and 111137F8 . Login to Monitor from the Maximo Application Suite Navigator page. Click Click Connect devices tile Or click On the Connect menu Click Open Platform Service application in the top-right corner to open the Watson IoT Platform tenant associated with this Monitor tenant in a separate browser tab. Go to the Devices menu. Enter the Device ID 111137F8 in the search box. Click Recent Events . It might take a moment to get values as shown in the image below. Optionally you can repeat this exercise with the other pump 11111096 using it's training data Congratulations you now pump device data flowing that you will use make a prediction model and monitor in dashboards.","title":"Verify the Device data"},{"location":"setup_local_environment/","text":"Setup Local Environment In this exercise you will setup your local development environment. Install and Create a Virtual Environment for Python v3.7.9 Setup and Activate a Virtual Environment Install Python dependencies, clone repository and verify environment Install and Launch Jupyter to work with Regression Models Download, Install and Configure CyberDuck for View Logs in Monitor Download, Install and Configure PyCharm Debug Functions Note These directions for are a Mac. Using Python v3.7.9 for Maximo Application Suite v8.4. Download Python for Windows at https://www.python.org/downloads/windows/ Install and Create a Virtual Environment Launch Terminal Install Brew Follow directions here: https://brew.sh/ Install the right Python Version v3.7.9 brew install python Install \"pip\". (Python Package Installer): sudo easy_install pip # for Mac try also removing sudo from the command For Python 3.8.10 try using instructions : python3 -m ensurepip --default-pip Install virtual environment to keep dependencies separate from other projects ### For Mac sudo pip install virtualenv ### For Windows pip install virtualenv Create a virtual environment use Python 3.7.9 for Maximo Application Suite v8.3 python3 -m venv iot-python3 Setup and Activate a Virtual Environment Open a new terminal window and change directory to your Virtual Environment directory. cd iot-python3 Activate your virtual environment. For Mac source bin/activate For Windows .\\Scripts\\activate The result in Terminal should be something like: For Mac (iot-python3) My-Mac: myuserid$ Install Git. For Windows See https://git-scm.com/download/win For Mac The easiest is to install the Xcode Command Line Tools. Clone the github repository. git clone repo provided by your instructor cd maxmio_autoai Within your project directory in the activated virtual environment, install Monitor Python Custom Functions SDK and dependencies. pip install -r requirements.txt Apply export variables in terminal for DYLD_LIBRARY_PATH for DB2 jars on Mac OS X only. For Mac cd \"<replace with the git cloned project directory name>\" export DYLD_LIBRARY_PATH=<\"replace with your virtual env directory>\"/lib/python3.7/site-packages/clidriver/lib:$DYLD_LIBRARY_PATH export DYLD_LIBRARY_PATH=/Users/carlosferreira/ve/iot-python3/lib/python3.7/site-packages/clidriver/lib:$DYLD_LIBRARY_PATH Set PYTHONPATH to your project directory where you installed your virtual environment. For Mac export PYTHONPATH=\"<replace with your root_project_directory>\"/maximo_autoai export PYTHONPATH=/Users/carlosferreira/Documents/AutoAILabs/iot-python3/maximo_autoai Go to Monitor, click on Services , click View Details of Watson IOT Analytics. Click on Copy and paste icon and copy the credentials into a file named beta-1_credentials.json file. Save the file in the project git cloned project directory name directory maximo_autoai . Verify that you can get a local Python Script to run without errors. python ./scripts/local_test_of_function.py Install and Launch Jupyter Jupyter is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and algorithms for working with AI Models and functions. Install Jupyter using instructions Use the Pip Install option. Start Jupyter Notebook process. Using a similar example steps below. cd /Users/student01/ve/iot-python3/bin source activate cd /Users/student01/MAS_AutoAI export PYTHONPATH=/Users/student01/MAS_AutoAI export DYLD_LIBRARY_PATH=/Users/student01/ve/iot-python3/lib/python3.7/site-packages/clidriver/lib:$DYLD_LIBRARY_PATH Launch Jupyter Notebook to edit Linear Regression Models. jupyter notebook This opens a Jupyter notebook in the new browser window that opened. Browse to the notebooks folder. Click on the notebook to view the Notebook. Download, Install and Configure CyberDuck for View Logs in Monitor Depending on the version of Monitor it may use either the Database or Object Storage service store logs. To access the log files for custom functions in Cloud Object Storage. Install and configure Cyberduck to view logs. Connect to the Cloud Object Storage (COS) to download the custom function logs. You can access the credentials for accessing the service in Monitor under Services tab. Use tool called Cyberduck. Download free version from: Web: https://cyberduck.io/download/ Configure the setting in CyberDuck to connect to the Object Storage service included with Monitor. In Monitor, click on Services menu. Copy the settings for Object Storage as shown in the below into CyberDuck . Open CyberDuck and create a New Connection . Select Protocol is S3 Amazon URL Server is taken from Monitor Object Storage Service Cross Region Endpoints choose your region like US https://s3-api.us-geo.objectstorage.softlayer.net Copy Access Key ID for your Tenant ID Copy Secret Access Key for your Tenant ID Click Connect Button. Hit refresh and navigate to your Asset Type and date folder to see and download your log files. You will see Entity_Type_ID in the first few lines of the log files for that Asset Type . Bookmark the page for your Asset Type so that you can navigate here directly next time you want to access logs. Download, Install and Configure DBeaver Depending on the version of Monitor it may use either the Database or Object Storage service store logs. To access the log files for custom functions in Database, install and configure Dbeaver client to view logs in the database table. Connect to the Monitor Database Service to query database for custom function logs. You can get the database credentials for accessing the database service in Monitor under Services tab. Use a universal database client tool like Dbeaver to access the table. Download the free community edition from https://dbeaver.io/download/ Configure the setting in Dbeaver to connect to the Database service included with Monitor. In Monitor, click on Services menu. Copy the settings for Database and enter them as as shown in DBeaver . Open Dbeaver . Select a New Database Connection option from the Database menu. Select IBM DB2 and click on Next button. Enter the database settings from Monitor Database Service in DBeaver connection settings dialog. Click test Connection Button. Click OK Button to save the connection. Query Logs using DBeaver Depending on the version of Monitor it may use either the Database or Object Storage service store logs. To access the log files for custom functions in Database use the following queries with Dbeaver client to view logs. Open Dbeaver . Click a Monitor Database Connection for BLUDB schema. Select New SQL Script from the SQL Editor menu. Enter the the following query to get status of execution for all functions. SELECT E.NAME, K.ENTITY_TYPE_ID, K.STATUS, COUNT(*) AS Count FROM MAS82_MAM.KPI_LOGGING K, IOTANALYTICS.ENTITY_TYPE E WHERE K.ENTITY_TYPE_ID = E.ENTITY_TYPE_ID GROUP BY E.NAME ,K.ENTITY_TYPE_ID,K.STATUS ; Enter the the following query to delete old logs. DELETE FROM MAS82_MAM.KPI_LOGGING WHERE DATE(UPDATED_TS)!=CURRENT_DATE; Enter the the following query to purge successful runs. DELETE FROM MAS82_MAM.KPI_LOGGING WHERE STATUS='SUCCESS' AND ENTITY_TYPE_ID IN (13,14); Enter the the following query to get last 10 logs. SELECT E.NAME, K.ENTITY_TYPE_ID, K.STATUS, K.LOGFILE, K.LOG_MESSAGE, K.ERROR_MESSAGE, K.STARTED_TS FROM MAS82_MAM.KPI_LOGGING K, IOTANALYTICS.ENTITY_TYPE E WHERE K.ENTITY_TYPE_ID = E.ENTITY_TYPE_ID ORDER BY K.STARTED_TS DESC LIMIT 10; Download, Install and Configure PyCharm Using an integrated development environment helps improve developer productivity when writing Python scripts and Monitor Custom Functions. It is recommended that you download and install Pycharme Community Edition . It is a free IDE. To run Python Scripts in you should configure your Python Environment for each script you would like to run to reference the virtual environment you setup earlier. Follow the instructions to install Pycharm Community Edition. Start Pycharm. In the Project view, right click on the Python script file you want to run. Select edit configurations . See the example settings below. Set the Python Environment variable similar to what is shown below. It should reflect the installation directory of your virtual environment. PYTHONUNBUFFERED=1;DYLD_LIBRARY_PATH=/Users/student01/ve/iot-python3/lib/python3.7/site-packages/clidriver/lib:$DYLD_LIBRARY_PATH;PYTHONPATH=/Users/student01/MAS_AutoAI Set the Python interpreter to your virtual environment. Debug Functions Functions can be run locally and also run within the pipeline. You typically want to make sure your function works locally before you git commit your function and register your function with Monitor. To run your function locally run Python script ../scripts/local_test_of_function.py Git commit your function to a Github and they see if your data item for the calculated metric that calls your function runs. Functions that have a problem will cause an error and cause the pipeline to stop for all other function on on the Entity Type. You should resolve those issues quickly so that others aren't prevented from monitoring their own calculated metrics on the same Asset Type. If you see error message saying Analysis Stopped this means you have a pipeline processing error and that a custom function likely is causing it. It may also mean an input or output argument required by a calculated metric has been deleted or doesn't have a needed value. If your calculate metric runs but doesn't give the desired results see the log files for that Asset Type. Download, Install and Configure CyberDuck for View Logs in Monitor","title":"1. Setup Local Environment"},{"location":"setup_local_environment/#setup-local-environment","text":"In this exercise you will setup your local development environment. Install and Create a Virtual Environment for Python v3.7.9 Setup and Activate a Virtual Environment Install Python dependencies, clone repository and verify environment Install and Launch Jupyter to work with Regression Models Download, Install and Configure CyberDuck for View Logs in Monitor Download, Install and Configure PyCharm Debug Functions Note These directions for are a Mac. Using Python v3.7.9 for Maximo Application Suite v8.4. Download Python for Windows at https://www.python.org/downloads/windows/","title":"Setup Local Environment"},{"location":"setup_local_environment/#install-and-create-a-virtual-environment","text":"Launch Terminal Install Brew Follow directions here: https://brew.sh/ Install the right Python Version v3.7.9 brew install python Install \"pip\". (Python Package Installer): sudo easy_install pip # for Mac try also removing sudo from the command For Python 3.8.10 try using instructions : python3 -m ensurepip --default-pip Install virtual environment to keep dependencies separate from other projects ### For Mac sudo pip install virtualenv ### For Windows pip install virtualenv Create a virtual environment use Python 3.7.9 for Maximo Application Suite v8.3 python3 -m venv iot-python3","title":"Install and Create a Virtual Environment"},{"location":"setup_local_environment/#setup-and-activate-a-virtual-environment","text":"Open a new terminal window and change directory to your Virtual Environment directory. cd iot-python3 Activate your virtual environment.","title":"Setup and Activate a Virtual Environment"},{"location":"setup_local_environment/#for-mac","text":"source bin/activate","title":"For Mac"},{"location":"setup_local_environment/#for-windows","text":".\\Scripts\\activate The result in Terminal should be something like:","title":"For Windows"},{"location":"setup_local_environment/#for-mac_1","text":"(iot-python3) My-Mac: myuserid$ Install Git.","title":"For Mac"},{"location":"setup_local_environment/#for-windows_1","text":"See https://git-scm.com/download/win","title":"For Windows"},{"location":"setup_local_environment/#for-mac_2","text":"The easiest is to install the Xcode Command Line Tools. Clone the github repository. git clone repo provided by your instructor cd maxmio_autoai Within your project directory in the activated virtual environment, install Monitor Python Custom Functions SDK and dependencies. pip install -r requirements.txt Apply export variables in terminal for DYLD_LIBRARY_PATH for DB2 jars on Mac OS X only.","title":"For Mac"},{"location":"setup_local_environment/#for-mac_3","text":"cd \"<replace with the git cloned project directory name>\" export DYLD_LIBRARY_PATH=<\"replace with your virtual env directory>\"/lib/python3.7/site-packages/clidriver/lib:$DYLD_LIBRARY_PATH export DYLD_LIBRARY_PATH=/Users/carlosferreira/ve/iot-python3/lib/python3.7/site-packages/clidriver/lib:$DYLD_LIBRARY_PATH Set PYTHONPATH to your project directory where you installed your virtual environment.","title":"For Mac"},{"location":"setup_local_environment/#for-mac_4","text":"export PYTHONPATH=\"<replace with your root_project_directory>\"/maximo_autoai export PYTHONPATH=/Users/carlosferreira/Documents/AutoAILabs/iot-python3/maximo_autoai Go to Monitor, click on Services , click View Details of Watson IOT Analytics. Click on Copy and paste icon and copy the credentials into a file named beta-1_credentials.json file. Save the file in the project git cloned project directory name directory maximo_autoai . Verify that you can get a local Python Script to run without errors. python ./scripts/local_test_of_function.py","title":"For Mac"},{"location":"setup_local_environment/#install-and-launch-jupyter","text":"Jupyter is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and algorithms for working with AI Models and functions. Install Jupyter using instructions Use the Pip Install option. Start Jupyter Notebook process. Using a similar example steps below. cd /Users/student01/ve/iot-python3/bin source activate cd /Users/student01/MAS_AutoAI export PYTHONPATH=/Users/student01/MAS_AutoAI export DYLD_LIBRARY_PATH=/Users/student01/ve/iot-python3/lib/python3.7/site-packages/clidriver/lib:$DYLD_LIBRARY_PATH Launch Jupyter Notebook to edit Linear Regression Models. jupyter notebook This opens a Jupyter notebook in the new browser window that opened. Browse to the notebooks folder. Click on the notebook to view the Notebook.","title":"Install and Launch Jupyter"},{"location":"setup_local_environment/#download-install-and-configure-cyberduck-for-view-logs-in-monitor","text":"Depending on the version of Monitor it may use either the Database or Object Storage service store logs. To access the log files for custom functions in Cloud Object Storage. Install and configure Cyberduck to view logs. Connect to the Cloud Object Storage (COS) to download the custom function logs. You can access the credentials for accessing the service in Monitor under Services tab. Use tool called Cyberduck. Download free version from: Web: https://cyberduck.io/download/ Configure the setting in CyberDuck to connect to the Object Storage service included with Monitor. In Monitor, click on Services menu. Copy the settings for Object Storage as shown in the below into CyberDuck . Open CyberDuck and create a New Connection . Select Protocol is S3 Amazon URL Server is taken from Monitor Object Storage Service Cross Region Endpoints choose your region like US https://s3-api.us-geo.objectstorage.softlayer.net Copy Access Key ID for your Tenant ID Copy Secret Access Key for your Tenant ID Click Connect Button. Hit refresh and navigate to your Asset Type and date folder to see and download your log files. You will see Entity_Type_ID in the first few lines of the log files for that Asset Type . Bookmark the page for your Asset Type so that you can navigate here directly next time you want to access logs.","title":"Download, Install and Configure CyberDuck for View Logs in Monitor"},{"location":"setup_local_environment/#download-install-and-configure-dbeaver","text":"Depending on the version of Monitor it may use either the Database or Object Storage service store logs. To access the log files for custom functions in Database, install and configure Dbeaver client to view logs in the database table. Connect to the Monitor Database Service to query database for custom function logs. You can get the database credentials for accessing the database service in Monitor under Services tab. Use a universal database client tool like Dbeaver to access the table. Download the free community edition from https://dbeaver.io/download/ Configure the setting in Dbeaver to connect to the Database service included with Monitor. In Monitor, click on Services menu. Copy the settings for Database and enter them as as shown in DBeaver . Open Dbeaver . Select a New Database Connection option from the Database menu. Select IBM DB2 and click on Next button. Enter the database settings from Monitor Database Service in DBeaver connection settings dialog. Click test Connection Button. Click OK Button to save the connection.","title":"Download, Install and Configure DBeaver"},{"location":"setup_local_environment/#query-logs-using-dbeaver","text":"Depending on the version of Monitor it may use either the Database or Object Storage service store logs. To access the log files for custom functions in Database use the following queries with Dbeaver client to view logs. Open Dbeaver . Click a Monitor Database Connection for BLUDB schema. Select New SQL Script from the SQL Editor menu. Enter the the following query to get status of execution for all functions. SELECT E.NAME, K.ENTITY_TYPE_ID, K.STATUS, COUNT(*) AS Count FROM MAS82_MAM.KPI_LOGGING K, IOTANALYTICS.ENTITY_TYPE E WHERE K.ENTITY_TYPE_ID = E.ENTITY_TYPE_ID GROUP BY E.NAME ,K.ENTITY_TYPE_ID,K.STATUS ; Enter the the following query to delete old logs. DELETE FROM MAS82_MAM.KPI_LOGGING WHERE DATE(UPDATED_TS)!=CURRENT_DATE; Enter the the following query to purge successful runs. DELETE FROM MAS82_MAM.KPI_LOGGING WHERE STATUS='SUCCESS' AND ENTITY_TYPE_ID IN (13,14); Enter the the following query to get last 10 logs. SELECT E.NAME, K.ENTITY_TYPE_ID, K.STATUS, K.LOGFILE, K.LOG_MESSAGE, K.ERROR_MESSAGE, K.STARTED_TS FROM MAS82_MAM.KPI_LOGGING K, IOTANALYTICS.ENTITY_TYPE E WHERE K.ENTITY_TYPE_ID = E.ENTITY_TYPE_ID ORDER BY K.STARTED_TS DESC LIMIT 10;","title":"Query Logs using DBeaver"},{"location":"setup_local_environment/#download-install-and-configure-pycharm","text":"Using an integrated development environment helps improve developer productivity when writing Python scripts and Monitor Custom Functions. It is recommended that you download and install Pycharme Community Edition . It is a free IDE. To run Python Scripts in you should configure your Python Environment for each script you would like to run to reference the virtual environment you setup earlier. Follow the instructions to install Pycharm Community Edition. Start Pycharm. In the Project view, right click on the Python script file you want to run. Select edit configurations . See the example settings below. Set the Python Environment variable similar to what is shown below. It should reflect the installation directory of your virtual environment. PYTHONUNBUFFERED=1;DYLD_LIBRARY_PATH=/Users/student01/ve/iot-python3/lib/python3.7/site-packages/clidriver/lib:$DYLD_LIBRARY_PATH;PYTHONPATH=/Users/student01/MAS_AutoAI Set the Python interpreter to your virtual environment.","title":"Download, Install and Configure PyCharm"},{"location":"setup_local_environment/#debug-functions","text":"Functions can be run locally and also run within the pipeline. You typically want to make sure your function works locally before you git commit your function and register your function with Monitor. To run your function locally run Python script ../scripts/local_test_of_function.py Git commit your function to a Github and they see if your data item for the calculated metric that calls your function runs. Functions that have a problem will cause an error and cause the pipeline to stop for all other function on on the Entity Type. You should resolve those issues quickly so that others aren't prevented from monitoring their own calculated metrics on the same Asset Type. If you see error message saying Analysis Stopped this means you have a pipeline processing error and that a custom function likely is causing it. It may also mean an input or output argument required by a calculated metric has been deleted or doesn't have a needed value. If your calculate metric runs but doesn't give the desired results see the log files for that Asset Type. Download, Install and Configure CyberDuck for View Logs in Monitor","title":"Debug Functions"},{"location":"train_test_save_model_in_monitor/","text":"Train, Test and Save Prediction Model in Monitor Monitor provides an APi to store and retrieve models that can be called using using a custom function to make predictions. This exercise include a sample Jupyter Notebook that shows you how to retrieve data from Monitor and a csv file to train a model. How to store a model and retrieve a model from Monitor make a prediction. In these exercises using the provided Jupyter Notebook you will: Train a Model Test a Model Save a Model in Monitor Retrieve a Model from Monitor Train a Model Note If this lab is instructor led, he or she will provide you access to virtual image that has the Jupyter and the notebooks already installed. Skip steps 3, 4 and 8 if you are using Windows Virtual Machine. Open a terminal window on Mac or a command prompt window on Windows. Activate your virtual environment. Example for Mac cd /Users/<\"replace with your user id\">/<\"replace with your virtual environment name\">/bin cd /Users/carlosferreira/ve/iot-python3/bin source activate Example for Windows cd C:\\Users\\ibmuser\\iot-python3 .\\Scripts\\activate.bat Change directory to your cloned github project directory. Example for Mac cd /Users/student01/MAS_AutoAI Example for Windows cd C:\\Users\\ibmuser\\iot-python3\\maximo_autoai Apply export variables in terminal for DYLD_LIBRARY_PATH for DB2 jars on Mac OS X only. Example for Mac cd \"<replace with the git cloned project directory name>\" cd /Users/carlos.ferreira1ibm.com/ws/autoai export DYLD_LIBRARY_PATH=<\"replace with your virtual env directory>\"/lib/python3.7/site-packages/clidriver/lib:$DYLD_LIBRARY_PATH export DYLD_LIBRARY_PATH=/Users/carlosferreira/ve/iot-python3/lib/python3.7/site-packages/clidriver/lib:$DYLD_LIBRARY_PATH # Example Set PYTHONPATH to your project directory where you installed your virtual environment Example for Mac export PYTHONPATH=\"<replace with your root_project_directory>\"/maximo_autoai export PYTHONPATH=/Users/carlosferreira/Documents/AutoAILabs/iot-python3/maximo_autoai Start the Jupyter Notebook service. and launch browser with Jupyter Notebook to edit Linear Regression Models. jupyter notebook Jupyter will open in a browser tab. Open and study the project notebook named maximo_auto_ai-extra-trees-pump.ipynb using the instructions for the virtual environment you created. Click on Notebooks folder. Click on notebook named maximo_auto_ai-extra-trees-pump.ipyn Make a copy of the Project Notebook Rename the notebook, change the name of your notebook by appending your own initials to the end of the Jupyter Notebook name. In the jupyter notebook, select file menu and Save As . Enter notebooks/maximo_auto_ai-extra-trees-pump-co.ipynb and click Save . This code in the notebook sets the Monitor credentials and entity type for your your instance of Monitor. Copy your credentials in Monitor from Services menu and Watson IOT Platform Analytics. Save it in a file named beta-1_credentials.json in the directory shown in the code below. credentials = {} with open('/Users/carlos.ferreira1ibm.com/ws/autoai/beta-1_credentials.json', encoding='utf-8') as F: credentials = json.loads(F.read()) db = Database(credentials = credentials) db_schema = \"BLUADMIN\" # set if you are not using the default entity_type = 'pump_co' This code in the notebook build a model for each pump. The Entity_Type_ID uniquely identifies each asset the model should be trained for. Set the Entity_Type_ID the model should be associated with. There are two ways to search the custom function logs in Cloud Object Storage using Cyberduck that are described in the exercise named Download, Install and Configure CyberDuck for View Logs in Monitor To find your Entity_Type_ID in the logs in Monitor, launch Cyberduck, and locate your pump, e.g. pump_co. Unzip and open one of the *.gz files there (e.g. 111012.gz) and search for 'entity_type_id'. It should be on the first row of the log files. entity_type = 'pump_cp' entity_type_id = 19305 entity_name = '04714B6037F8' a_df = r_df.loc[r_df['device_id'] == entity_name, :] print ('a_df.shape 1') print (a_df.shape) print (a_df) This code in the notebook splits the data into train and test subsets. from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42) This code in the notebook creates the model using the train data. extra_trees_model = ExtraTreesRegressor() extra_trees_model.fit(X_train, y_train.values.ravel() ) Test a Model This code in the notebook tests the model using the test data to make a prediction. It should return a power prediction = 11.471 row = [[ 971.0, 989.633, 331.0, 26.44]] yhat = extra_trees_model.predict(row) x_pos_predictions = extra_trees_model.predict(X_test) This code in the notebook plots the prediction accuracy by comparing prediction values versus true values. plt.scatter(y_test, x_pos_predictions) plt.xlabel('True Values') plt.ylabel('Predictions') This code in the notebook calculates the model accuracy. Smaller values indicate better accuracy making predictions. from sklearn import metrics print(\"Mean Absolute Error\") print(metrics.mean_absolute_error(y_test, x_pos_predictions)) print(\"Mean Square Error\") print(metrics.mean_squared_error(y_test, x_pos_predictions)) print(\"Root Mean Square Error\") print(np.sqrt(metrics.mean_squared_error(y_test, x_pos_predictions))) Save Model to Monitor. In the notebook, change the name of your model by replacing co with your own initials power_extra_trees_model_co.mod This code in the notebook saves the model to disk locally, re-loads the mode into memory and tries to make a prediction. import pickle model_file_path = '/Users/carlos.ferreira1ibm.com/ws/autoai/models/power_random_forest.mod' pickle.dump(extra_trees_model, open(model_file_path, 'wb')) model = pickle.load(open(model_file_path, 'rb')) row = [[1160.0, 1190.626, 438.0, 33.16]] yhat = model.predict(row) This code in the notebook saves the model in Monitor. Make sure you replace the co in the model name to your own initials power_extra_trees_model_co.mod from iotfunctions.db import Database import json credentials = {} credential_file = '/Users/carlos.ferreira1ibm.com/ws/autoai/beta-1_credentials.json' with open(credential_file, encoding='utf-8') as F: credentials = json.loads(F.read()) db_ctp = Database(credentials=credentials, entity_type_id=entity_type_id ) from datetime import datetime model_name = 'power_extra_trees_model_co.mod' try: feature_vector = ['speed', 'flow', 'voltage', 'CURRENT' ] model_dict = { 'model': model, 'feature_vector': feature_vector, 'timesstamp' : datetime.now().strftime(\"%Y%m%d%H%M%S\") } db_ctp.model_store.store_model(model_name, model_dict) except Exception as e: print('Model store failed with ' + str(e)) pass Retrieve a Model and Make Predictions This code in the notebook retrieves the model from Monitor and tries to make a prediction. try: model_dict = db_ctp.model_store.retrieve_model(model_name) print(\"load model\") monitor_model = model_dict[\"model\"] print(monitor_model) feature_vector = model_dict[\"feature_vector\"] print(feature_vector) feature_vector = model_dict[\"timesstamp\"] print(feature_vector) except Exception as e: print(\"Model retrieval failed with \" + str(e)) pass Congratulations you have learned how to use the provided Jupyter notebook to train test and deploy a prediction model to Monitor. For more resource intensive models you should deploy them to a separate runtime service to make predictions. In the next lab exercise you will register the provided Monitor Custom function that will allow you to send the pump metrics data to your deployed model to make a prediction.","title":"8. Train Model"},{"location":"train_test_save_model_in_monitor/#train-test-and-save-prediction-model-in-monitor","text":"Monitor provides an APi to store and retrieve models that can be called using using a custom function to make predictions. This exercise include a sample Jupyter Notebook that shows you how to retrieve data from Monitor and a csv file to train a model. How to store a model and retrieve a model from Monitor make a prediction. In these exercises using the provided Jupyter Notebook you will: Train a Model Test a Model Save a Model in Monitor Retrieve a Model from Monitor","title":"Train, Test and Save Prediction Model in Monitor"},{"location":"train_test_save_model_in_monitor/#train-a-model","text":"Note If this lab is instructor led, he or she will provide you access to virtual image that has the Jupyter and the notebooks already installed. Skip steps 3, 4 and 8 if you are using Windows Virtual Machine. Open a terminal window on Mac or a command prompt window on Windows. Activate your virtual environment.","title":"Train a Model"},{"location":"train_test_save_model_in_monitor/#example-for-mac","text":"cd /Users/<\"replace with your user id\">/<\"replace with your virtual environment name\">/bin cd /Users/carlosferreira/ve/iot-python3/bin source activate","title":"Example for Mac"},{"location":"train_test_save_model_in_monitor/#example-for-windows","text":"cd C:\\Users\\ibmuser\\iot-python3 .\\Scripts\\activate.bat Change directory to your cloned github project directory.","title":"Example for Windows"},{"location":"train_test_save_model_in_monitor/#example-for-mac_1","text":"cd /Users/student01/MAS_AutoAI","title":"Example for Mac"},{"location":"train_test_save_model_in_monitor/#example-for-windows_1","text":"cd C:\\Users\\ibmuser\\iot-python3\\maximo_autoai Apply export variables in terminal for DYLD_LIBRARY_PATH for DB2 jars on Mac OS X only.","title":"Example for Windows"},{"location":"train_test_save_model_in_monitor/#example-for-mac_2","text":"cd \"<replace with the git cloned project directory name>\" cd /Users/carlos.ferreira1ibm.com/ws/autoai export DYLD_LIBRARY_PATH=<\"replace with your virtual env directory>\"/lib/python3.7/site-packages/clidriver/lib:$DYLD_LIBRARY_PATH export DYLD_LIBRARY_PATH=/Users/carlosferreira/ve/iot-python3/lib/python3.7/site-packages/clidriver/lib:$DYLD_LIBRARY_PATH # Example Set PYTHONPATH to your project directory where you installed your virtual environment","title":"Example for Mac"},{"location":"train_test_save_model_in_monitor/#example-for-mac_3","text":"export PYTHONPATH=\"<replace with your root_project_directory>\"/maximo_autoai export PYTHONPATH=/Users/carlosferreira/Documents/AutoAILabs/iot-python3/maximo_autoai Start the Jupyter Notebook service. and launch browser with Jupyter Notebook to edit Linear Regression Models. jupyter notebook Jupyter will open in a browser tab. Open and study the project notebook named maximo_auto_ai-extra-trees-pump.ipynb using the instructions for the virtual environment you created. Click on Notebooks folder. Click on notebook named maximo_auto_ai-extra-trees-pump.ipyn Make a copy of the Project Notebook Rename the notebook, change the name of your notebook by appending your own initials to the end of the Jupyter Notebook name. In the jupyter notebook, select file menu and Save As . Enter notebooks/maximo_auto_ai-extra-trees-pump-co.ipynb and click Save . This code in the notebook sets the Monitor credentials and entity type for your your instance of Monitor. Copy your credentials in Monitor from Services menu and Watson IOT Platform Analytics. Save it in a file named beta-1_credentials.json in the directory shown in the code below. credentials = {} with open('/Users/carlos.ferreira1ibm.com/ws/autoai/beta-1_credentials.json', encoding='utf-8') as F: credentials = json.loads(F.read()) db = Database(credentials = credentials) db_schema = \"BLUADMIN\" # set if you are not using the default entity_type = 'pump_co' This code in the notebook build a model for each pump. The Entity_Type_ID uniquely identifies each asset the model should be trained for. Set the Entity_Type_ID the model should be associated with. There are two ways to search the custom function logs in Cloud Object Storage using Cyberduck that are described in the exercise named Download, Install and Configure CyberDuck for View Logs in Monitor To find your Entity_Type_ID in the logs in Monitor, launch Cyberduck, and locate your pump, e.g. pump_co. Unzip and open one of the *.gz files there (e.g. 111012.gz) and search for 'entity_type_id'. It should be on the first row of the log files. entity_type = 'pump_cp' entity_type_id = 19305 entity_name = '04714B6037F8' a_df = r_df.loc[r_df['device_id'] == entity_name, :] print ('a_df.shape 1') print (a_df.shape) print (a_df) This code in the notebook splits the data into train and test subsets. from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42) This code in the notebook creates the model using the train data. extra_trees_model = ExtraTreesRegressor() extra_trees_model.fit(X_train, y_train.values.ravel() )","title":"Example for Mac"},{"location":"train_test_save_model_in_monitor/#test-a-model","text":"This code in the notebook tests the model using the test data to make a prediction. It should return a power prediction = 11.471 row = [[ 971.0, 989.633, 331.0, 26.44]] yhat = extra_trees_model.predict(row) x_pos_predictions = extra_trees_model.predict(X_test) This code in the notebook plots the prediction accuracy by comparing prediction values versus true values. plt.scatter(y_test, x_pos_predictions) plt.xlabel('True Values') plt.ylabel('Predictions') This code in the notebook calculates the model accuracy. Smaller values indicate better accuracy making predictions. from sklearn import metrics print(\"Mean Absolute Error\") print(metrics.mean_absolute_error(y_test, x_pos_predictions)) print(\"Mean Square Error\") print(metrics.mean_squared_error(y_test, x_pos_predictions)) print(\"Root Mean Square Error\") print(np.sqrt(metrics.mean_squared_error(y_test, x_pos_predictions)))","title":"Test a Model"},{"location":"train_test_save_model_in_monitor/#save-model-to-monitor","text":"In the notebook, change the name of your model by replacing co with your own initials power_extra_trees_model_co.mod This code in the notebook saves the model to disk locally, re-loads the mode into memory and tries to make a prediction. import pickle model_file_path = '/Users/carlos.ferreira1ibm.com/ws/autoai/models/power_random_forest.mod' pickle.dump(extra_trees_model, open(model_file_path, 'wb')) model = pickle.load(open(model_file_path, 'rb')) row = [[1160.0, 1190.626, 438.0, 33.16]] yhat = model.predict(row) This code in the notebook saves the model in Monitor. Make sure you replace the co in the model name to your own initials power_extra_trees_model_co.mod from iotfunctions.db import Database import json credentials = {} credential_file = '/Users/carlos.ferreira1ibm.com/ws/autoai/beta-1_credentials.json' with open(credential_file, encoding='utf-8') as F: credentials = json.loads(F.read()) db_ctp = Database(credentials=credentials, entity_type_id=entity_type_id ) from datetime import datetime model_name = 'power_extra_trees_model_co.mod' try: feature_vector = ['speed', 'flow', 'voltage', 'CURRENT' ] model_dict = { 'model': model, 'feature_vector': feature_vector, 'timesstamp' : datetime.now().strftime(\"%Y%m%d%H%M%S\") } db_ctp.model_store.store_model(model_name, model_dict) except Exception as e: print('Model store failed with ' + str(e)) pass","title":"Save Model to Monitor."},{"location":"train_test_save_model_in_monitor/#retrieve-a-model-and-make-predictions","text":"This code in the notebook retrieves the model from Monitor and tries to make a prediction. try: model_dict = db_ctp.model_store.retrieve_model(model_name) print(\"load model\") monitor_model = model_dict[\"model\"] print(monitor_model) feature_vector = model_dict[\"feature_vector\"] print(feature_vector) feature_vector = model_dict[\"timesstamp\"] print(feature_vector) except Exception as e: print(\"Model retrieval failed with \" + str(e)) pass Congratulations you have learned how to use the provided Jupyter notebook to train test and deploy a prediction model to Monitor. For more resource intensive models you should deploy them to a separate runtime service to make predictions. In the next lab exercise you will register the provided Monitor Custom function that will allow you to send the pump metrics data to your deployed model to make a prediction.","title":"Retrieve a Model and Make Predictions"},{"location":"update_dashboards/","text":"Add Calculations, Alerts and Update Dashboards Monitor calculations allow you to process time series data or do other scheduled activities. Calculations could be to check how much the actual power consumption deviates from the prediction power consumption from the pump. If this deviation is too large it could indicate there is a anomaly that needs to be investigated. In this exercise you will: Add Calculations to add a new metric called predicted_power_max_deviation using a formula power_prediction * 1.2 Add Alerts to raise an alert when the actual POWER is greater than maximum_predicted_power_deviation. Add Calculations To see and monitor the values of calculated metric in Monitor, you must add the metric, calculated metrics and alerts to an asset dashboard. In this exercise you will add the new calculated metric named power_prediction_co_max_deviation to your asset calculated metrics to calculate the maximum power prediction allowed. Note Remember to replace co with your initials in the name of your own asset type if you aren't in an instructor led lab. Remember to replace co with the initials that you used for your power prediction calculated metric. Click Setup menu. Search on pump_co . Click pump_co Click on Manage Asset Type to see the metrics that have already been added to your asset type for your pump_co . Click on the Data tab, expand the Metrics and Calulated Metric These are the raw metrics sent by the simulated pump time series data and the calculations used to operate on the data. Like making a prediction for power like you did in the last exercise to Deploy Model . Add a calculation for what is the maximum acceptable power consumption. Click + button in the Asset view, and then search for and select the NewColFromCalculation function. Click on select button. From sources Data Items choose the power_prediction metric as the input to our calculation. For the calculation expression enter: 1.2*df['power_prediction'] and click the Next button Set Output metric to predicted_power_co_max_deviation . Set Output type to Number . Finally click the Next button. Add alerts Note Remember to replace co with your initials in the name of your own calculated metrics and alert names. The \"Alerts\" function allows you to be notified when anomalies are detected. In this exercise you will add an Alerts that check if the actual POWER is greater than the predicted_power_co_max_deviation . Click Setup menu. Search on pump_co if you are in the instructor led class. Otherwise search for pump_Your_Initials to find the asset type you created and click on it. Click pump_Your_Initials Click on Manage Asset Type to see the metrics that have already been added to your asset type for your pump_Your_Initials Click on the Data tab, expand the Metrics and Calulated Metric These are the raw metrics sent by the simulated pump time series data and the calculations used to operate on the data. Like making a prediction for power like you did in the last exercise to Deploy Model . Click + button in the Asset view, and then search for and select the AlertExpression function. Then, enter a condition indicating when the Alert should be triggered. In this case, we should get an alert whenever POWER is greater power_prediction_co_max_deviation df['POWER']>df['power_prediction_co_max_deviation'] Click Next Set Output metric: power_prediction_co_max_deviation_alert Set Output type: Number Click Create button. The calculation of alerts will be checked every 5 minutes by default. You can set a different schedule frequency as well for verifying calculations and alerts. Update Dashboard Power Card To see and monitor the values of calculated metric in Monitor, you must add the metric, calculated metrics and alerts to an asset dashboard. In this exercise you will add the new calculated metric power_prediction_co_max_deviation to your asset dashboard as a line series card. Note Remember to replace co with your initials in the name of your own asset type if you aren't in an instructor led lab. Remember to replace co with the initials that you used for your power prediction calculated metrics and alerts. Edit the Asset dashboard selecting your recently created calculated metric for power_prediction_co . Click on Monitor , search on pump_co , click on 111137F8 , click on Asset Metrics Dashboard tab and click on Settings gear icon. Click Edit Dashboard and then click Continue button in dialog. Click on the POWER card. In the card window , data section click on data item filter and select power_prediction_co . Click on the Dashboard menu tab. In the card window , data section click on data item filter and select power_prediction_co . Click on the POWER card. In the card window , data section click on data item filter and select power_prediction_co . Click the Save and close button to save your changes to the dashboard. All pumps will now get this same dashboard change. You can also create asset specific dashboards for each asset in the Setup Asset Type menu. Update Dashboard Power Card with Alert To see a visual red dot on line series cards where alerts happen at specific time stamps you must edit the JSON of the dashboard directly. Edit the Asset dashboard selecting your recently created calculated metric for power_prediction_co . Click on Monitor , search on pump_co , click on 111137F8 , click on Asset Metrics Dashboard tab and click on Settings gear icon. Click Edit Dashboard and then click Continue button in dialog. Click Export Dashboard and save the json file locally. Update and save the Json with the following code using a Python Editor or Monitor's Json editor in the Dashboard Editor. Import the updated Json file and click the Save and close button to save your changes to the dashboard. All pumps will now get this same dashboard change. You can also create asset specific dashboards for each asset in the Setup Asset Type menu. You should now see the Asset Metrics Dashboard with alerts similar to the one below in the Asset Dashboard. View Dashboard Note Remember to replace co with your initials in the name of your own asset type if you aren't in an instructor led lab. Remember to replace co with the initials that you used for your power prediction calculated metrics and alerts. View the Asset dashboard. Click on Monitor menu on the left, search on pump_co , click on 111137F8 , click on Asset Metrics Dashboard and scroll down to see the Power card. Expand the POWER card. Click on the double square icon. When the window opens click on POWER and Click on power_prediction_co to toggle the lines off and on. Notice the power values in the table below. You can also export the data to a csv file by clicking on the funnel icon. View Alerts To see alerts for a specific asset, click on Monitor , search on pump_co asset type, click on 111137F8 , click on Alerts tab. To see why there aren't any alerts modify the asset dashboard for 11111096 . Add power_prediction_co_max_deviation to your asset dashboard. Notice how the maximum value of the actual power never exceeds the power_prediction_co_max_deviation An alert should therefore never be triggered. Experiment setting new column calculated for power_prediction_co_max_deviation to only be 1.05 higher to see if you can get some alerts showing. Congratulations you have completed all the exercises in this lab and hopefully have a better understanding of how to create AI models and make the usable in Maximo Asset Monitor to monitor your assets.","title":"10. Update Dashboards"},{"location":"update_dashboards/#add-calculations-alerts-and-update-dashboards","text":"Monitor calculations allow you to process time series data or do other scheduled activities. Calculations could be to check how much the actual power consumption deviates from the prediction power consumption from the pump. If this deviation is too large it could indicate there is a anomaly that needs to be investigated. In this exercise you will: Add Calculations to add a new metric called predicted_power_max_deviation using a formula power_prediction * 1.2 Add Alerts to raise an alert when the actual POWER is greater than maximum_predicted_power_deviation.","title":"Add Calculations, Alerts and Update Dashboards"},{"location":"update_dashboards/#add-calculations","text":"To see and monitor the values of calculated metric in Monitor, you must add the metric, calculated metrics and alerts to an asset dashboard. In this exercise you will add the new calculated metric named power_prediction_co_max_deviation to your asset calculated metrics to calculate the maximum power prediction allowed. Note Remember to replace co with your initials in the name of your own asset type if you aren't in an instructor led lab. Remember to replace co with the initials that you used for your power prediction calculated metric. Click Setup menu. Search on pump_co . Click pump_co Click on Manage Asset Type to see the metrics that have already been added to your asset type for your pump_co . Click on the Data tab, expand the Metrics and Calulated Metric These are the raw metrics sent by the simulated pump time series data and the calculations used to operate on the data. Like making a prediction for power like you did in the last exercise to Deploy Model . Add a calculation for what is the maximum acceptable power consumption. Click + button in the Asset view, and then search for and select the NewColFromCalculation function. Click on select button. From sources Data Items choose the power_prediction metric as the input to our calculation. For the calculation expression enter: 1.2*df['power_prediction'] and click the Next button Set Output metric to predicted_power_co_max_deviation . Set Output type to Number . Finally click the Next button.","title":"Add Calculations"},{"location":"update_dashboards/#add-alerts","text":"Note Remember to replace co with your initials in the name of your own calculated metrics and alert names. The \"Alerts\" function allows you to be notified when anomalies are detected. In this exercise you will add an Alerts that check if the actual POWER is greater than the predicted_power_co_max_deviation . Click Setup menu. Search on pump_co if you are in the instructor led class. Otherwise search for pump_Your_Initials to find the asset type you created and click on it. Click pump_Your_Initials Click on Manage Asset Type to see the metrics that have already been added to your asset type for your pump_Your_Initials Click on the Data tab, expand the Metrics and Calulated Metric These are the raw metrics sent by the simulated pump time series data and the calculations used to operate on the data. Like making a prediction for power like you did in the last exercise to Deploy Model . Click + button in the Asset view, and then search for and select the AlertExpression function. Then, enter a condition indicating when the Alert should be triggered. In this case, we should get an alert whenever POWER is greater power_prediction_co_max_deviation df['POWER']>df['power_prediction_co_max_deviation'] Click Next Set Output metric: power_prediction_co_max_deviation_alert Set Output type: Number Click Create button. The calculation of alerts will be checked every 5 minutes by default. You can set a different schedule frequency as well for verifying calculations and alerts.","title":"Add alerts"},{"location":"update_dashboards/#update-dashboard-power-card","text":"To see and monitor the values of calculated metric in Monitor, you must add the metric, calculated metrics and alerts to an asset dashboard. In this exercise you will add the new calculated metric power_prediction_co_max_deviation to your asset dashboard as a line series card. Note Remember to replace co with your initials in the name of your own asset type if you aren't in an instructor led lab. Remember to replace co with the initials that you used for your power prediction calculated metrics and alerts. Edit the Asset dashboard selecting your recently created calculated metric for power_prediction_co . Click on Monitor , search on pump_co , click on 111137F8 , click on Asset Metrics Dashboard tab and click on Settings gear icon. Click Edit Dashboard and then click Continue button in dialog. Click on the POWER card. In the card window , data section click on data item filter and select power_prediction_co . Click on the Dashboard menu tab. In the card window , data section click on data item filter and select power_prediction_co . Click on the POWER card. In the card window , data section click on data item filter and select power_prediction_co . Click the Save and close button to save your changes to the dashboard. All pumps will now get this same dashboard change. You can also create asset specific dashboards for each asset in the Setup Asset Type menu.","title":"Update Dashboard Power Card"},{"location":"update_dashboards/#update-dashboard-power-card-with-alert","text":"To see a visual red dot on line series cards where alerts happen at specific time stamps you must edit the JSON of the dashboard directly. Edit the Asset dashboard selecting your recently created calculated metric for power_prediction_co . Click on Monitor , search on pump_co , click on 111137F8 , click on Asset Metrics Dashboard tab and click on Settings gear icon. Click Edit Dashboard and then click Continue button in dialog. Click Export Dashboard and save the json file locally. Update and save the Json with the following code using a Python Editor or Monitor's Json editor in the Dashboard Editor. Import the updated Json file and click the Save and close button to save your changes to the dashboard. All pumps will now get this same dashboard change. You can also create asset specific dashboards for each asset in the Setup Asset Type menu. You should now see the Asset Metrics Dashboard with alerts similar to the one below in the Asset Dashboard.","title":"Update Dashboard Power Card with Alert"},{"location":"update_dashboards/#view-dashboard","text":"Note Remember to replace co with your initials in the name of your own asset type if you aren't in an instructor led lab. Remember to replace co with the initials that you used for your power prediction calculated metrics and alerts. View the Asset dashboard. Click on Monitor menu on the left, search on pump_co , click on 111137F8 , click on Asset Metrics Dashboard and scroll down to see the Power card. Expand the POWER card. Click on the double square icon. When the window opens click on POWER and Click on power_prediction_co to toggle the lines off and on. Notice the power values in the table below. You can also export the data to a csv file by clicking on the funnel icon.","title":"View Dashboard"},{"location":"update_dashboards/#view-alerts","text":"To see alerts for a specific asset, click on Monitor , search on pump_co asset type, click on 111137F8 , click on Alerts tab. To see why there aren't any alerts modify the asset dashboard for 11111096 . Add power_prediction_co_max_deviation to your asset dashboard. Notice how the maximum value of the actual power never exceeds the power_prediction_co_max_deviation An alert should therefore never be triggered. Experiment setting new column calculated for power_prediction_co_max_deviation to only be 1.05 higher to see if you can get some alerts showing. Congratulations you have completed all the exercises in this lab and hopefully have a better understanding of how to create AI models and make the usable in Maximo Asset Monitor to monitor your assets.","title":"View Alerts"}]}